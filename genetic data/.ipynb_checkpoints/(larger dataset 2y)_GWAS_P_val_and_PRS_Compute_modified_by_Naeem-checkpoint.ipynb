{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug cell\n",
    "with open('simple_table.txt', 'r') as f:\n",
    "    print(type(f))\n",
    "    cnt = 2\n",
    "    for i,line in enumerate(f):\n",
    "        print(i, ':\\t', line)\n",
    "        cnt -= 1\n",
    "        if cnt == 0:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug cell\n",
    "import gzip\n",
    "with gzip.open('./ukb-b-6134.vcf.gz') as f:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import time\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "def generate_gwas_output_as_tsv_file(inVCF_File, writeFile=None):\n",
    "    root = './tabular_format_gwas_data/'\n",
    "    t0 = time.time()\n",
    "    if writeFile is None:\n",
    "        writeFile = root + inVCF_File.split('/')[-1].split('.')[0] + '.tsv'\n",
    "    \n",
    "    print(\"Processing:\", inVCF_File)\n",
    "    if \".gz\" == inVCF_File[-3:]:\n",
    "        with gzip.open(inVCF_File, 'rb') as f_in:\n",
    "            with open(root+'temp_vcf.vcf', 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "        inVCF_File = root+'temp_vcf.vcf'\n",
    "    print(\"gzip open done :\", inVCF_File)\n",
    "    \"\"\"\n",
    "    Convert all the VCF into simplified tsv format\n",
    "    Source: https://github.com/everestial/VCF-simplify#table-of-contents\n",
    "    python3 ./VCF-Simplify/VCF-Simplify/VcfSimplify.py SimplifyVCF -toType table -inVCF ./ukb-b-6134.vcf -outFile ./simple_table.txt\n",
    "    \"\"\"\n",
    "    vcf_simplify_path = \"./VCF-Simplify/VCF-Simplify/VcfSimplify.py\"\n",
    "    out_File = root+'temp_table.tsv'\n",
    "    os.system(f\"python3 {vcf_simplify_path} SimplifyVCF -toType table -inVCF {inVCF_File} -outFile {out_File}\")\n",
    "    print(writeFile)\n",
    "        \n",
    "    f_read = open(out_File, 'r')\n",
    "    f_write = open(writeFile, 'w')\n",
    "    cnt = 0\n",
    "    for line in f_read:\n",
    "#         print(line)\n",
    "        newliner = ''\n",
    "        if '\\n' == line[-1]:\n",
    "            newliner = '\\n'\n",
    "            line = line.strip()\n",
    "        if 'CHROM' in line:\n",
    "            line = line.upper() + '\\tPVAL_generated_from_LP'\n",
    "        else:\n",
    "            LP = float(line.split('\\t')[10])\n",
    "#             LP = float(line.split('\\t')[14])\n",
    "            #find out LP column from the tsv file\n",
    "            \n",
    "            p_val = str(10**(-1 * LP))\n",
    "            line = line + '\\t' + p_val\n",
    "        line = line + newliner\n",
    "    #     print(line)\n",
    "        f_write.write(line)\n",
    "        cnt += 1\n",
    "    #     if cnt == 20: break\n",
    "\n",
    "    f_read.close()\n",
    "    f_write.close()\n",
    "    print(f'Total SNPs: {cnt} | Total exec time: {time.time() - t0} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "generate_gwas_output_as_tsv_file(inVCF_File='./tabular_format_gwas_data/ukb-b-20289.vcf.gz', writeFile=None)\n",
    "generate_gwas_output_as_tsv_file(inVCF_File='./tabular_format_gwas_data/ukb-b-19732.vcf.gz', writeFile=None)\n",
    "\n",
    "# generate_gwas_output_as_tsv_file(inVCF_File='./tabular_format_gwas_data/ukb-b-17006.vcf.gz', writeFile=None)\n",
    "# generate_gwas_output_as_tsv_file(inVCF_File='./tabular_format_gwas_data/ukb-b-5779.vcf.gz', writeFile=None)\n",
    "# generate_gwas_output_as_tsv_file(inVCF_File='./tabular_format_gwas_data/ukb-b-15541.vcf.gz', writeFile=None)\n",
    "\n",
    "\n",
    "# need to just specify the file path here\n",
    "# ebi-a-GCST005920.vcf.gz\n",
    "# ebi-a-GCST005923.vcf.gz\n",
    "# ukb-b-14699.vcf.gz\n",
    "# ukb-b-323.vcf.gz\n",
    "# ukb-b-6358\n",
    "# next update in the 'GWAS_datasets_to_consider.xlsx'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ' abc def\\n'.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10**(-1*0.200659) #0.6300007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %pip install openpyxl\n",
    "import pandas as pd\n",
    "\n",
    "category_map = {\n",
    "    'Continuous' : 'beta', \n",
    "    'Categorical Ordered (assumed continuous)': 'beta',\n",
    "    'Binary': 'or',\n",
    "    'NA (Possibly binary)': 'or'\n",
    "}\n",
    "\n",
    "df = pd.read_excel('GWAS_datasets_to_consider.xlsx', engine='openpyxl')[['GWAS_ID', 'Trait', 'Category']]\n",
    "print(df['Category'].unique())\n",
    "GWAS_ID = 'ieu-b-111'\n",
    "category = category_map[df[df['GWAS_ID'] == GWAS_ID].to_numpy()[0, 2]] \n",
    "category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "# all_gwas_vcf_files = glob('/mnt/c/Users/HP/Downloads/Compressed/GWAS/*')\n",
    "# ROOT = '/mnt/c/Users/HP/Downloads/Compressed/GWAS/'\n",
    "# ALL_GWAS_IDS = list(set(df['GWAS_ID'].to_numpy().tolist()) - {'bbj-a-46', 'bbj-a-78', 'ieu-a-1283', 'ukb-a-257','ukb-b-2209','ukb-b-17627','ieub-109','ieu-b-110','ieu-b-111','met-d-Total_C'})\n",
    "# bbj-a-78,ukb-a-257,bbj-a-46\n",
    "# ALL_GWAS_IDS = list(set(df['GWAS_ID'].to_numpy().tolist()) - { 'ieu-a-1283','bbj-a-46', 'bbj-a-78'})\n",
    "ALL_GWAS_IDS = list(set(df['GWAS_ID'].to_numpy().tolist()) - { 'ieu-a-1283','bbj-a-46', 'bbj-a-78','ukb-b-13806','ukb-b-12064','ukb-b-323','ukb-b-14699','ukb-b-14699','ukb-b-5779'})\n",
    "\n",
    "\n",
    "base_files = {}\n",
    "\n",
    "# base_files=[] #naeem mod\n",
    "for GWAS_ID in ALL_GWAS_IDS:\n",
    "    print(GWAS_ID)\n",
    "#     file = ROOT + GWAS_ID + '.vcf.gz'\n",
    "    base_files[GWAS_ID] = category_map[df[df['GWAS_ID'] == GWAS_ID].to_numpy()[0, 2]]\n",
    "\n",
    "#     generate_gwas_output_as_tsv_file(inVCF_File=file, writeFile=None)\n",
    "# print(name_mapping)\n",
    "# print(name_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# base_files\n",
    "print(base_files)\n",
    "for GWAS_ID in base_files:\n",
    "    print(GWAS_ID)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gender_map = {'Female': 0,'Male': 1}\n",
    "ADNIMERGE = pd.read_csv('ADNIMERGE.csv')\n",
    "def get_gender_and_age(PTID):\n",
    "    gender = ADNIMERGE[ADNIMERGE['PTID'] == PTID]['PTGENDER'].dropna().unique()[0]\n",
    "    age = ADNIMERGE[ADNIMERGE['PTID'] == PTID]['AGE'].dropna().unique()[0]\n",
    "    return str(gender_map[gender]) + ' ' + str(age)\n",
    "\n",
    "# NUM_TRAINING_SAMPLES = int(830 * .7)\n",
    "# print('NUM_TRAINING_SAMPLES:', NUM_TRAINING_SAMPLES)\n",
    "# f_writable = open('./COVAR_FILE.txt', 'w')\n",
    "# f_TRAINING_SAMPLES = open('./TRAINING_SAMPLES.txt', 'w')\n",
    "# with open('/mnt/c/Users/HP/Documents/GWA_tutorial/2_Population_stratification/covar_mds.txt') as f:\n",
    "#     for i, line in enumerate(f):\n",
    "#         if 'FID IID' in line:\n",
    "#             line = line[:-1] + ' GENDER AGE\\n'\n",
    "#         else:\n",
    "#             line = line[:-1] + ' ' + get_gender_and_age(PTID=line.split(' ')[1]) + '\\n'\n",
    "#         if i < NUM_TRAINING_SAMPLES:\n",
    "#             f_TRAINING_SAMPLES.write(' '.join(line.split(' ')[:2])+'\\n')\n",
    "#         f_writable.write(line)\n",
    "# #         print(line)\n",
    "# f_writable.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_prsice(GWAS_ID, redo=False):\n",
    "#     TARGET_DATA = '/mnt/c/Users/HP/Documents/GWA_tutorial/2_Population_stratification/ADNI' # old and smaller dataset\n",
    "    TARGET_DATA = '../larger_dataset/larger_dataset' # new and larger dataset\n",
    "    '''\n",
    "    return_status --> 0: success | 256: Error. Execusion Halted | 2: \n",
    "    '''\n",
    "#     need to alter between these two if needed\n",
    "    if os.path.isfile(f'./PRSice_output/{GWAS_ID}/'):\n",
    "#     if True:\n",
    "        return_status = os.system(f'mkdir ./PRSice_output/{GWAS_ID}/')\n",
    "        print('0:', return_status)\n",
    "        if return_status == 256 and not redo:\n",
    "            return return_status\n",
    "    print('stat',{base_files[GWAS_ID]})\n",
    "#     prsice_command = f'Rscript ./PRSice_linux/PRSice.R \\\n",
    "#         --dir ./PRSice_output \\\n",
    "#         --prsice ./PRSice_linux/PRSice_linux \\\n",
    "#         --base ./tabular_format_gwas_data/{GWAS_ID}.tsv \\\n",
    "#         --target {TARGET_DATA} \\\n",
    "#         --thread 2 \\\n",
    "#         --stat {base_files[GWAS_ID].upper()} \\\n",
    "#         --{base_files[GWAS_ID]} \\\n",
    "#         --binary-target F \\\n",
    "#         --quantile 10 \\\n",
    "#         --out ./PRSice_output/{GWAS_ID}/{GWAS_ID} \\\n",
    "#         --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat {GWAS_ID.upper()}:ES --pvalue PVAL_generated_from_LP \\\n",
    "#         --score std \\\n",
    "#         --cov ../larger_dataset/COVAR_FILE_bigger_dataset.txt \\\n",
    "#         --extract ./PRSice_output/{GWAS_ID}/{GWAS_ID}.valid'\n",
    "    if os.path.isfile(f'./PRSice_output/{GWAS_ID}/{GWAS_ID}.valid'):\n",
    "        prsice_command = f'Rscript ./PRSice_linux/PRSice.R \\\n",
    "            --dir ./PRSice_output \\\n",
    "            --prsice ./PRSice_linux/PRSice_linux \\\n",
    "            --base ./tabular_format_gwas_data/{GWAS_ID}.tsv \\\n",
    "            --target {TARGET_DATA} \\\n",
    "            --thread 2 \\\n",
    "            --stat {base_files[GWAS_ID].upper()} \\\n",
    "            --{base_files[GWAS_ID]} \\\n",
    "            --binary-target F \\\n",
    "            --quantile 10 \\\n",
    "            --out ./PRSice_output/{GWAS_ID}/{GWAS_ID} \\\n",
    "            --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat {GWAS_ID.upper()}:ES --pvalue PVAL_generated_from_LP \\\n",
    "            --score std \\\n",
    "            --cov ../larger_dataset/COVAR_FILE_bigger_dataset.txt \\\n",
    "            --extract ./PRSice_output/{GWAS_ID}/{GWAS_ID}.valid'\n",
    "    else :\n",
    "        prsice_command = f'Rscript ./PRSice_linux/PRSice.R \\\n",
    "            --dir ./PRSice_output \\\n",
    "            --prsice ./PRSice_linux/PRSice_linux \\\n",
    "            --base ./tabular_format_gwas_data/{GWAS_ID}.tsv \\\n",
    "            --target {TARGET_DATA} \\\n",
    "            --thread 2 \\\n",
    "            --stat {base_files[GWAS_ID].upper()} \\\n",
    "            --{base_files[GWAS_ID]} \\\n",
    "            --binary-target F \\\n",
    "            --quantile 10 \\\n",
    "            --out ./PRSice_output/{GWAS_ID}/{GWAS_ID} \\\n",
    "            --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat {GWAS_ID.upper()}:ES --pvalue PVAL_generated_from_LP \\\n",
    "            --score std \\\n",
    "            --cov ../larger_dataset/COVAR_FILE_bigger_dataset.txt '\n",
    "#         print(prsice_command)\n",
    "#         print('stat',{base_files[GWAS_ID]})\n",
    "#         return_status = os.system(prsice_command) # generate the file named {GWAS_ID}.valid\n",
    "#         print('1:', return_status)\n",
    "#         return_status = os.system('echo \"===== Done =====\"')\n",
    "#         print('2:', return_status) \n",
    "\n",
    "    #             running second time with .valid extraction\n",
    "#         prsice_command = f'Rscript ./PRSice_linux/PRSice.R \\\n",
    "#             --dir ./PRSice_output \\\n",
    "#             --prsice ./PRSice_linux/PRSice_linux \\\n",
    "#             --base ./tabular_format_gwas_data/{GWAS_ID}.tsv \\\n",
    "#             --target {TARGET_DATA} \\\n",
    "#             --thread 2 \\\n",
    "#             --stat {base_files[GWAS_ID].upper()} \\\n",
    "#             --{base_files[GWAS_ID]} \\\n",
    "#             --binary-target F \\\n",
    "#             --quantile 10 \\\n",
    "#             --out ./PRSice_output/{GWAS_ID}/{GWAS_ID} \\\n",
    "#             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat {GWAS_ID.upper()}:ES --pvalue PVAL_generated_from_LP \\\n",
    "#             --score std \\\n",
    "#             --cov ../larger_dataset/COVAR_FILE_bigger_dataset.txt \\\n",
    "#             --extract ./PRSice_output/{GWAS_ID}/{GWAS_ID}.valid'\n",
    "        \n",
    "\n",
    "# #     return_status = os.system(prsice_command + '  --keep ./TRAINING_SAMPLES.txt') # generate the file named {GWAS_ID}.valid\n",
    "# #     return_status = os.system(prsice_command) # generate the file named {GWAS_ID}.valid\n",
    "# #     print('1a:', return_status)\n",
    "# #     return\n",
    "# #     if os.path.isfile(f'./PRSice_output/{GWAS_ID}/{GWAS_ID}.valid'): \n",
    "# #         prsice_command += f' --extract ./PRSice_output/{GWAS_ID}/{GWAS_ID}.valid' \n",
    "# #         return_status = os.system(prsice_command + '  --keep ./TRAINING_SAMPLES.txt') # perform the regression analysis on the training samples only and choose the best p-value-threshold\n",
    "# #         return_status = os.system(prsice_command) # perform the regression analysis on the training samples only and choose the best p-value-threshold\n",
    "# #         print('1b:', return_status)\n",
    "# #         if return_status != 0:\n",
    "# # #             return_status = os.system(prsice_command) # perform the regression analysis on the training samples only and choose the best p-value-threshold\n",
    "# #             print('1c:', return_status)\n",
    "# #     return_status = os.system(prsice_command + '  --all-score --no-regress') # Do not perform the regression analysis and simply output all PRS.\n",
    "# #     return_status = os.system(prsice_command + '  --all-score') # Do not perform the regression analysis and simply output all PRS.\n",
    "# #     print('2:', return_status)\n",
    "#     # in later steps, select the PRS values for the selected p-value-threshold for all the samples (both training and testing)\n",
    "    print(prsice_command)\n",
    "    print('stat',{base_files[GWAS_ID]})\n",
    "    return_status = os.system(prsice_command) # generate the file named {GWAS_ID}.valid\n",
    "    print('1:', return_status)\n",
    "    return_status = os.system('echo \"===== Done =====\"')\n",
    "    print('2:', return_status) \n",
    "#     os.system(f'mv ./prsice_output/{GWAS_ID}.* ./prsice_output/{GWAS_ID}/')\n",
    "# https://github.com/adiamb/Remove-duplicate-snps-plink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# here for some files a weird error occurs: \"reporter not initialized\"\n",
    "#         bbj-a-78\n",
    "# ukb-a-257\n",
    "# bbj-a-46\n",
    "for GWAS_ID in base_files:\n",
    "    if GWAS_ID == 'ukb-b-19732' :\n",
    "        print('*****GWAS ID IS*****',GWAS_ID)\n",
    "        run_prsice(GWAS_ID=GWAS_ID)\n",
    "#         problem -> they do not have corresponding entries in prsice_output folder->create those folders manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_prsice(GWAS_ID='ukb-b-17627')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls 'tabular_format_gwas_data/{GWAS_ID}.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_files\n",
    "GWAS_ID = 'ukb-b-18275'\n",
    "\n",
    "#====\n",
    "\n",
    "def get_prs_values(GWAS_ID):\n",
    "    prsice_output = f'./PRSice_output/{GWAS_ID}/'\n",
    "\n",
    "    if False:\n",
    "        with open(prsice_output+f'{GWAS_ID}.all_score', 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            lines = ['\\t'.join(x.split()) for x in lines]\n",
    "            lines = '\\n'.join(lines)\n",
    "\n",
    "        with open(prsice_output+f'{GWAS_ID}.all_score.tsv', 'w') as f:\n",
    "            f.write(lines)\n",
    "\n",
    "        # best_p_val_threshold = '0.00025005'\n",
    "        best_p_val_threshold = str(open(prsice_output+f'{GWAS_ID}.summary').readlines()[1].split('\\t')[2]) \n",
    "    #     print(best_p_val_threshold) \n",
    "    prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy() \n",
    "    return prs_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prs_values(GWAS_ID=GWAS_ID).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os.path\n",
    "import json\n",
    "name_mapping={}\n",
    "# GWAS_ID\n",
    "# ukb-b-13806\n",
    "# ukb-b-12064\n",
    "# ukb-b-323\n",
    "# ukb-b-14699\n",
    "# ukb-b-5779\n",
    "# base_files=base_files-\n",
    "print(base_files)\n",
    "\n",
    "\n",
    "\n",
    "PRS_feature_matrix = np.zeros([len(base_files), 1816])\n",
    "for i, GWAS_ID in enumerate(base_files):\n",
    "    print(GWAS_ID)\n",
    "    prsice_output = f'./PRSice_output/{GWAS_ID}/{GWAS_ID}.best'\n",
    "    if os.path.exists(prsice_output):  \n",
    "        PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
    "        name_mapping[GWAS_ID] =df[df['GWAS_ID'] == GWAS_ID].to_numpy()[0, 1]\n",
    "    else :\n",
    "        print(\"no path exists\")\n",
    "with open(\"traits_map.json\", \"w\") as outfile:\n",
    "    json.dump(name_mapping, outfile)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRS_feature_matrix = PRS_feature_matrix.T\n",
    "np.save('PRS_feature_matrix', PRS_feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRS_feature_matrix.shape\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SAMPLE_SIZE = 550\n",
    "train_samples = list(range(847))\n",
    "random.shuffle(train_samples)\n",
    "train_samples, test_samples = train_samples[:TRAIN_SAMPLE_SIZE], train_samples[TRAIN_SAMPLE_SIZE:]\n",
    "print(test_samples)\n",
    "print(len(train_samples), len(test_samples), len(train_samples) + len(test_samples))\n",
    "PRS_feature_matrix[train_samples].mean(0), PRS_feature_matrix[train_samples].std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRS_feature_matrix[test_samples].mean(0), PRS_feature_matrix[test_samples].std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRS_feature_matrix[:].mean(0), PRS_feature_matrix[:].std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "GWAS_ID = 'ieu-b-25'\n",
    "usable_samples_ADNI = pd.read_csv(f'./PRSice_output/{GWAS_ID}/{GWAS_ID}.best', ' ')['IID'].to_numpy().tolist()\n",
    "usable_samples_ADNI = {'_'.join(sample.split('_')[1:]):idx for idx,sample in enumerate(usable_samples_ADNI)}\n",
    "# json.dump(usable_samples_ADNI, open('./usable_samples_ADNI.json', 'w'))\n",
    "type(usable_samples_ADNI), len(usable_samples_ADNI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls PRSice_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "PRS_feature_matrix = np.load('./PRS_feature_matrix.npy')\n",
    "# usable_samples_ADNI = json.load(open('./usable_samples_ADNI.json'))\n",
    "print(PRS_feature_matrix.shape, usable_samples_ADNI.__len__())\n",
    "\n",
    "usable_samples_ADNI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "THRESHOLD_MONTH = 12*2\n",
    "ADNIMERGE = pd.read_csv('ADNIMERGE.csv')\n",
    "ADNI_TEMP = ADNIMERGE[['RID', 'PTID', 'DX', 'Month']].dropna().sort_values(by=['PTID', 'Month'])\n",
    "Dementia = ADNI_TEMP[ADNI_TEMP['DX']=='Dementia']\n",
    "Samples_Dementia = set(Dementia['PTID'].unique())\n",
    "Samples_NonDementia = set(ADNI_TEMP['PTID'].unique()) - Samples_Dementia\n",
    "# Samples_NonDementia\n",
    "Final_Samples_Dementia = set()\n",
    "for sample in Samples_Dementia:\n",
    "    last_dx = ADNI_TEMP[ADNI_TEMP['PTID']==sample]['DX'].iloc[-1]\n",
    "    last_month_of_dx = ADNI_TEMP[ADNI_TEMP['PTID']==sample]['Month'].iloc[-1]\n",
    "    if last_month_of_dx >= THRESHOLD_MONTH or True:\n",
    "        if last_dx == 'Dementia' and sample in usable_samples_ADNI:\n",
    "                Final_Samples_Dementia = Final_Samples_Dementia.union({sample})\n",
    "\n",
    "Final_Samples_NonDementia = set()\n",
    "for sample in Samples_NonDementia:\n",
    "    last_month_of_dx = ADNI_TEMP[ADNI_TEMP['PTID']==sample]['Month'].iloc[-1]\n",
    "    if last_month_of_dx >= THRESHOLD_MONTH and sample in usable_samples_ADNI:\n",
    "        Final_Samples_NonDementia = Final_Samples_NonDementia | {sample} # union symbol in python sets\n",
    "    \n",
    "# sum(ADNI_TEMP['Month'] == 6), ADNI_TEMP.shape\n",
    "# Dementia\n",
    "Final_Samples_Dementia = [[x, 1] for x in Final_Samples_Dementia]\n",
    "Final_Samples_NonDementia = [[x, 0] for x in Final_Samples_NonDementia]\n",
    "\n",
    "Final_Samples = Final_Samples_Dementia + Final_Samples_NonDementia\n",
    "json.dump(Final_Samples, open('Final_Samples.json', 'w'))\n",
    "\n",
    "Final_Samples_Dementia.__len__(), Final_Samples_NonDementia.__len__(), Final_Samples.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "GWAS_ID = 'ieu-b-25'\n",
    "usable_samples_ADNI = pd.read_csv(f'./PRSice_output/{GWAS_ID}/{GWAS_ID}.best', ' ')['IID'].to_numpy().tolist()\n",
    "usable_samples_ADNI = {sample:idx for idx,sample in enumerate(usable_samples_ADNI)}\n",
    "json.dump(usable_samples_ADNI, open('./usable_samples_ADNI.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_GWAS_IDS = [key for key in base_files]\n",
    "print(ALL_GWAS_IDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('GWAS_datasets_to_consider.xlsx', engine='openpyxl')[['GWAS_ID', 'Trait', 'Category']]\n",
    "all_traits = []\n",
    "for GWAS_ID in ALL_GWAS_IDS:\n",
    "    trait = str(df[df['GWAS_ID'] == GWAS_ID]['Trait'].to_numpy()[0])\n",
    "    print(GWAS_ID, ':', trait)\n",
    "    all_traits += [trait]\n",
    "print(all_traits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for demo purpose\n",
    "prsice_command = f'Rscript ./PRSice_linux/PRSice.R --dir ./PRSice_linux\t\\\n",
    "--prsice ./PRSice_linux/PRSice_linux     \\\n",
    "--base ./PRSice_linux/simple_table_with_pval.txt     \\\n",
    "--target ./PRSice_linux/ADNI_plink     \\\n",
    "--thread 1     \\\n",
    "--beta     \\\n",
    "--binary-target F\t\\\n",
    "--out ./PRSice_output/PRSice\t\\\n",
    "--snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat UKB-b-6134:ES --pvalue PVAL_generated_from_LP\t\\\n",
    "--extract ./PRSice_output/PRSice.valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # this is for demo purpose\n",
    "    import os\n",
    "    return_status = os.system(prsice_command) # generate the file named {GWAS_ID}.valid\n",
    "    print('1a:', return_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
