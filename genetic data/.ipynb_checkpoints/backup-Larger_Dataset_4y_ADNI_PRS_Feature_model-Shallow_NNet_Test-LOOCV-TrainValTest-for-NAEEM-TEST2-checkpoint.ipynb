{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "# Final_Samples\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "usable_samples_ADNI = json.load(open('./usable_samples_ADNI.json'))\n",
    "PRS_orig_feature_matrix = np.load('./PRS_feature_matrix.npy').astype(np.float32)\n",
    "PRS_orig_feature_matrix = (PRS_orig_feature_matrix - PRS_orig_feature_matrix.mean(0))/PRS_orig_feature_matrix.std(0)\n",
    "PRS_orig_feature_matrix.shape[1], len(usable_samples_ADNI), usable_samples_ADNI\n",
    "num_features=PRS_orig_feature_matrix.shape[1]\n",
    "print(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_features = 23\n",
    "hidden = 4\n",
    "hidden_dimension = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = \"./shap/\" + str(num_features)\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1816, 33)\n"
     ]
    }
   ],
   "source": [
    "PRS_feature_matrix = PRS_orig_feature_matrix\n",
    "PRS_feature_matrix = PRS_feature_matrix[:, :num_features]\n",
    "print(PRS_feature_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['d', '4'], ['c', '3'], ['b', '2'], ['a', '1']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([['a',1],['b',2],['c',3],['d',4]]).tolist()\n",
    "random.shuffle(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (1817, 14)\n",
      "(1817, 2) (1817, 2)\n",
      "                FID               IID       PC1       PC2       PC3       PC4  \\\n",
      "0  ADNI3_036_S_6231  ADNI3_036_S_6231 -0.006724 -0.010617  0.001596 -0.000460   \n",
      "1  ADNI3_006_S_6277  ADNI3_006_S_6277 -0.010432 -0.010269  0.012757  0.006921   \n",
      "2  ADNI3_129_S_6146  ADNI3_129_S_6146 -0.004919 -0.011656 -0.035521  0.064641   \n",
      "3  ADNI3_033_S_6352  ADNI3_033_S_6352 -0.014069 -0.010279  0.020014  0.053023   \n",
      "4  ADNI3_027_S_6183  ADNI3_027_S_6183 -0.010766 -0.012370 -0.010960  0.029830   \n",
      "\n",
      "        PC5       PC6       PC7       PC8       PC9      PC10  PTGENDER   AGE  \n",
      "0 -0.013131 -0.005855 -0.005142 -0.009063 -0.001739 -0.012863         1  69.1  \n",
      "1 -0.014958 -0.005860 -0.027775 -0.009632  0.054966  0.087390         1  70.7  \n",
      "2  0.012094  0.003860  0.035955  0.006561  0.019736 -0.023304         1  65.5  \n",
      "3  0.023691  0.000247 -0.002273 -0.030627 -0.053461  0.049984         0  71.4  \n",
      "4 -0.019520 -0.001955  0.023844  0.079138  0.002207  0.008892         0  65.6  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naeem/anaconda3/envs/ad_venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3397: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./COVAR_FILE_bigger_dataset.txt', ' ') \n",
    "print(\"shape\",df.shape)\n",
    "print( df[['AGE', 'PTGENDER']].shape, df[['AGE', 'PTGENDER']].dropna().shape )\n",
    "print( df.head() ) # PC - Principal Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape1 (1816, 33)\n",
      "shape2 (1816, 45)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.1288546255506608,\n",
       " array([[ 1.1957877e+00,  6.7549521e-01, -8.1201518e-01,  1.4735116e+00,\n",
       "          1.5833879e+00,  1.1038882e+00,  1.3769143e+00, -2.5817478e-01,\n",
       "          6.0254073e-01,  1.9010180e-01,  4.1337675e-01, -5.0156575e-01,\n",
       "          8.8049096e-01, -2.0883363e-01,  2.0768111e+00,  3.4892298e-02,\n",
       "         -4.5751646e-02,  1.5471818e+00,  8.8257521e-01,  2.1130602e-01,\n",
       "          4.4062281e-01, -7.8878814e-01,  1.1477689e+00, -1.5337672e+00,\n",
       "         -7.1390218e-01,  6.5592009e-01,  6.4279914e-01,  3.6035888e-02,\n",
       "         -1.0208811e+00,  4.2786098e-01,  3.8611200e-01, -5.8913165e-01,\n",
       "         -5.6206602e-01, -6.7239902e-03, -1.0617300e-02,  1.5955199e-03,\n",
       "         -4.6042900e-04, -1.3131300e-02, -5.8546802e-03, -5.1415302e-03,\n",
       "         -9.0632401e-03, -1.7389200e-03, -1.2863100e-02,  1.0000000e+00,\n",
       "          6.9099998e+01],\n",
       "        [ 6.9074273e-01,  8.7522858e-01,  2.1927162e-01, -3.7697020e-01,\n",
       "         -4.5436200e-01,  7.2349036e-01, -2.8283790e-01,  1.0644186e+00,\n",
       "          3.2023571e-02, -2.0424709e-01,  5.5778086e-01, -9.1423553e-01,\n",
       "         -4.4283944e-01,  3.5013828e-02,  5.9753662e-01, -2.4813785e-01,\n",
       "          6.6405241e-03,  2.8968764e-02,  1.3060592e+00, -2.7886992e-02,\n",
       "          3.0547190e-01,  2.6224835e+00,  4.3087134e-01,  6.1258554e-01,\n",
       "         -2.8895292e-01,  2.4560858e-01, -5.5759084e-01, -5.2110817e-02,\n",
       "         -4.4763651e-02, -1.8602200e-01, -7.2182208e-01,  5.6008160e-01,\n",
       "         -4.5909986e-01, -1.0432100e-02, -1.0269200e-02,  1.2757200e-02,\n",
       "          6.9213500e-03, -1.4958400e-02, -5.8604302e-03, -2.7775100e-02,\n",
       "         -9.6316896e-03,  5.4965999e-02,  8.7389797e-02,  1.0000000e+00,\n",
       "          7.0699997e+01]], dtype=float32),\n",
       " array([[ 1.1957877 ,  0.6754952 , -0.8120152 ,  1.4735116 ,  1.5833879 ,\n",
       "          1.1038882 ,  1.3769143 , -0.25817478,  0.60254073,  0.1901018 ,\n",
       "          0.41337675, -0.50156575,  0.88049096, -0.20883363,  2.076811  ,\n",
       "          0.0348923 , -0.04575165,  1.5471818 ,  0.8825752 ,  0.21130602,\n",
       "          0.4406228 , -0.78878814,  1.1477689 , -1.5337672 , -0.7139022 ,\n",
       "          0.6559201 ,  0.64279914,  0.03603589, -1.020881  ,  0.42786098,\n",
       "          0.386112  , -0.58913165, -0.562066  ],\n",
       "        [ 0.69074273,  0.8752286 ,  0.21927162, -0.3769702 , -0.454362  ,\n",
       "          0.72349036, -0.2828379 ,  1.0644186 ,  0.03202357, -0.20424709,\n",
       "          0.55778086, -0.91423553, -0.44283944,  0.03501383,  0.5975366 ,\n",
       "         -0.24813785,  0.00664052,  0.02896876,  1.3060592 , -0.02788699,\n",
       "          0.3054719 ,  2.6224835 ,  0.43087134,  0.61258554, -0.28895292,\n",
       "          0.24560858, -0.55759084, -0.05211082, -0.04476365, -0.186022  ,\n",
       "         -0.7218221 ,  0.5600816 , -0.45909986]], dtype=float32))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# COVAR_FILE = df.to_numpy()[:, 2:].astype(np.float32)\n",
    "cnt = 0\n",
    "print(\"shape1\",PRS_feature_matrix.shape)\n",
    "FEATURE_MATRIX = np.concatenate([PRS_feature_matrix, np.zeros([PRS_feature_matrix.shape[0], 12])], 1).astype(np.float32)\n",
    "print(\"shape2\",FEATURE_MATRIX.shape)\n",
    "for sample in usable_samples_ADNI:\n",
    "    covar = df[df['IID'] == sample].to_numpy()[:, 2:].astype(np.float32) # taking from the PCs, skipping the first two columns of IID, FID\n",
    "#     if cnt < 2:\n",
    "#         print(covar)\n",
    "    if covar.shape[0] != 1:\n",
    "#         print(sample)\n",
    "        cnt += 1\n",
    "        continue\n",
    "#     FEATURE_MATRIX[usable_samples_ADNI[sample], 23:] = covar\n",
    "# cnt/FEATURE_MATRIX.shape[0], FEATURE_MATRIX[:2], PRS_feature_matrix[:2]\n",
    "\n",
    "    FEATURE_MATRIX[usable_samples_ADNI[sample], num_features:] = covar # naeem's modification\n",
    "cnt/FEATURE_MATRIX.shape[0], FEATURE_MATRIX[:2], PRS_feature_matrix[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /home/naeem/anaconda3/envs/ad_venv:\r\n",
      "#\r\n",
      "# Name                    Version                   Build  Channel\r\n",
      "_anaconda_depends         2022.05                  py39_0  \r\n",
      "_libgcc_mutex             0.1                        main  \r\n",
      "_openmp_mutex             5.1                       1_gnu  \r\n",
      "aiohttp                   3.8.1            py39h7f8727e_1  \r\n",
      "aiosignal                 1.2.0              pyhd3eb1b0_0  \r\n",
      "alabaster                 0.7.12             pyhd3eb1b0_0  \r\n",
      "anaconda                  custom                   py39_1  \r\n",
      "anaconda-client           1.9.0            py39h06a4308_0  \r\n",
      "anaconda-project          0.10.2             pyhd3eb1b0_0  \r\n",
      "anyio                     3.5.0            py39h06a4308_0  \r\n",
      "appdirs                   1.4.4              pyhd3eb1b0_0  \r\n",
      "argon2-cffi               21.3.0             pyhd3eb1b0_0  \r\n",
      "argon2-cffi-bindings      21.2.0           py39h7f8727e_0  \r\n",
      "arrow                     1.2.2              pyhd3eb1b0_0  \r\n",
      "astroid                   2.6.6            py39h06a4308_0  \r\n",
      "astropy                   5.0.4            py39hce1f21e_0  \r\n",
      "asttokens                 2.0.5              pyhd3eb1b0_0  \r\n",
      "async-timeout             4.0.1              pyhd3eb1b0_0  \r\n",
      "atomicwrites              1.4.0                      py_0  \r\n",
      "attrs                     21.4.0             pyhd3eb1b0_0  \r\n",
      "automat                   20.2.0                     py_0  \r\n",
      "autopep8                  1.6.0              pyhd3eb1b0_0  \r\n",
      "babel                     2.9.1              pyhd3eb1b0_0  \r\n",
      "backcall                  0.2.0              pyhd3eb1b0_0  \r\n",
      "backports                 1.1                pyhd3eb1b0_0  \r\n",
      "backports.functools_lru_cache 1.6.4              pyhd3eb1b0_0  \r\n",
      "backports.tempfile        1.0                pyhd3eb1b0_1  \r\n",
      "backports.weakref         1.0.post1                  py_1  \r\n",
      "bcrypt                    3.2.0            py39he8ac12f_0  \r\n",
      "beautifulsoup4            4.11.1           py39h06a4308_0  \r\n",
      "binaryornot               0.4.4              pyhd3eb1b0_1  \r\n",
      "bitarray                  2.5.0            py39h7f8727e_0  \r\n",
      "bkcharts                  0.2              py39h06a4308_0  \r\n",
      "black                     19.10b0                    py_0  \r\n",
      "blas                      1.0                         mkl  \r\n",
      "bleach                    4.1.0              pyhd3eb1b0_0  \r\n",
      "blosc                     1.21.0               h8c45485_0  \r\n",
      "bokeh                     2.4.2            py39h06a4308_1  \r\n",
      "boto3                     1.24.2           py39h06a4308_0  \r\n",
      "botocore                  1.27.2           py39h06a4308_0  \r\n",
      "bottleneck                1.3.4            py39hce1f21e_0  \r\n",
      "brotli                    1.0.9                he6710b0_2  \r\n",
      "brotlipy                  0.7.0           py39h27cfd23_1003  \r\n",
      "brunsli                   0.1                  h2531618_0  \r\n",
      "bzip2                     1.0.8                h7b6447c_0  \r\n",
      "c-ares                    1.18.1               h7f8727e_0  \r\n",
      "ca-certificates           2022.4.26            h06a4308_0  \r\n",
      "cachetools                4.2.2              pyhd3eb1b0_0  \r\n",
      "certifi                   2022.5.18.1      py39h06a4308_0  \r\n",
      "cffi                      1.15.0           py39hd667e15_1  \r\n",
      "cfitsio                   3.470                hf0d0db6_6  \r\n",
      "chardet                   4.0.0           py39h06a4308_1003  \r\n",
      "charls                    2.2.0                h2531618_0  \r\n",
      "charset-normalizer        2.0.4              pyhd3eb1b0_0  \r\n",
      "click                     8.0.4            py39h06a4308_0  \r\n",
      "cloudpickle               2.0.0              pyhd3eb1b0_0  \r\n",
      "clyent                    1.2.2            py39h06a4308_1  \r\n",
      "colorama                  0.4.4              pyhd3eb1b0_0  \r\n",
      "colorcet                  3.0.0            py39h06a4308_0  \r\n",
      "conda                     4.13.0           py39h06a4308_0  \r\n",
      "conda-content-trust       0.1.1              pyhd3eb1b0_0  \r\n",
      "conda-pack                0.6.0              pyhd3eb1b0_0  \r\n",
      "conda-package-handling    1.8.1            py39h7f8727e_0  \r\n",
      "conda-token               0.3.0              pyhd3eb1b0_0  \r\n",
      "constantly                15.1.0             pyh2b92418_0  \r\n",
      "cookiecutter              1.7.3              pyhd3eb1b0_0  \r\n",
      "cryptography              37.0.1           py39h9ce1e76_0  \r\n",
      "cssselect                 1.1.0              pyhd3eb1b0_0  \r\n",
      "curl                      7.82.0               h7f8727e_0  \r\n",
      "cycler                    0.11.0             pyhd3eb1b0_0  \r\n",
      "cython                    0.29.28          py39h295c915_0  \r\n",
      "cytoolz                   0.11.0           py39h27cfd23_0  \r\n",
      "daal4py                   2021.5.0         py39h78b71dc_0  \r\n",
      "dal                       2021.5.1           h06a4308_803  \r\n",
      "dask                      2022.5.0         py39h06a4308_0  \r\n",
      "dask-core                 2022.5.0         py39h06a4308_0  \r\n",
      "dataclasses               0.8                pyh6d0b6a4_7  \r\n",
      "datashader                0.13.0             pyhd3eb1b0_1  \r\n",
      "datashape                 0.5.4            py39h06a4308_1  \r\n",
      "dbus                      1.13.18              hb2f20db_0  \r\n",
      "debugpy                   1.5.1            py39h295c915_0  \r\n",
      "decorator                 5.1.1              pyhd3eb1b0_0  \r\n",
      "defusedxml                0.7.1              pyhd3eb1b0_0  \r\n",
      "diff-match-patch          20200713           pyhd3eb1b0_0  \r\n",
      "distributed               2022.5.0         py39h06a4308_0  \r\n",
      "docutils                  0.17.1           py39h06a4308_1  \r\n",
      "entrypoints               0.4              py39h06a4308_0  \r\n",
      "et_xmlfile                1.1.0            py39h06a4308_0  \r\n",
      "executing                 0.8.3              pyhd3eb1b0_0  \r\n",
      "expat                     2.4.4                h295c915_0  \r\n",
      "filelock                  3.6.0              pyhd3eb1b0_0  \r\n",
      "flake8                    3.9.2              pyhd3eb1b0_0  \r\n",
      "flask                     2.0.3              pyhd3eb1b0_0  \r\n",
      "fontconfig                2.13.1               h6c09931_0  \r\n",
      "fonttools                 4.25.0             pyhd3eb1b0_0  \r\n",
      "freetype                  2.11.0               h70c0345_0  \r\n",
      "frozenlist                1.2.0            py39h7f8727e_0  \r\n",
      "fsspec                    2022.3.0         py39h06a4308_0  \r\n",
      "future                    0.18.2           py39h06a4308_1  \r\n",
      "gensim                    4.1.2            py39h295c915_0  \r\n",
      "geos                      3.8.0                he6710b0_0  \r\n",
      "giflib                    5.2.1                h7b6447c_0  \r\n",
      "glib                      2.69.1               h4ff587b_1  \r\n",
      "glob2                     0.7                pyhd3eb1b0_0  \r\n",
      "gmp                       6.2.1                h295c915_3  \r\n",
      "gmpy2                     2.1.2            py39heeb90bb_0  \r\n",
      "google-api-core           2.2.2              pyhd3eb1b0_0  \r\n",
      "google-auth               2.6.0              pyhd3eb1b0_0  \r\n",
      "google-cloud-core         2.2.2              pyhd3eb1b0_0  \r\n",
      "google-cloud-storage      1.43.0           py39h06a4308_0  \r\n",
      "google-crc32c             1.1.2            py39h27cfd23_0  \r\n",
      "google-resumable-media    1.3.1              pyhd3eb1b0_1  \r\n",
      "googleapis-common-protos  1.53.0           py39h06a4308_0  \r\n",
      "greenlet                  1.1.1            py39h295c915_0  \r\n",
      "grpcio                    1.42.0           py39hce63b2e_0  \r\n",
      "gst-plugins-base          1.14.0               h8213a91_2  \r\n",
      "gstreamer                 1.14.0               h28cd5cc_2  \r\n",
      "h5py                      3.6.0            py39ha0f2276_0  \r\n",
      "hdf5                      1.10.6               hb1b8bf9_0  \r\n",
      "heapdict                  1.0.1              pyhd3eb1b0_0  \r\n",
      "holoviews                 1.14.8             pyhd3eb1b0_0  \r\n",
      "hvplot                    0.7.3              pyhd3eb1b0_1  \r\n",
      "hyperlink                 21.0.0             pyhd3eb1b0_0  \r\n",
      "icu                       58.2                 he6710b0_3  \r\n",
      "idna                      3.3                pyhd3eb1b0_0  \r\n",
      "imagecodecs               2021.8.26        py39h4cda21f_0  \r\n",
      "imageio                   2.9.0              pyhd3eb1b0_0  \r\n",
      "imagesize                 1.3.0              pyhd3eb1b0_0  \r\n",
      "importlib-metadata        4.11.3           py39h06a4308_0  \r\n",
      "importlib_metadata        4.11.3               hd3eb1b0_0  \r\n",
      "incremental               21.3.0             pyhd3eb1b0_0  \r\n",
      "inflection                0.5.1            py39h06a4308_0  \r\n",
      "iniconfig                 1.1.1              pyhd3eb1b0_0  \r\n",
      "intake                    0.6.5              pyhd3eb1b0_0  \r\n",
      "intel-openmp              2021.4.0          h06a4308_3561  \r\n",
      "intervaltree              3.1.0              pyhd3eb1b0_0  \r\n",
      "ipykernel                 6.9.1            py39h06a4308_0  \r\n",
      "ipython                   8.3.0            py39h06a4308_0  \r\n",
      "ipython_genutils          0.2.0              pyhd3eb1b0_1  \r\n",
      "ipywidgets                7.6.5              pyhd3eb1b0_1  \r\n",
      "isort                     5.9.3              pyhd3eb1b0_0  \r\n",
      "itemadapter               0.3.0              pyhd3eb1b0_0  \r\n",
      "itemloaders               1.0.4              pyhd3eb1b0_1  \r\n",
      "itsdangerous              2.0.1              pyhd3eb1b0_0  \r\n",
      "jdcal                     1.4.1              pyhd3eb1b0_0  \r\n",
      "jedi                      0.18.1           py39h06a4308_1  \r\n",
      "jeepney                   0.7.1              pyhd3eb1b0_0  \r\n",
      "jinja2                    3.0.3              pyhd3eb1b0_0  \r\n",
      "jinja2-time               0.2.0              pyhd3eb1b0_3  \r\n",
      "jmespath                  0.10.0             pyhd3eb1b0_0  \r\n",
      "joblib                    1.1.0              pyhd3eb1b0_0  \r\n",
      "jpeg                      9e                   h7f8727e_0  \r\n",
      "jq                        1.6               h27cfd23_1000  \r\n",
      "json5                     0.9.6              pyhd3eb1b0_0  \r\n",
      "jsonschema                4.4.0            py39h06a4308_0  \r\n",
      "jupyter                   1.0.0            py39h06a4308_7  \r\n",
      "jupyter_client            6.1.12             pyhd3eb1b0_0  \r\n",
      "jupyter_console           6.4.0              pyhd3eb1b0_0  \r\n",
      "jupyter_contrib_core      0.3.3                      py_2    conda-forge\r\n",
      "jupyter_core              4.10.0           py39h06a4308_0  \r\n",
      "jupyter_nbextensions_configurator 0.4.1            py39hf3d152e_2    conda-forge\r\n",
      "jupyter_server            1.13.5             pyhd3eb1b0_0  \r\n",
      "jupyterlab                3.3.2              pyhd3eb1b0_0  \r\n",
      "jupyterlab_pygments       0.1.2                      py_0  \r\n",
      "jupyterlab_server         2.12.0           py39h06a4308_0  \r\n",
      "jupyterlab_widgets        1.0.0              pyhd3eb1b0_1  \r\n",
      "jxrlib                    1.1                  h7b6447c_2  \r\n",
      "keyring                   23.4.0           py39h06a4308_0  \r\n",
      "kiwisolver                1.4.2            py39h295c915_0  \r\n",
      "krb5                      1.19.2               hac12032_0  \r\n",
      "lazy-object-proxy         1.6.0            py39h27cfd23_0  \r\n",
      "lcms2                     2.12                 h3be6417_0  \r\n",
      "ld_impl_linux-64          2.38                 h1181459_1  \r\n",
      "lerc                      3.0                  h295c915_0  \r\n",
      "libaec                    1.0.4                he6710b0_1  \r\n",
      "libarchive                3.4.2                h62408e4_0  \r\n",
      "libcrc32c                 1.1.1                he6710b0_2  \r\n",
      "libcurl                   7.82.0               h0b77cf5_0  \r\n",
      "libdeflate                1.8                  h7f8727e_5  \r\n",
      "libedit                   3.1.20210910         h7f8727e_0  \r\n",
      "libev                     4.33                 h7f8727e_1  \r\n",
      "libffi                    3.3                  he6710b0_2  \r\n",
      "libgcc-ng                 11.2.0               h1234567_1  \r\n",
      "libgfortran-ng            7.5.0               ha8ba4b0_17  \r\n",
      "libgfortran4              7.5.0               ha8ba4b0_17  \r\n",
      "libgomp                   11.2.0               h1234567_1  \r\n",
      "libidn2                   2.3.2                h7f8727e_0  \r\n",
      "liblief                   0.11.5               h295c915_1  \r\n",
      "libllvm11                 11.1.0               h3826bc1_1  \r\n",
      "libnghttp2                1.46.0               hce63b2e_0  \r\n",
      "libpng                    1.6.37               hbc83047_0  \r\n",
      "libprotobuf               3.20.1               h4ff587b_0  \r\n",
      "libsodium                 1.0.18               h7b6447c_0  \r\n",
      "libspatialindex           1.9.3                h2531618_0  \r\n",
      "libssh2                   1.10.0               h8f2d780_0  \r\n",
      "libstdcxx-ng              11.2.0               h1234567_1  \r\n",
      "libtiff                   4.2.0                h85742a9_0  \r\n",
      "libunistring              0.9.10               h27cfd23_0  \r\n",
      "libuuid                   1.0.3                h7f8727e_2  \r\n",
      "libwebp                   1.2.2                h55f646e_0  \r\n",
      "libwebp-base              1.2.2                h7f8727e_0  \r\n",
      "libxcb                    1.15                 h7f8727e_0  \r\n",
      "libxml2                   2.9.14               h74e7548_0  \r\n",
      "libxslt                   1.1.35               h4e12654_0  \r\n",
      "libzopfli                 1.0.3                he6710b0_0  \r\n",
      "llvmlite                  0.38.0           py39h4ff587b_0  \r\n",
      "locket                    1.0.0            py39h06a4308_0  \r\n",
      "lxml                      4.8.0            py39h1f438cf_0  \r\n",
      "lz4                       3.1.3            py39h27cfd23_0  \r\n",
      "lz4-c                     1.9.3                h295c915_1  \r\n",
      "lzo                       2.10                 h7b6447c_2  \r\n",
      "markdown                  3.3.4            py39h06a4308_0  \r\n",
      "markupsafe                2.1.1            py39h7f8727e_0  \r\n",
      "matplotlib                3.5.1            py39h06a4308_1  \r\n",
      "matplotlib-base           3.5.1            py39ha18d171_1  \r\n",
      "matplotlib-inline         0.1.2              pyhd3eb1b0_2  \r\n",
      "mccabe                    0.6.1            py39h06a4308_1  \r\n",
      "mistune                   0.8.4           py39h27cfd23_1000  \r\n",
      "mkl                       2021.4.0           h06a4308_640  \r\n",
      "mkl-service               2.4.0            py39h7f8727e_0  \r\n",
      "mkl_fft                   1.3.1            py39hd3c417c_0  \r\n",
      "mkl_random                1.2.2            py39h51133e4_0  \r\n",
      "mock                      4.0.3              pyhd3eb1b0_0  \r\n",
      "mpc                       1.1.0                h10f8cd9_1  \r\n",
      "mpfr                      4.0.2                hb69a4c5_1  \r\n",
      "mpi                       1.0                       mpich  \r\n",
      "mpich                     3.3.2                hc856adb_0  \r\n",
      "mpmath                    1.2.1            py39h06a4308_0  \r\n",
      "msgpack-python            1.0.3            py39hd09550d_0  \r\n",
      "multidict                 5.2.0            py39h7f8727e_2  \r\n",
      "multipledispatch          0.6.0            py39h06a4308_0  \r\n",
      "munkres                   1.1.4                      py_0  \r\n",
      "mypy_extensions           0.4.3            py39h06a4308_1  \r\n",
      "nbclassic                 0.3.5              pyhd3eb1b0_0  \r\n",
      "nbclient                  0.5.13           py39h06a4308_0  \r\n",
      "nbconvert                 6.4.4            py39h06a4308_0  \r\n",
      "nbformat                  5.3.0            py39h06a4308_0  \r\n",
      "ncurses                   6.3                  h7f8727e_2  \r\n",
      "nest-asyncio              1.5.5            py39h06a4308_0  \r\n",
      "networkx                  2.7.1              pyhd3eb1b0_0  \r\n",
      "ninja                     1.10.2               h06a4308_5  \r\n",
      "ninja-base                1.10.2               hd09550d_5  \r\n",
      "nltk                      3.7                pyhd3eb1b0_0  \r\n",
      "nose                      1.3.7           pyhd3eb1b0_1008  \r\n",
      "notebook                  6.4.11           py39h06a4308_0  \r\n",
      "numba                     0.55.1           py39h51133e4_0  \r\n",
      "numexpr                   2.8.1            py39h6abb31d_0  \r\n",
      "numpy                     1.21.5           py39h6c91a56_3  \r\n",
      "numpy-base                1.21.5           py39ha15fc14_3  \r\n",
      "numpydoc                  1.2                pyhd3eb1b0_0  \r\n",
      "olefile                   0.46               pyhd3eb1b0_0  \r\n",
      "oniguruma                 6.9.7.1              h27cfd23_0  \r\n",
      "openjpeg                  2.4.0                h3ad879b_0  \r\n",
      "openpyxl                  3.0.9              pyhd3eb1b0_0  \r\n",
      "openssl                   1.1.1o               h7f8727e_0  \r\n",
      "packaging                 21.3               pyhd3eb1b0_0  \r\n",
      "pandas                    1.4.2            py39h295c915_0  \r\n",
      "pandocfilters             1.5.0              pyhd3eb1b0_0  \r\n",
      "panel                     0.13.0           py39h06a4308_0  \r\n",
      "param                     1.12.0             pyhd3eb1b0_0  \r\n",
      "parsel                    1.6.0            py39h06a4308_0  \r\n",
      "parso                     0.8.3              pyhd3eb1b0_0  \r\n",
      "partd                     1.2.0              pyhd3eb1b0_1  \r\n",
      "patchelf                  0.13                 h295c915_0  \r\n",
      "pathspec                  0.7.0                      py_0  \r\n",
      "patsy                     0.5.2            py39h06a4308_1  \r\n",
      "pcre                      8.45                 h295c915_0  \r\n",
      "pep8                      1.7.1            py39h06a4308_0  \r\n",
      "pexpect                   4.8.0              pyhd3eb1b0_3  \r\n",
      "pickleshare               0.7.5           pyhd3eb1b0_1003  \r\n",
      "pillow                    9.0.1            py39h22f2fdc_0  \r\n",
      "pip                       21.2.4           py39h06a4308_0  \r\n",
      "pkginfo                   1.8.2              pyhd3eb1b0_0  \r\n",
      "plotly                    5.6.0              pyhd3eb1b0_0  \r\n",
      "pluggy                    1.0.0            py39h06a4308_1  \r\n",
      "poyo                      0.5.0              pyhd3eb1b0_0  \r\n",
      "prometheus_client         0.13.1             pyhd3eb1b0_0  \r\n",
      "prompt-toolkit            3.0.20             pyhd3eb1b0_0  \r\n",
      "prompt_toolkit            3.0.20               hd3eb1b0_0  \r\n",
      "protego                   0.1.16                     py_0  \r\n",
      "protobuf                  3.20.1           py39h295c915_0  \r\n",
      "psutil                    5.8.0            py39h27cfd23_1  \r\n",
      "ptyprocess                0.7.0              pyhd3eb1b0_2  \r\n",
      "pure_eval                 0.2.2              pyhd3eb1b0_0  \r\n",
      "py                        1.11.0             pyhd3eb1b0_0  \r\n",
      "py-lief                   0.11.5           py39h295c915_1  \r\n",
      "pyasn1                    0.4.8              pyhd3eb1b0_0  \r\n",
      "pyasn1-modules            0.2.8                      py_0  \r\n",
      "pycodestyle               2.7.0              pyhd3eb1b0_0  \r\n",
      "pycosat                   0.6.3            py39h27cfd23_0  \r\n",
      "pycparser                 2.21               pyhd3eb1b0_0  \r\n",
      "pyct                      0.4.6            py39h06a4308_0  \r\n",
      "pycurl                    7.44.1           py39h8f2d780_1  \r\n",
      "pydispatcher              2.0.5            py39h06a4308_2  \r\n",
      "pydocstyle                6.1.1              pyhd3eb1b0_0  \r\n",
      "pyerfa                    2.0.0            py39h27cfd23_0  \r\n",
      "pyflakes                  2.3.1              pyhd3eb1b0_0  \r\n",
      "pygments                  2.11.2             pyhd3eb1b0_0  \r\n",
      "pyhamcrest                2.0.2              pyhd3eb1b0_2  \r\n",
      "pylint                    2.9.6            py39h06a4308_1  \r\n",
      "pyls-spyder               0.4.0              pyhd3eb1b0_0  \r\n",
      "pyodbc                    4.0.32           py39h295c915_1  \r\n",
      "pyopenssl                 22.0.0             pyhd3eb1b0_0  \r\n",
      "pyparsing                 3.0.4              pyhd3eb1b0_0  \r\n",
      "pyqt                      5.9.2            py39h2531618_6  \r\n",
      "pyrsistent                0.18.0           py39heee7806_0  \r\n",
      "pysocks                   1.7.1            py39h06a4308_0  \r\n",
      "pytables                  3.6.1            py39h77479fe_1  \r\n",
      "pytest                    7.1.2            py39h06a4308_0  \r\n",
      "python                    3.9.0                hdb3f193_2  \r\n",
      "python-dateutil           2.8.2              pyhd3eb1b0_0  \r\n",
      "python-fastjsonschema     2.15.1             pyhd3eb1b0_0  \r\n",
      "python-libarchive-c       2.9                pyhd3eb1b0_1  \r\n",
      "python-lsp-black          1.0.0              pyhd3eb1b0_0  \r\n",
      "python-lsp-jsonrpc        1.0.0              pyhd3eb1b0_0  \r\n",
      "python-lsp-server         1.2.4              pyhd3eb1b0_0  \r\n",
      "python-slugify            5.0.2              pyhd3eb1b0_0  \r\n",
      "python-snappy             0.6.0            py39h2531618_3  \r\n",
      "python_abi                3.9                      2_cp39    conda-forge\r\n",
      "pytorch                   1.10.2          cpu_py39hfa7516b_0  \r\n",
      "pytz                      2021.3             pyhd3eb1b0_0  \r\n",
      "pyviz_comms               2.0.2              pyhd3eb1b0_0  \r\n",
      "pywavelets                1.3.0            py39h7f8727e_0  \r\n",
      "pyxdg                     0.27               pyhd3eb1b0_0  \r\n",
      "pyyaml                    6.0              py39h7f8727e_1  \r\n",
      "pyzmq                     22.3.0           py39h295c915_2  \r\n",
      "qdarkstyle                3.0.2              pyhd3eb1b0_0  \r\n",
      "qstylizer                 0.1.10             pyhd3eb1b0_0  \r\n",
      "qt                        5.9.7                h5867ecd_1  \r\n",
      "qtawesome                 1.0.3              pyhd3eb1b0_0  \r\n",
      "qtconsole                 5.3.0              pyhd3eb1b0_0  \r\n",
      "qtpy                      2.0.1              pyhd3eb1b0_0  \r\n",
      "queuelib                  1.5.0            py39h06a4308_0  \r\n",
      "readline                  8.1.2                h7f8727e_1  \r\n",
      "regex                     2022.3.15        py39h7f8727e_0  \r\n",
      "requests                  2.27.1             pyhd3eb1b0_0  \r\n",
      "requests-file             1.5.1              pyhd3eb1b0_0  \r\n",
      "ripgrep                   12.1.1                        0  \r\n",
      "rope                      0.22.0             pyhd3eb1b0_0  \r\n",
      "rsa                       4.7.2              pyhd3eb1b0_1  \r\n",
      "rtree                     0.9.7            py39h06a4308_1  \r\n",
      "ruamel_yaml               0.15.100         py39h27cfd23_0  \r\n",
      "s3transfer                0.6.0            py39h06a4308_0  \r\n",
      "scikit-image              0.19.2           py39h51133e4_0  \r\n",
      "scikit-learn              1.0.2            py39h51133e4_1  \r\n",
      "scikit-learn-intelex      2021.5.0         py39h06a4308_0  \r\n",
      "scipy                     1.7.3            py39hc147768_0  \r\n",
      "scrapy                    2.6.1            py39h06a4308_0  \r\n",
      "seaborn                   0.11.2             pyhd3eb1b0_0  \r\n",
      "secretstorage             3.3.1            py39h06a4308_0  \r\n",
      "send2trash                1.8.0              pyhd3eb1b0_1  \r\n",
      "service_identity          18.1.0             pyhd3eb1b0_1  \r\n",
      "setuptools                61.2.0           py39h06a4308_0  \r\n",
      "shap                      0.39.0           py39h51133e4_0  \r\n",
      "shapely                   1.7.1            py39h1728cc4_0  \r\n",
      "sip                       4.19.13          py39h295c915_0  \r\n",
      "six                       1.16.0             pyhd3eb1b0_1  \r\n",
      "slicer                    0.0.7              pyhd3eb1b0_0  \r\n",
      "smart_open                5.2.1            py39h06a4308_0  \r\n",
      "snappy                    1.1.9                h295c915_0  \r\n",
      "sniffio                   1.2.0            py39h06a4308_1  \r\n",
      "snowballstemmer           2.2.0              pyhd3eb1b0_0  \r\n",
      "sortedcollections         2.1.0              pyhd3eb1b0_0  \r\n",
      "sortedcontainers          2.4.0              pyhd3eb1b0_0  \r\n",
      "soupsieve                 2.3.1              pyhd3eb1b0_0  \r\n",
      "sphinx                    4.4.0              pyhd3eb1b0_0  \r\n",
      "sphinxcontrib-applehelp   1.0.2              pyhd3eb1b0_0  \r\n",
      "sphinxcontrib-devhelp     1.0.2              pyhd3eb1b0_0  \r\n",
      "sphinxcontrib-htmlhelp    2.0.0              pyhd3eb1b0_0  \r\n",
      "sphinxcontrib-jsmath      1.0.1              pyhd3eb1b0_0  \r\n",
      "sphinxcontrib-qthelp      1.0.3              pyhd3eb1b0_0  \r\n",
      "sphinxcontrib-serializinghtml 1.1.5              pyhd3eb1b0_0  \r\n",
      "spyder                    5.1.5            py39h06a4308_1  \r\n",
      "spyder-kernels            2.1.3            py39h06a4308_0  \r\n",
      "sqlalchemy                1.4.32           py39h7f8727e_0  \r\n",
      "sqlite                    3.38.3               hc218d9a_0  \r\n",
      "stack_data                0.2.0              pyhd3eb1b0_0  \r\n",
      "statsmodels               0.13.2           py39h7f8727e_0  \r\n",
      "sympy                     1.10.1           py39h06a4308_0  \r\n",
      "tabulate                  0.8.9            py39h06a4308_0  \r\n",
      "tbb                       2021.5.0             hd09550d_0  \r\n",
      "tbb4py                    2021.5.0         py39hd09550d_0  \r\n",
      "tblib                     1.7.0              pyhd3eb1b0_0  \r\n",
      "tenacity                  8.0.1            py39h06a4308_0  \r\n",
      "terminado                 0.13.1           py39h06a4308_0  \r\n",
      "testpath                  0.5.0              pyhd3eb1b0_0  \r\n",
      "text-unidecode            1.3                pyhd3eb1b0_0  \r\n",
      "textdistance              4.2.1              pyhd3eb1b0_0  \r\n",
      "threadpoolctl             2.2.0              pyh0d69192_0  \r\n",
      "three-merge               0.1.1              pyhd3eb1b0_0  \r\n",
      "tifffile                  2021.7.2           pyhd3eb1b0_2  \r\n",
      "tinycss                   0.4             pyhd3eb1b0_1002  \r\n",
      "tk                        8.6.12               h1ccaba5_0  \r\n",
      "tldextract                3.2.0              pyhd3eb1b0_0  \r\n",
      "toml                      0.10.2             pyhd3eb1b0_0  \r\n",
      "tomli                     1.2.2              pyhd3eb1b0_0  \r\n",
      "toolz                     0.11.2             pyhd3eb1b0_0  \r\n",
      "tornado                   6.1              py39h27cfd23_0  \r\n",
      "tqdm                      4.64.0           py39h06a4308_0  \r\n",
      "traitlets                 5.1.1              pyhd3eb1b0_0  \r\n",
      "twisted                   22.2.0           py39h7f8727e_0  \r\n",
      "typed-ast                 1.4.3            py39h7f8727e_1  \r\n",
      "typing-extensions         4.1.1                hd3eb1b0_0  \r\n",
      "typing_extensions         4.1.1              pyh06a4308_0  \r\n",
      "tzdata                    2022a                hda174b7_0  \r\n",
      "ujson                     5.1.0            py39h295c915_0  \r\n",
      "unidecode                 1.2.0              pyhd3eb1b0_0  \r\n",
      "unixodbc                  2.3.9                h7b6447c_0  \r\n",
      "urllib3                   1.26.9           py39h06a4308_0  \r\n",
      "w3lib                     1.21.0             pyhd3eb1b0_0  \r\n",
      "watchdog                  2.1.6            py39h06a4308_0  \r\n",
      "wcwidth                   0.2.5              pyhd3eb1b0_0  \r\n",
      "webencodings              0.5.1            py39h06a4308_1  \r\n",
      "websocket-client          0.58.0           py39h06a4308_4  \r\n",
      "werkzeug                  2.0.3              pyhd3eb1b0_0  \r\n",
      "wget                      1.21.3               h0b77cf5_0  \r\n",
      "wheel                     0.37.1             pyhd3eb1b0_0  \r\n",
      "widgetsnbextension        3.5.2            py39h06a4308_0  \r\n",
      "wrapt                     1.12.1           py39he8ac12f_1  \r\n",
      "wurlitzer                 3.0.2            py39h06a4308_0  \r\n",
      "xarray                    0.20.1             pyhd3eb1b0_1  \r\n",
      "xlrd                      2.0.1              pyhd3eb1b0_0  \r\n",
      "xlsxwriter                3.0.3              pyhd3eb1b0_0  \r\n",
      "xz                        5.2.5                h7f8727e_1  \r\n",
      "yaml                      0.2.5                h7b6447c_0  \r\n",
      "yapf                      0.31.0             pyhd3eb1b0_0  \r\n",
      "yarl                      1.6.3            py39h27cfd23_0  \r\n",
      "zeromq                    4.3.4                h2531618_0  \r\n",
      "zfp                       0.5.5                h295c915_6  \r\n",
      "zict                      2.0.0              pyhd3eb1b0_0  \r\n",
      "zipp                      3.8.0            py39h06a4308_0  \r\n",
      "zlib                      1.2.12               h7f8727e_2  \r\n",
      "zope                      1.0              py39h06a4308_1  \r\n",
      "zope.interface            5.4.0            py39h7f8727e_0  \r\n",
      "zstd                      1.4.9                haebb681_0  \r\n"
     ]
    }
   ],
   "source": [
    "!conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_in_file(model_name, accuracy):\n",
    "    model_file = open(\"model_details.txt\",\"a\")\n",
    "    model_file.write(model_name + \" -> accuracy : \" + str(accuracy) + \"\\n\" )\n",
    "    model_file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:   \n",
    "    def warn(*args, **kwargs):\n",
    "        pass\n",
    "    import warnings\n",
    "    warnings.warn = warn\n",
    "\n",
    "\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import torch as t\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "feature_indices_to_consider = list(range(23))#list(range(35)) #[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 18, 20, 22]\n",
    "hidden = 4\n",
    "class simple_model(nn.Module):\n",
    "    def __init__(self, num_features=FEATURE_MATRIX.shape[1], hidden_dim=32*4, drop_probab=0.3):\n",
    "        super(simple_model, self).__init__()\n",
    "        \n",
    "        ####\n",
    "        self.drop_probab = drop_probab\n",
    "        self.dropout_feature = nn.Dropout(p=0.3)\n",
    "        self.fc1 = nn.Linear(num_features, hidden_dim)\n",
    "        self.dropout1 = nn.Dropout(p=self.drop_probab)\n",
    "        num_hidden = hidden\n",
    "        self.fc_hidden = nn.ModuleList([nn.Linear(hidden_dim, hidden_dim) for i in range(num_hidden)])\n",
    "        self.dropout_hidden = nn.ModuleList([nn.Dropout(p=0.0) for i in range(num_hidden)])\n",
    "        self.fc2 = nn.Linear(hidden_dim, 8)\n",
    "        self.dropout2 = nn.Dropout(p=0.3)\n",
    "        self.outLayer = nn.Linear(8, 1)\n",
    "#         self.softmax = nn.Softmax(-1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.num_hidden = num_hidden\n",
    "        ####\n",
    "\n",
    "    def forward(self, features):\n",
    "        features = self.dropout_feature(features)\n",
    "        features = self.fc1(features)\n",
    "        features = self.dropout1(features)\n",
    "        for i in range(self.num_hidden):\n",
    "            features = self.fc_hidden[i](features)\n",
    "            features = self.dropout_hidden[i](features)\n",
    "        features = self.fc2(features)\n",
    "        features = self.dropout2(features)\n",
    "        logit = self.outLayer(features)\n",
    "#         print(features.shape, features)\n",
    "        probab = self.sigmoid(logit)\n",
    "        return probab\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    def warn(*args, **kwargs):\n",
    "        pass\n",
    "    import warnings\n",
    "    warnings.warn = warn\n",
    "\n",
    "\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import torch as t\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# feature_indices_to_consider = list(range(23))#list(range(35)) #[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 18, 20, 22]\n",
    "# naeem modified\n",
    "feature_indices_to_consider = list(range(num_features))#list(range(35)) #[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 18, 20, 22]\n",
    "\n",
    "\n",
    "class simple_model(nn.Module):\n",
    "    def __init__(self, num_features=FEATURE_MATRIX.shape[1], hidden_dim=32, drop_probab=.8):\n",
    "        super(simple_model, self).__init__()\n",
    "        \n",
    "        ####\n",
    "        num_hidden = hidden\n",
    "        hidden_dim = hidden_dimension\n",
    "        self.fc1 = nn.Linear(num_features, hidden_dim)\n",
    "        self.fc_hidden = nn.ModuleList([nn.Linear(hidden_dim, hidden_dim) for i in range(num_hidden)])\n",
    "        self.fc2 = nn.Linear(hidden_dim, 8)\n",
    "        self.outLayer = nn.Linear(8, 1)\n",
    "#         self.softmax = nn.Softmax(-1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.num_hidden = num_hidden\n",
    "        self.drop_probab = drop_probab\n",
    "        self.dropout = nn.functional.dropout\n",
    "        ####\n",
    "\n",
    "    def forward(self, features):\n",
    "        features = self.fc1(features)\n",
    "        features = self.dropout(features, p=self.drop_probab)\n",
    "        for i in range(self.num_hidden):\n",
    "            features = self.fc_hidden[i](features)\n",
    "        features = self.fc2(features)\n",
    "        features = self.dropout(features, p=self.drop_probab)\n",
    "        logit = self.outLayer(features)\n",
    "#         print(features.shape, features)\n",
    "        probab = self.sigmoid(logit)\n",
    "        return probab\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1158\n",
      "[['126_S_0865', 1], ['041_S_4974', 1]]\n",
      "500 500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_Samples = json.load(open('Final_Samples.json', 'r')) \n",
    "print(len(Final_Samples))\n",
    "print(Final_Samples[:2])\n",
    "positive_samples = Final_Samples[:654] # Final_Samples[654:]\n",
    "positive_samples = Final_Samples[:654]\n",
    "negative_samples = Final_Samples[654:]\n",
    "random_seed = None\n",
    "if random_seed is not None: \n",
    "    random.seed(random_seed * 2)\n",
    "random.shuffle(positive_samples)\n",
    "random.shuffle(negative_samples)\n",
    "Final_Samples = positive_samples[:500] + negative_samples[:500]\n",
    "print(len([x[1] for x in Final_Samples if x[1] == 1]), len([x[1] for x in Final_Samples if x[1] == 0]))\n",
    "Final_Samples = np.array(Final_Samples)\n",
    "Final_Samples.shape\n",
    "# Final_Samples.reshape(10, -1, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "simple_model(\n",
       "  (fc1): Linear(in_features=33, out_features=32, bias=True)\n",
       "  (fc_hidden): ModuleList(\n",
       "    (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (3): Linear(in_features=32, out_features=32, bias=True)\n",
       "  )\n",
       "  (fc2): Linear(in_features=32, out_features=8, bias=True)\n",
       "  (outLayer): Linear(in_features=8, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model(num_features=len(feature_indices_to_consider))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "class dataSet(data.Dataset):\n",
    "    def __init__(self, Final_Samples, feature_matrix, usable_samples_ADNI, feature_indices_to_consider=feature_indices_to_consider):\n",
    "        super(dataSet, self).__init__()  \n",
    "        self.data_len = len(Final_Samples)\n",
    "        self.usable_samples_ADNI = usable_samples_ADNI\n",
    "        self.Final_Samples = Final_Samples\n",
    "        self.feature_indices_to_consider = feature_indices_to_consider\n",
    "        self.feature_matrix = feature_matrix[:, self.feature_indices_to_consider]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        features = torch.from_numpy(self.feature_matrix[self.usable_samples_ADNI[self.Final_Samples[index][0]]]).float()\n",
    "        label = torch.tensor([float(self.Final_Samples[index][1])]).float()\n",
    "        return features, label\n",
    "    \n",
    "    def update_prs_features(self, mean, std):\n",
    "        self.feature_matrix = (self.feature_matrix - mean) / std\n",
    "        \n",
    "    def get_mean_std(self):\n",
    "        mean = self.feature_matrix.mean(0)\n",
    "        std = self.feature_matrix.std(0)\n",
    "        return mean, std\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1816, 33)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def random_samples(total_folds, random_seed=None):\n",
    "    Final_Samples = json.load(open('Final_Samples.json', 'r')) \n",
    "    positive_samples = Final_Samples[:654]\n",
    "    negative_samples = Final_Samples[654:]\n",
    "    if random_seed is not None: \n",
    "        random.seed(random_seed * 2)\n",
    "    random.shuffle(positive_samples)\n",
    "    random.shuffle(negative_samples)\n",
    "    Final_Samples = positive_samples[:500] + negative_samples[:500]\n",
    "    if random_seed is not None: \n",
    "        random.seed(random_seed)\n",
    "    random.shuffle(Final_Samples)\n",
    "    Final_Samples = np.array(Final_Samples)\n",
    "    N_splits = Final_Samples.reshape(total_folds, -1, 2)\n",
    "    return N_splits\n",
    "\n",
    "def generate_datasets(N_splits, fold_num, random_seed):\n",
    "    test_samples = N_splits[fold_num:fold_num+1].reshape([-1, 2])\n",
    "    train_samples = np.concatenate([N_splits[0:fold_num],N_splits[fold_num+1:]], 0).reshape([-1, 2]).tolist()\n",
    "    if random_seed is not None: \n",
    "        random.seed(random_seed * 3)\n",
    "    random.shuffle(train_samples)\n",
    "    train_samples = np.array(train_samples)\n",
    "    split_pos = int(train_samples.shape[0] * 1.) \n",
    "    #split_pos = int(train_samples.shape[0] * .8) \n",
    "#     print(train_samples.shape, split_pos, train_samples.shape[0])\n",
    "    train_samples, val_samples = train_samples[:split_pos], train_samples[split_pos:]\n",
    "    train_set = dataSet(Final_Samples=train_samples, \n",
    "                        feature_matrix=FEATURE_MATRIX, \n",
    "                        usable_samples_ADNI=usable_samples_ADNI)\n",
    "    val_set = dataSet(Final_Samples=val_samples, \n",
    "                      feature_matrix=FEATURE_MATRIX, \n",
    "                      usable_samples_ADNI=usable_samples_ADNI)\n",
    "    test_set = dataSet(Final_Samples=test_samples, \n",
    "                      feature_matrix=FEATURE_MATRIX, \n",
    "                      usable_samples_ADNI=usable_samples_ADNI)\n",
    "    mean, std = train_set.get_mean_std()\n",
    "    train_set.update_prs_features(mean, std)\n",
    "    val_set.update_prs_features(mean, std)\n",
    "    test_set.update_prs_features(mean, std)\n",
    "    \n",
    "    return train_set, val_set, test_set\n",
    "\n",
    "def generate_loader(train_set, val_set, test_set, num_workers):\n",
    "    train_batch_size = train_set.__len__()\n",
    "    val_batch_size = val_set.__len__()\n",
    "    test_batch_size = test_set.__len__()\n",
    "    train_loader = torch.utils.data.DataLoader(train_set,\n",
    "                                              batch_size=train_batch_size,\n",
    "                                              shuffle=True,\n",
    "                                              pin_memory=(torch.cuda.is_available()),\n",
    "                                              num_workers=num_workers)\n",
    "    val_loader = torch.utils.data.DataLoader(val_set,\n",
    "                                              batch_size=val_batch_size,\n",
    "                                              shuffle=False,\n",
    "                                              pin_memory=(torch.cuda.is_available()),\n",
    "                                              num_workers=num_workers)\n",
    "    test_loader = torch.utils.data.DataLoader(test_set,\n",
    "                                              batch_size=test_batch_size,\n",
    "                                              shuffle=False,\n",
    "                                              pin_memory=(torch.cuda.is_available()),\n",
    "                                              num_workers=num_workers)\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "train_set, val_set, test_set = generate_datasets(N_splits=random_samples(total_folds=10, random_seed=0), fold_num=0, random_seed=0)\n",
    "val_set.feature_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1816\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, precision_recall_curve, auc\n",
    "\n",
    "\n",
    "def epoch(model, optimizer, criterion, is_training, loader):\n",
    "    pred = []\n",
    "    true = []\n",
    "    total_loss = 0.\n",
    "    \n",
    "    for batch_idx, (features, label) in enumerate(loader):\n",
    "        features = torch.autograd.Variable(features.to(DEVICE).float())\n",
    "        label = torch.autograd.Variable(label.to(DEVICE).float())\n",
    "#         print(features.shape, label.shape)\n",
    "        probab = model(features)\n",
    "    \n",
    "        if is_training:  \n",
    "            loss = criterion(probab, label)\n",
    "            ## compute gradient and do SGD step \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "#             print(batch_idx, ':', loss) \n",
    "        pred += probab.detach().cpu().numpy().tolist()\n",
    "        true += label.detach().cpu().numpy().tolist()\n",
    "    \n",
    "    pred, true, total_loss = np.array(pred).reshape([-1]), np.array(true).reshape([-1]), total_loss\n",
    "    pred_binary = (pred > .5).astype(float)\n",
    "#     precision, recall, fscore, support = precision_recall_fscore_support(true, pred_binary)\n",
    "#     auroc = roc_auc_score(true, pred)\n",
    "#     p, r, thresholds = precision_recall_curve(true, pred)\n",
    "#     auprc = auc(r, p)\n",
    "    acc = (pred_binary==true).mean()\n",
    "    \n",
    "#     return precision[1], recall[1], fscore[1], support, auroc, auprc, acc, total_loss, pred, pred_binary, true\n",
    "    return None, None, None, None, None, None, acc, total_loss, pred, pred_binary, true\n",
    "    \n",
    "import json\n",
    "import pandas as pd\n",
    "GWAS_ID = 'ieu-b-25'\n",
    "usable_samples_ADNI = pd.read_csv(f'./PRSice_output/{GWAS_ID}/{GWAS_ID}.best', ' ')['IID'].to_numpy().tolist()\n",
    "usable_samples_ADNI = {'_'.join(sample.split('_')[1:]):idx for idx,sample in enumerate(usable_samples_ADNI)}\n",
    "# usable_samples_ADNI = {sample:idx for idx,sample in enumerate(usable_samples_ADNI)}\n",
    "print(len( usable_samples_ADNI ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "Shape of usable features :  (1000, 33)\n",
      "Length of usable labels :  1000\n",
      "Usable Features :  tensor([[ 0.9406, -0.7234, -0.2323,  0.5206, -2.5076, -1.4637,  1.8379, -0.2694,\n",
      "          0.1493,  0.4971,  1.1003,  1.8472,  0.7541,  0.7190,  0.1785,  0.2353,\n",
      "          0.5303,  0.4526, -1.4365,  1.2019,  1.3641, -0.6168, -0.0276,  1.2361,\n",
      "          0.9771, -2.6741,  0.7302, -0.1066,  0.9238,  0.3654,  0.7977,  0.6525,\n",
      "          0.4663],\n",
      "        [ 0.7608,  0.1073,  0.2473, -0.0651, -0.7541, -0.1898,  0.4950,  0.2483,\n",
      "          1.5045, -0.4754,  0.9235,  2.0243,  1.9377, -0.2021,  0.0032, -0.1451,\n",
      "         -0.1105, -1.5657,  0.3656, -0.1631,  0.9855, -1.2865, -0.4987,  1.5060,\n",
      "          2.2429, -1.1307,  0.9938, -0.4407,  1.6337, -0.7865, -0.4463,  0.6915,\n",
      "          0.1495]])\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "import shap\n",
    "from copy import deepcopy\n",
    "\n",
    "print(len(Final_Samples))\n",
    "usable_indices = [( usable_samples_ADNI[Final_Samples[i][0]] if ( Final_Samples[i][0] in usable_samples_ADNI.keys() ) else None ) for i in range(len(Final_Samples))]\n",
    "print(len(usable_indices))\n",
    "# print(usable_indices)\n",
    "usable_features = FEATURE_MATRIX[usable_indices][:, feature_indices_to_consider]\n",
    "print(\"Shape of usable features : \", usable_features.shape)\n",
    "usable_labels = np.array([float(Final_Samples[i][1]) for i in range(len(Final_Samples))])\n",
    "print(\"Length of usable labels : \", len(usable_labels))\n",
    "usable_features = torch.autograd.Variable(torch.from_numpy(usable_features)).to(DEVICE).float()\n",
    "\n",
    "print(\"Usable Features : \", usable_features[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NF:33\n",
      "\n",
      "#F10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|                                                  | 5/10 [01:29<01:30, 18.11s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "GENERATE_SHAP = True\n",
    "total_epochs = 500 #250(ideal)\n",
    "num_features_list = [usable_features.shape[1]]\n",
    "# random_integers = [2, 6, 108, 90, 5]\n",
    "random_integers = [90]#, 92, 0, 87, 73, 82, 54]\n",
    "\n",
    "folds_list = [10]#[37*2]\n",
    "\n",
    "avg_val_acc = []\n",
    "\n",
    "shap_values_list = []\n",
    "for num_features in num_features_list:\n",
    "    print(f'NF:{num_features}')\n",
    "    global_best_acc_val = 0.\n",
    "    for total_folds in folds_list:\n",
    "        print(f'\\n#F{total_folds}')\n",
    "        for random_seed in random_integers:\n",
    "            N_splits = random_samples(total_folds=total_folds, random_seed=random_seed)\n",
    "            accuracies = []\n",
    "            accuracies_val = []\n",
    "            temp_shap_values = np.zeros(usable_features.shape)\n",
    "            for fold_num in tqdm(range(total_folds)):\n",
    "    #             print(f'fold-{fold_num}:')\n",
    "#                 train_set, val_set, test_set = generate_datasets(N_splits=N_splits, fold_num=fold_num, random_seed=random_seed)\n",
    "                train_set, _, test_set = generate_datasets(N_splits=N_splits, fold_num=fold_num, random_seed=random_seed)\n",
    "                val_set = test_set        \n",
    "                train_loader, val_loader, test_loader = generate_loader(train_set=train_set, val_set=val_set, \n",
    "                                                                        test_set=test_set, num_workers=0)\n",
    "                model = simple_model(num_features=usable_features.shape[1], hidden_dim=32)\n",
    "                model = model.to(DEVICE)\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "                criterion = torch.nn.BCEWithLogitsLoss() \n",
    "                best_acc_val = 0.\n",
    "                model_best = None\n",
    "                for epoch_num in range(total_epochs):\n",
    "                    model.train()\n",
    "#                     model.drop_probab=.8\n",
    "                    precision, recall, fscore, support, auroc, auprc, acc_train, total_loss, pred, pred_binary, true = epoch(model=model, optimizer=optimizer, \n",
    "                                                                                             criterion=criterion, is_training=True, \n",
    "                                                                                             loader=train_loader)\n",
    "                    model.eval()\n",
    "#                     model.drop_probab=.0\n",
    "                    precision, recall, fscore, support, auroc, auprc, acc_val, total_loss, pred, pred_binary, true = epoch(model=model, \n",
    "                                                                                             optimizer=optimizer, \n",
    "                                                                                             criterion=criterion, is_training=False, \n",
    "                                                                                             loader=val_loader)\n",
    "                    if acc_val > best_acc_val:\n",
    "                        best_acc_val = acc_val\n",
    "                        if acc_val > global_best_acc_val:\n",
    "                            global_best_acc_val = acc_val\n",
    "    #                         print('global updated!')\n",
    "                        torch.save(model.state_dict(), 'PRS_model.pt')\n",
    "    #                     print(f'#F:{total_folds}| seed:{random_seed}, fold:{fold_num}, epoch:{epoch_num} -> local:{best_acc_val}, global:{global_best_acc_val}')  \n",
    "#                     if epoch_num + 1 == total_epochs:\n",
    "#     #                     print(f'LAST_Epoch:{epoch_num}, train_acc:{acc_train}, val_acc:{acc_val}, local_best:{best_acc_val}, global_best:{global_best_acc_val}')\n",
    "#                         pass\n",
    "                model_best = simple_model(num_features=usable_features.shape[1], hidden_dim=32, drop_probab=.0)\n",
    "                model_best.load_state_dict(torch.load('PRS_model.pt'))\n",
    "                model_best = model_best.to(DEVICE)\n",
    "                model_best.eval()\n",
    "                precision, recall, fscore, support, auroc, auprc, acc_test, total_loss, pred, pred_binary, true = epoch(model=model_best, \n",
    "                                                                                         optimizer=optimizer, \n",
    "                                                                                         criterion=criterion, is_training=False, \n",
    "                                                                                         loader=val_loader)\n",
    "                accuracies += [acc_test]\n",
    "                accuracies_val += [best_acc_val]\n",
    "                \n",
    "#                 print(fold_num, ':', accuracies)\n",
    "                if GENERATE_SHAP:\n",
    "                    explainer = shap.GradientExplainer(model_best.to(DEVICE), usable_features,\n",
    "                                                       batch_size=usable_features.shape[0]) #https://shap-lrjball.readthedocs.io/en/latest/generated/shap.KernelExplainer.html\n",
    "                    shap_values = explainer.shap_values(usable_features, nsamples=100)\n",
    "#                     print(\"Shap values : \", shap_values)\n",
    "                    temp_shap_values += shap_values \n",
    "            if GENERATE_SHAP:\n",
    "                temp_shap_values /= total_folds\n",
    "                shap_values_list += [temp_shap_values] \n",
    "            print(f'random_seed:{random_seed}:', np.mean(accuracies), np.std(accuracies), \n",
    "                  np.mean(accuracies_val), np.std(accuracies_val), 'train acc:', acc_train)\n",
    "            avg_val_acc += [np.mean(accuracies_val)]\n",
    "            \n",
    "    print(f'global_best_acc_val:{global_best_acc_val}')\n",
    "# usable_features = usable_features.cpu().detach().numpy().astype(np.float64)\n",
    "avg_val_acc = np.array(avg_val_acc)\n",
    "print(avg_val_acc.max(), avg_val_acc.min(), avg_val_acc.mean(), avg_val_acc.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_in_file(\"Neural Network with \" + str(hidden) + \" layers\", global_best_acc_val)\n",
    "# save_in_file(\"Neural Network with \" + str(hidden) + \" layers\", global_best_acc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usable_features = usable_features.cpu().detach().numpy().astype(np.float64)\n",
    "print(np.array([.67699, 0.685, 0.694, 0.687, 0.695, 0.693, 0.6849999, 0.683]).mean())\n",
    "print(np.array([0.6809999999999999, 0.6889999999999998, 0.7060000000000001, 0.6910000000000001, 0.701, 0.6740000000000002, 0.6869999999999999, 0.6869999999999999]).mean())\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( shap_values_list )\n",
    "\n",
    "import pickle\n",
    "pickle.dump(shap_values_list, open('shap_values_list.pkl', 'wb'))\n",
    "shap_values = np.mean(shap_values_list, axis=0)\n",
    "shap_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# print( shap_values_list )\n",
    "# print the JS visualization code to the notebook\n",
    "shap.initjs()\n",
    "# print(shap_values[0, :])\n",
    "# print(usable_features[0, :])\n",
    "# shap.summary_plot(shap_values[:, :], usable_features[:, :])\n",
    "\n",
    "shap.force_plot(.5, shap_values[0,:], usable_features[0, :], link = \"logit\", matplotlib = True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shap.force_plot(.5, shap_values[:,:], usable_features[:, :], link=\"logit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traits[20]\n",
    "# shap_values = np.sum(shap_values_list)\n",
    "# usable_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GWAS_IDS = ['ieu-b-109', 'ukb-b-12064', 'ukb-b-13806', 'ukb-d-20405_0', 'ieu-b-38', 'ukb-b-6134', 'ieu-b-110', 'ukb-b-17627', 'ukb-b-19953', 'ukb-b-8476', 'ukb-d-20405_1', 'ukb-d-20405_2', 'ukb-b-2209', 'ukb-b-4424', 'ukb-b-7663', \n",
    "#             'ukb-b-18275', 'ukb-b-770', 'met-d-Total_C', 'ieu-b-25', 'ieu-b-111', 'ukb-b-3957', 'ieu-b-39', 'ukb-b-6324',\n",
    "#            'ukb-a-257','ukb-b-14699','ukb-b-323']\n",
    "# # new added\n",
    "# # ukb-a-257 Hearing difficulty/problems: Yes\n",
    "# # ukb-b-14699 Illnesses of mother: Alzheimer's disease/dementia\n",
    "# # ukb-b-323 Illnesses of father: Alzheimer's disease/dementia\n",
    "GWAS_IDS=[\n",
    "'ukb-b-2209',\n",
    "'ieu-b-39',\n",
    "'ukb-b-4424',\n",
    "'ukb-b-7663',\n",
    "'ukb-d-20405_2',\n",
    "'ukb-b-6324',\n",
    "'ieu-b-111',\n",
    "'ukb-b-13806',\n",
    "'ieu-b-25',\n",
    "'ukb-d-20405_1',\n",
    "'ukb-b-14699',\n",
    "'ukb-b-770',\n",
    "'ieu-b-109',\n",
    "'ukb-d-20405_0',\n",
    "'ieu-b-110',\n",
    "'ukb-b-17627',\n",
    "'ukb-a-257',\n",
    "'ieu-b-38',\n",
    "'ukb-b-18275',\n",
    "'ukb-b-3957'   \n",
    "]\n",
    "\n",
    "# traits = ['HDL cholesterol', 'Non-cancer illness code, self-reported: depression', \n",
    "#           'Non-cancer illness code, self-reported: type 2 diabetes', 'Ever had known person concerned about, or recommend reduction of, alcohol consumption: No', \n",
    "#           'systolic blood pressure', 'Age completed full time education', 'LDL cholesterol', \n",
    "#           'Non-oily fish intake', 'Body mass index (BMI)', 'Loneliness, isolation', \n",
    "#           'Ever had known person concerned about, or recommend reduction of, alcohol consumption: Yes, but not in the last year', \n",
    "#           'Ever had known person concerned about, or recommend reduction of, alcohol consumption: Yes, during the last year',\n",
    "#           'Oily fish intake', 'Sleep duration', 'Types of physical activity in last 4 weeks: Strenuous sports', \n",
    "#           'Hearing difficulty/problems with background noise', 'Other meat intake', 'Total cholesterol', \n",
    "#           'Cigarettes per Day', 'triglycerides', 'Sleeplessness / insomnia', 'diastolic blood pressure', \n",
    "#           'Processed meat intake','Hearing difficulty/problems: Yes','Illnesses of mother: Alzheimer\\'s disease/dementia','Illnesses of father: Alzheimer\\'s di\n",
    "\n",
    "\n",
    "\n",
    "# for GWAS_ID in GWAS_IDS:\n",
    "#     print(GWAS_ID)\n",
    "# traits = ['HDL cholesterol', 'Non-cancer illness code, self-reported: depression', \n",
    "#           'Non-cancer illness code, self-reported: type 2 diabetes', 'Ever had known person concerned about, or recommend reduction of, alcohol consumption: No', \n",
    "#           'systolic blood pressure', 'Age completed full time education', 'LDL cholesterol', \n",
    "#           'Non-oily fish intake', 'Body mass index (BMI)', 'Loneliness, isolation', \n",
    "#           'Ever had known person concerned about, or recommend reduction of, alcohol consumption: Yes, but not in the last year', \n",
    "#           'Ever had known person concerned about, or recommend reduction of, alcohol consumption: Yes, during the last year',\n",
    "#           'Oily fish intake', 'Sleep duration', 'Types of physical activity in last 4 weeks: Strenuous sports', \n",
    "#           'Hearing difficulty/problems with background noise', 'Other meat intake', 'Total cholesterol', \n",
    "#           'Cigarettes per Day', 'triglycerides', 'Sleeplessness / insomnia', 'diastolic blood pressure', \n",
    "#           'Processed meat intake','Hearing difficulty/problems: Yes','Illnesses of mother: Alzheimer\\'s disease/dementia','Illnesses of father: Alzheimer\\'s disease/dementia']\n",
    "\n",
    "# # https://shap-lrjball.readthedocs.io/en/latest/generated/shap.summary_plot.html?highlight=beeswarm#shap.summary_plot\n",
    "# # usable_features_std = (usable_features - usable_features.mean(0))/usable_features.std(0)\n",
    "# shap.summary_plot(shap_values, features=usable_features, feature_names=traits, plot_type='dot', max_display=len(traits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# in place of json straight took it hardcoded\n",
    "\n",
    "all_traits = json.load(open('traits_map.json', 'r'))\n",
    "# print(all_traits)\n",
    "GWAS_IDS = list(all_traits)\n",
    "# print(GWAS_IDS)\n",
    "traits = [all_traits[x] for x in all_traits]\n",
    "print(len(traits))\n",
    "# for trait in traits:\n",
    "#     print(trait)\n",
    "# https://shap-lrjball.readthedocs.io/en/latest/generated/shap.summary_plot.html?highlight=beeswarm#shap.summary_plot\n",
    "# usable_features_std = (usable_features - usable_features.mean(0))/usable_features.std(0)\n",
    "shap.summary_plot(shap_values, features=usable_features, feature_names=traits, plot_type='dot', max_display=len(traits), show = False)\n",
    "plt.savefig('shap/' + str(num_features) + '/summary_plot_hidden_'+ str(hidden) + '_dim_' + str(hidden_dimension) + '.pdf',  bbox_inches='tight')\n",
    "# shap.summary_plot(shap_values, features=usable_features, feature_names=list(range(23)), plot_type='dot', max_display=len(traits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://shap-lrjball.readthedocs.io/en/latest/generated/shap.summary_plot.html?highlight=beeswarm#shap.summary_plot\n",
    "# shap.summary_plot(shap_values, features=usable_features, feature_names=list(range(23)), plot_type='bar', max_display=len(traits), show=False)\n",
    "# plt.savefig('shap/summary_plot_hidden_'+ str(hidden) + '_bar.png', bbox_inches='tight')\n",
    "# naeem modified\n",
    "shap.summary_plot(shap_values, features=usable_features, feature_names=list(range(num_features)), plot_type='bar', max_display=len(traits), show=False)\n",
    "plt.savefig('shap/summary_plot_hidden_'+ str(hidden) + '_bar.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(list(zip(list(range(23)), abs(shap_values).mean(0))), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(shap.force_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(Final_Samples)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor, BernoulliRBM\n",
    "\n",
    "feature_indices_to_consider = list(range(0, 23)) #[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 18, 20, 22]\n",
    "\n",
    "usable_indices = [usable_samples_ADNI[Final_Samples[i][0]] for i in range(len(Final_Samples))]\n",
    "usable_features = FEATURE_MATRIX[usable_indices][:, feature_indices_to_consider]\n",
    "usable_labels = np.array([float(Final_Samples[i][1]) for i in range(len(Final_Samples))])\n",
    "\n",
    "Final_Samples = positive_samples[:500] + negative_samples[:500]\n",
    "random.seed(2);random.shuffle(Final_Samples)\n",
    "# Final_Samples = np.array(Final_Samples)\n",
    "print(len([x[1] for x in Final_Samples if x[1] == 1]), len([x[1] for x in Final_Samples if x[1] == 0]))\n",
    "print(sum(usable_labels), len(usable_labels))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    usable_features, usable_labels, test_size=0.1)\n",
    "\n",
    "X_train.shape, y_train.shape\n",
    "\n",
    "X_test.shape, y_test.shape\n",
    "\n",
    "print(y_test.sum(), y_test.shape)\n",
    "clf = svm.SVC(kernel='rbf', C=1).fit(X_train, y_train)\n",
    "# clf = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam').fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(Final_Samples)\n",
    "usable_indices = [usable_samples_ADNI[Final_Samples[i][0]] for i in range(len(Final_Samples))]\n",
    "usable_features = FEATURE_MATRIX[usable_indices][:, feature_indices_to_consider]\n",
    "usable_labels = np.array([float(Final_Samples[i][1]) for i in range(len(Final_Samples))])\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "X = usable_features[:, :23]\n",
    "y = usable_labels\n",
    "kf = KFold(n_splits=10)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "print(kf)\n",
    "# print(y_test)\n",
    "accuracies = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "#     clf = MLPClassifier(hidden_layer_sizes=(32,8), activation='relu', solver='adam', max_iter=100, learning_rate='invscaling').fit(X_train, y_train)\n",
    "#     print(y_test.sum(), y_test.shape)\n",
    "    print(clf.score(X_test, y_test))\n",
    "    accuracies += [clf.score(X_test, y_test)]\n",
    "print(np.mean(accuracies), np.std(accuracies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "accuracies = []\n",
    "X = usable_features[:, :23]\n",
    "y = usable_labels\n",
    "kf = KFold(n_splits=10)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    reg = RandomForestClassifier(random_state=0)\n",
    "    reg.fit(X_train, y_train)\n",
    "    print(\"Accuracy of model : \",reg.score(X_test, y_test)*100,\"%\")\n",
    "#     clf = MLPClassifier(hidden_layer_sizes=(32,8), activation='relu', solver='adam', max_iter=100, learning_rate='invscaling').fit(X_train, y_train)\n",
    "#     print(y_test.sum(), y_test.shape)\n",
    "    accuracies += [reg.score(X_test, y_test)]\n",
    "print(np.mean(accuracies), np.std(accuracies))\n",
    "save_in_file(\"Random Forest\", np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "model_name = \"XGB\"\n",
    "\n",
    "accuracies = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "#     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    reg = XGBClassifier()\n",
    "    reg.fit(X_train, y_train)\n",
    "    print(\"Accuracy of model : \",reg.score(X_test, y_test)*100,\"%\")\n",
    "#     clf = MLPClassifier(hidden_layer_sizes=(32,8), activation='relu', solver='adam', max_iter=100, learning_rate='invscaling').fit(X_train, y_train)\n",
    "#     print(y_test.sum(), y_test.shape)\n",
    "    accuracies += [reg.score(X_test, y_test)]\n",
    "print(np.mean(accuracies), np.std(accuracies))\n",
    "save_in_file(\"XGBoost\", np.mean(accuracies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# open the file in the write mode\n",
    "f = open('model_global_best_accuracy.csv', 'a')\n",
    "\n",
    "# create the csv writer\n",
    "writer = csv.writer(f)\n",
    "\n",
    "# write a row to the csv file\n",
    "# writer.writerow(['num_features','num_nn_layers','global_best_accuracy'])\n",
    "writer.writerow([str(num_features),str(hidden),str(global_best_acc_val)])\n",
    "\n",
    "# close the file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
