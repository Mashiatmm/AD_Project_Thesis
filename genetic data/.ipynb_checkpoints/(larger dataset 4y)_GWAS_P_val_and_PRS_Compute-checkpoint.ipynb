{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug cell\n",
    "with open('simple_table.txt', 'r') as f:\n",
    "    print(type(f))\n",
    "    cnt = 2\n",
    "    for i,line in enumerate(f):\n",
    "        print(i, ':\\t', line)\n",
    "        cnt -= 1\n",
    "        if cnt == 0:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug cell\n",
    "import gzip\n",
    "with gzip.open('./ukb-b-6134.vcf.gz') as f:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import time\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "def generate_gwas_output_as_tsv_file(inVCF_File, writeFile=None):\n",
    "    root = './tabular_format_gwas_data/'\n",
    "    t0 = time.time()\n",
    "    if writeFile is None:\n",
    "        writeFile = root + inVCF_File.split('/')[-1].split('.')[0] + '.tsv'\n",
    "    \n",
    "    print(\"Processing:\", inVCF_File)\n",
    "    if \".gz\" == inVCF_File[-3:]:\n",
    "        with gzip.open(inVCF_File, 'rb') as f_in:\n",
    "            with open(root+'temp_vcf.vcf', 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "        inVCF_File = root+'temp_vcf.vcf'\n",
    "    \"\"\"\n",
    "    Convert all the VCF into simplified tsv format\n",
    "    Source: https://github.com/everestial/VCF-simplify#table-of-contents\n",
    "    python3 ./VCF-Simplify/VCF-Simplify/VcfSimplify.py SimplifyVCF -toType table -inVCF ./ukb-b-6134.vcf -outFile ./simple_table.txt\n",
    "    \"\"\"\n",
    "    vcf_simplify_path = \"./VCF-Simplify/VCF-Simplify/VcfSimplify.py\"\n",
    "    out_File = root+'temp_table.tsv'\n",
    "    os.system(f\"python3 {vcf_simplify_path} SimplifyVCF -toType table -inVCF {inVCF_File} -outFile {out_File}\")\n",
    "        \n",
    "    f_read = open(out_File, 'r')\n",
    "    f_write = open(writeFile, 'w')\n",
    "    cnt = 0\n",
    "    for line in f_read:\n",
    "    #     print(line)\n",
    "        newliner = ''\n",
    "        if '\\n' == line[-1]:\n",
    "            newliner = '\\n'\n",
    "            line = line.strip()\n",
    "        if 'CHROM' in line:\n",
    "            line = line.upper() + '\\tPVAL_generated_from_LP'\n",
    "        else:\n",
    "            LP = float(line.split('\\t')[10])\n",
    "            p_val = str(10**(-1 * LP))\n",
    "            line = line + '\\t' + p_val\n",
    "        line = line + newliner\n",
    "    #     print(line)\n",
    "        f_write.write(line)\n",
    "        cnt += 1\n",
    "    #     if cnt == 20: break\n",
    "\n",
    "    f_read.close()\n",
    "    f_write.close()\n",
    "    print(f'Total SNPs: {cnt} | Total exec time: {time.time() - t0} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_gwas_output_as_tsv_file(inVCF_File='./ukb-b-6134.vcf.gz', writeFile=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ' abc def\\n'.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10**(-1*0.200659) #0.6300007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %pip install openpyxl\n",
    "import pandas as pd\n",
    "\n",
    "category_map = {\n",
    "    'Continuous' : 'beta', \n",
    "    'Categorical Ordered (assumed continuous)': 'beta',\n",
    "    'Binary': 'or',\n",
    "    'NA (Possibly binary)': 'or'\n",
    "}\n",
    "\n",
    "df = pd.read_excel('GWAS_datasets_to_consider.xlsx', engine='openpyxl')[['GWAS_ID', 'Trait', 'Category']]\n",
    "print(df['Category'].unique())\n",
    "GWAS_ID = 'ieu-b-111'\n",
    "category = category_map[df[df['GWAS_ID'] == GWAS_ID].to_numpy()[0, 2]] \n",
    "category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "# all_gwas_vcf_files = glob('/mnt/c/Users/HP/Downloads/Compressed/GWAS/*')\n",
    "ROOT = '/mnt/c/Users/HP/Downloads/Compressed/GWAS/'\n",
    "ALL_GWAS_IDS = sorted(list(set(df['GWAS_ID'].to_numpy().tolist()) - {'bbj-a-46', 'bbj-a-78', 'ieu-a-1283', 'ukb-a-257'}))\n",
    "base_files = {}\n",
    "for GWAS_ID in ALL_GWAS_IDS:\n",
    "    print(GWAS_ID)\n",
    "    file = ROOT + GWAS_ID + '.vcf.gz'\n",
    "    base_files[GWAS_ID] = category_map[df[df['GWAS_ID'] == GWAS_ID].to_numpy()[0, 2]] \n",
    "#     generate_gwas_output_as_tsv_file(inVCF_File=file, writeFile=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gender_map = {'Female': 0,'Male': 1}\n",
    "ADNIMERGE = pd.read_csv('ADNIMERGE.csv')\n",
    "def get_gender_and_age(PTID):\n",
    "    gender = ADNIMERGE[ADNIMERGE['PTID'] == PTID]['PTGENDER'].dropna().unique()[0]\n",
    "    age = ADNIMERGE[ADNIMERGE['PTID'] == PTID]['AGE'].dropna().unique()[0]\n",
    "    return str(gender_map[gender]) + ' ' + str(age)\n",
    "\n",
    "# NUM_TRAINING_SAMPLES = int(830 * .7)\n",
    "# print('NUM_TRAINING_SAMPLES:', NUM_TRAINING_SAMPLES)\n",
    "# f_writable = open('./COVAR_FILE.txt', 'w')\n",
    "# f_TRAINING_SAMPLES = open('./TRAINING_SAMPLES.txt', 'w')\n",
    "# with open('/mnt/c/Users/HP/Documents/GWA_tutorial/2_Population_stratification/covar_mds.txt') as f:\n",
    "#     for i, line in enumerate(f):\n",
    "#         if 'FID IID' in line:\n",
    "#             line = line[:-1] + ' GENDER AGE\\n'\n",
    "#         else:\n",
    "#             line = line[:-1] + ' ' + get_gender_and_age(PTID=line.split(' ')[1]) + '\\n'\n",
    "#         if i < NUM_TRAINING_SAMPLES:\n",
    "#             f_TRAINING_SAMPLES.write(' '.join(line.split(' ')[:2])+'\\n')\n",
    "#         f_writable.write(line)\n",
    "# #         print(line)\n",
    "# f_writable.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_prsice(GWAS_ID, redo=False):\n",
    "#     TARGET_DATA = '/mnt/c/Users/HP/Documents/GWA_tutorial/2_Population_stratification/ADNI' # old and smaller dataset\n",
    "    TARGET_DATA = '../larger_dataset/larger_dataset' # new and larger dataset\n",
    "    '''\n",
    "    return_status --> 0: success | 256: Error. Execusion Halted | 2: \n",
    "    '''\n",
    "    return_status = os.system(f'mkdir ./prsice_output/{GWAS_ID}/')\n",
    "    print('0:', return_status)\n",
    "    if return_status == 256 and not redo:\n",
    "        return return_status\n",
    "    prsice_command = f'Rscript ./PRSice_linux/PRSice.R \\\n",
    "        --dir ./prsice_output \\\n",
    "        --prsice ./PRSice_linux/PRSice_linux \\\n",
    "        --base ./tabular_format_gwas_data/{GWAS_ID}.tsv \\\n",
    "        --target {TARGET_DATA} \\\n",
    "        --thread 64 \\\n",
    "        --stat {base_files[GWAS_ID].upper()} \\\n",
    "        --{base_files[GWAS_ID]} \\\n",
    "        --binary-target F \\\n",
    "        --quantile 10 \\\n",
    "        --out ./prsice_output/{GWAS_ID}/{GWAS_ID} \\\n",
    "        --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat {GWAS_ID.upper()}:ES --pvalue PVAL_generated_from_LP \\\n",
    "        --score std \\\n",
    "        --cov ../larger_dataset/COVAR_FILE_bigger_dataset.txt'\n",
    "    print(prsice_command)\n",
    "#     return_status = os.system(prsice_command + '  --keep ./TRAINING_SAMPLES.txt') # generate the file named {GWAS_ID}.valid\n",
    "    return_status = os.system(prsice_command) # generate the file named {GWAS_ID}.valid\n",
    "    print('1a:', return_status)\n",
    "#     return\n",
    "    if os.path.isfile(f'./prsice_output/{GWAS_ID}/{GWAS_ID}.valid'): \n",
    "        prsice_command += f'  --extract ./prsice_output/{GWAS_ID}/{GWAS_ID}.valid' \n",
    "#         return_status = os.system(prsice_command + '  --keep ./TRAINING_SAMPLES.txt') # perform the regression analysis on the training samples only and choose the best p-value-threshold\n",
    "        return_status = os.system(prsice_command) # perform the regression analysis on the training samples only and choose the best p-value-threshold\n",
    "        print('1b:', return_status)\n",
    "        if return_status != 0:\n",
    "            return_status = os.system(prsice_command) # perform the regression analysis on the training samples only and choose the best p-value-threshold\n",
    "            print('1c:', return_status)\n",
    "#     return_status = os.system(prsice_command + '  --all-score --no-regress') # Do not perform the regression analysis and simply output all PRS.\n",
    "#     return_status = os.system(prsice_command + '  --all-score') # Do not perform the regression analysis and simply output all PRS.\n",
    "#     print('2:', return_status)\n",
    "    # in later steps, select the PRS values for the selected p-value-threshold for all the samples (both training and testing)\n",
    "    return_status = os.system('echo \"===== Done =====\"')\n",
    "    print('2:', return_status) \n",
    "#     os.system(f'mv ./prsice_output/{GWAS_ID}.* ./prsice_output/{GWAS_ID}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for GWAS_ID in base_files:\n",
    "    print(GWAS_ID)\n",
    "#     run_prsice(GWAS_ID=GWAS_ID)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_prsice(GWAS_ID='ukb-b-17627')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls 'tabular_format_gwas_data/{GWAS_ID}.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_files\n",
    "GWAS_ID = 'ieu-b-109'\n",
    "\n",
    "#====\n",
    "\n",
    "def get_prs_values(GWAS_ID):\n",
    "    prsice_output = f'./prsice_output/{GWAS_ID}/'\n",
    "\n",
    "    if False:\n",
    "        with open(prsice_output+f'{GWAS_ID}.all_score', 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            lines = ['\\t'.join(x.split()) for x in lines]\n",
    "            lines = '\\n'.join(lines)\n",
    "\n",
    "        with open(prsice_output+f'{GWAS_ID}.all_score.tsv', 'w') as f:\n",
    "            f.write(lines)\n",
    "\n",
    "        # best_p_val_threshold = '0.00025005'\n",
    "        best_p_val_threshold = str(open(prsice_output+f'{GWAS_ID}.summary').readlines()[1].split('\\t')[2]) \n",
    "    #     print(best_p_val_threshold) \n",
    "    prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy() \n",
    "    return prs_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prs_values(GWAS_ID=GWAS_ID).shape\n",
    "base_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df = pd.read_excel('GWAS_datasets_to_consider.xlsx', engine='openpyxl')[['GWAS_ID', 'Trait', 'Category']]\n",
    "all_traits = {}\n",
    "PRS_feature_matrix = np.zeros([len(base_files), 1816])\n",
    "for i, GWAS_ID in enumerate(base_files):\n",
    "    print(i, GWAS_ID)\n",
    "    PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
    "    trait = str(df[df['GWAS_ID'] == GWAS_ID]['Trait'].to_numpy()[0])\n",
    "    print(GWAS_ID, ':', trait)\n",
    "    all_traits[GWAS_ID] = trait\n",
    "print(all_traits)\n",
    "json.dump(all_traits, open('all_traits_map.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRS_feature_matrix = PRS_feature_matrix.T\n",
    "np.save('PRS_feature_matrix', PRS_feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRS_feature_matrix.shape\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SAMPLE_SIZE = 550\n",
    "train_samples = list(range(847))\n",
    "random.shuffle(train_samples)\n",
    "train_samples, test_samples = train_samples[:TRAIN_SAMPLE_SIZE], train_samples[TRAIN_SAMPLE_SIZE:]\n",
    "print(test_samples)\n",
    "print(len(train_samples), len(test_samples), len(train_samples) + len(test_samples))\n",
    "PRS_feature_matrix[train_samples].mean(0), PRS_feature_matrix[train_samples].std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRS_feature_matrix[test_samples].mean(0), PRS_feature_matrix[test_samples].std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRS_feature_matrix[:].mean(0), PRS_feature_matrix[:].std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "GWAS_ID = 'ieu-b-25'\n",
    "usable_samples_ADNI = pd.read_csv(f'./prsice_output/{GWAS_ID}/{GWAS_ID}.best', ' ')['IID'].to_numpy().tolist()\n",
    "usable_samples_ADNI = {'_'.join(sample.split('_')[1:]):idx for idx,sample in enumerate(usable_samples_ADNI)}\n",
    "# json.dump(usable_samples_ADNI, open('./usable_samples_ADNI.json', 'w'))\n",
    "type(usable_samples_ADNI), len(usable_samples_ADNI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls prsice_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "PRS_feature_matrix = np.load('./PRS_feature_matrix.npy')\n",
    "# usable_samples_ADNI = json.load(open('./usable_samples_ADNI.json'))\n",
    "print(PRS_feature_matrix.shape, usable_samples_ADNI.__len__())\n",
    "\n",
    "usable_samples_ADNI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "THRESHOLD_MONTH = 12*4\n",
    "ADNIMERGE = pd.read_csv('ADNIMERGE.csv')\n",
    "ADNI_TEMP = ADNIMERGE[['RID', 'PTID', 'DX', 'Month']].dropna().sort_values(by=['PTID', 'Month'])\n",
    "Dementia = ADNI_TEMP[ADNI_TEMP['DX']=='Dementia']\n",
    "Samples_Dementia = set(Dementia['PTID'].unique())\n",
    "Samples_NonDementia = set(ADNI_TEMP['PTID'].unique()) - Samples_Dementia\n",
    "# Samples_NonDementia\n",
    "Final_Samples_Dementia = set()\n",
    "for sample in Samples_Dementia:\n",
    "    last_dx = ADNI_TEMP[ADNI_TEMP['PTID']==sample]['DX'].iloc[-1]\n",
    "    last_month_of_dx = ADNI_TEMP[ADNI_TEMP['PTID']==sample]['Month'].iloc[-1]\n",
    "    if last_month_of_dx >= THRESHOLD_MONTH or True:\n",
    "        if last_dx == 'Dementia' and sample in usable_samples_ADNI:\n",
    "                Final_Samples_Dementia = Final_Samples_Dementia.union({sample})\n",
    "\n",
    "Final_Samples_NonDementia = set()\n",
    "for sample in Samples_NonDementia:\n",
    "    last_month_of_dx = ADNI_TEMP[ADNI_TEMP['PTID']==sample]['Month'].iloc[-1]\n",
    "    if last_month_of_dx >= THRESHOLD_MONTH and sample in usable_samples_ADNI:\n",
    "        Final_Samples_NonDementia = Final_Samples_NonDementia | {sample} # union symbol in python sets\n",
    "    \n",
    "# sum(ADNI_TEMP['Month'] == 6), ADNI_TEMP.shape\n",
    "# Dementia\n",
    "Final_Samples_Dementia = [[x, 1] for x in Final_Samples_Dementia]\n",
    "Final_Samples_NonDementia = [[x, 0] for x in Final_Samples_NonDementia]\n",
    "\n",
    "Final_Samples = Final_Samples_Dementia + Final_Samples_NonDementia\n",
    "json.dump(Final_Samples, open('Final_Samples.json', 'w'))\n",
    "\n",
    "Final_Samples_Dementia.__len__(), Final_Samples_NonDementia.__len__(), Final_Samples.__len__(), Final_Samples_Dementia.__len__()/Final_Samples.__len__(), Final_Samples_NonDementia.__len__()/Final_Samples.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "GWAS_ID = 'ieu-b-25'\n",
    "usable_samples_ADNI = pd.read_csv(f'./prsice_output/{GWAS_ID}/{GWAS_ID}.best', ' ')['IID'].to_numpy().tolist()\n",
    "usable_samples_ADNI = {sample:idx for idx,sample in enumerate(usable_samples_ADNI)}\n",
    "json.dump(usable_samples_ADNI, open('./usable_samples_ADNI.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_GWAS_IDS = [key for key in base_files]\n",
    "print(ALL_GWAS_IDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = pd.read_excel('GWAS_datasets_to_consider.xlsx', engine='openpyxl')[['GWAS_ID', 'Trait', 'Category']]\n",
    "# all_traits = {}\n",
    "# for GWAS_ID in ALL_GWAS_IDS:\n",
    "#     trait = str(df[df['GWAS_ID'] == GWAS_ID]['Trait'].to_numpy()[0])\n",
    "#     print(GWAS_ID, ':', trait)\n",
    "#     all_traits[GWAS_ID] = trait\n",
    "# print(all_traits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(all_traits)\n",
    "[all_traits[x] for x in all_traits]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
