{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '_io.TextIOWrapper'>\n",
      "0 :\t CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tUKB-b-6134:ES\tUKB-b-6134:SE\tUKB-b-6134:LP\tUKB-b-6134:AF\tUKB-b-6134:SS\tUKB-b-6134:EZ\tUKB-b-6134:SI\tUKB-b-6134:NC\tUKB-b-6134:ID\n",
      "\n",
      "1 :\t 1\t49298\trs10399793\tT\tC\t.\tPASS\t0.623238\t0.0017795\t0.00366743\t0.200659\t0.623238\t.\t.\t.\t.\trs10399793\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# debug cell\n",
    "with open('simple_table.txt', 'r') as f:\n",
    "    print(type(f))\n",
    "    cnt = 2\n",
    "    for i,line in enumerate(f):\n",
    "        print(i, ':\\t', line)\n",
    "        cnt -= 1\n",
    "        if cnt == 0:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './ukb-b-6134.vcf.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# debug cell\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgzip\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mgzip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./ukb-b-6134.vcf.gz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(f)\n",
      "File \u001b[0;32m~/anaconda3/envs/ad_venv/lib/python3.9/gzip.py:58\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(filename, mode, compresslevel, encoding, errors, newline)\u001b[0m\n\u001b[1;32m     56\u001b[0m gz_mode \u001b[38;5;241m=\u001b[39m mode\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filename, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike)):\n\u001b[0;32m---> 58\u001b[0m     binary_file \u001b[38;5;241m=\u001b[39m \u001b[43mGzipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgz_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompresslevel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwrite\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     60\u001b[0m     binary_file \u001b[38;5;241m=\u001b[39m GzipFile(\u001b[38;5;28;01mNone\u001b[39;00m, gz_mode, compresslevel, filename)\n",
      "File \u001b[0;32m~/anaconda3/envs/ad_venv/lib/python3.9/gzip.py:173\u001b[0m, in \u001b[0;36mGzipFile.__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    171\u001b[0m     mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     fileobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmyfileobj \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    175\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fileobj, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './ukb-b-6134.vcf.gz'"
     ]
    }
   ],
   "source": [
    "# debug cell\n",
    "import gzip\n",
    "with gzip.open('./ukb-b-6134.vcf.gz') as f:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import time\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "def generate_gwas_output_as_tsv_file(inVCF_File, writeFile=None):\n",
    "    root = './tabular_format_gwas_data/'\n",
    "    t0 = time.time()\n",
    "    if writeFile is None:\n",
    "        writeFile = root + inVCF_File.split('/')[-1].split('.')[0] + '.tsv'\n",
    "    \n",
    "    print(\"Processing:\", inVCF_File)\n",
    "    if \".gz\" == inVCF_File[-3:]:\n",
    "        with gzip.open(inVCF_File, 'rb') as f_in:\n",
    "            with open(root+'temp_vcf.vcf', 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "        inVCF_File = root+'temp_vcf.vcf'\n",
    "    \"\"\"\n",
    "    Convert all the VCF into simplified tsv format\n",
    "    Source: https://github.com/everestial/VCF-simplify#table-of-contents\n",
    "    python3 ./VCF-Simplify/VCF-Simplify/VcfSimplify.py SimplifyVCF -toType table -inVCF ./ukb-b-6134.vcf -outFile ./simple_table.txt\n",
    "    \"\"\"\n",
    "    vcf_simplify_path = \"./VCF-Simplify/VCF-Simplify/VcfSimplify.py\"\n",
    "    out_File = root+'temp_table.tsv'\n",
    "    os.system(f\"python3 {vcf_simplify_path} SimplifyVCF -toType table -inVCF {inVCF_File} -outFile {out_File}\")\n",
    "        \n",
    "    f_read = open(out_File, 'r')\n",
    "    f_write = open(writeFile, 'w')\n",
    "    cnt = 0\n",
    "    for line in f_read:\n",
    "    #     print(line)\n",
    "        newliner = ''\n",
    "        if '\\n' == line[-1]:\n",
    "            newliner = '\\n'\n",
    "            line = line.strip()\n",
    "        if 'CHROM' in line:\n",
    "            line = line.upper() + '\\tPVAL_generated_from_LP'\n",
    "        else:\n",
    "            LP = float(line.split('\\t')[10])\n",
    "            p_val = str(10**(-1 * LP))\n",
    "            line = line + '\\t' + p_val\n",
    "        line = line + newliner\n",
    "    #     print(line)\n",
    "        f_write.write(line)\n",
    "        cnt += 1\n",
    "    #     if cnt == 20: break\n",
    "\n",
    "    f_read.close()\n",
    "    f_write.close()\n",
    "    print(f'Total SNPs: {cnt} | Total exec time: {time.time() - t0} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_gwas_output_as_tsv_file(inVCF_File='./ukb-b-6134.vcf.gz', writeFile=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ' abc def\\n'.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10**(-1*0.200659) #0.6300007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Continuous' 'Binary' 'Risk factor' 'NA (Possibly binary)'\n",
      " 'Categorical Ordered (assumed continuous)']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'beta'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %pip install openpyxl\n",
    "import pandas as pd\n",
    "\n",
    "category_map = {\n",
    "    'Continuous' : 'beta', \n",
    "    'Categorical Ordered (assumed continuous)': 'beta',\n",
    "    'Binary': 'or',\n",
    "    'NA (Possibly binary)': 'or'\n",
    "}\n",
    "\n",
    "df = pd.read_excel('GWAS_datasets_to_consider.xlsx', engine='openpyxl')[['GWAS_ID', 'Trait', 'Category']]\n",
    "print(df['Category'].unique())\n",
    "GWAS_ID = 'ieu-b-111'\n",
    "category = category_map[df[df['GWAS_ID'] == GWAS_ID].to_numpy()[0, 2]] \n",
    "category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ukb-b-770\n",
      "ieu-b-38\n",
      "ukb-d-20405_1\n",
      "ukb-d-20405_0\n",
      "ieu-b-109\n",
      "ieu-b-39\n",
      "ukb-b-13806\n",
      "ukb-b-19953\n",
      "ukb-b-4424\n",
      "ieu-b-25\n",
      "ukb-b-18275\n",
      "ukb-b-12064\n",
      "ukb-b-7663\n",
      "ukb-b-3957\n",
      "ukb-b-8476\n",
      "ukb-b-6134\n",
      "ukb-d-20405_2\n",
      "ukb-b-6324\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "# all_gwas_vcf_files = glob('/mnt/c/Users/HP/Downloads/Compressed/GWAS/*')\n",
    "# ROOT = '/mnt/c/Users/HP/Downloads/Compressed/GWAS/'\n",
    "ALL_GWAS_IDS = list(set(df['GWAS_ID'].to_numpy().tolist()) - {'bbj-a-46', 'bbj-a-78', 'ieu-a-1283', 'ukb-a-257','ukb-b-2209','ukb-b-17627','ieub-109','ieu-b-110','ieu-b-111','met-d-Total_C'})\n",
    "base_files = {}\n",
    "for GWAS_ID in ALL_GWAS_IDS:\n",
    "    print(GWAS_ID)\n",
    "#     file = ROOT + GWAS_ID + '.vcf.gz'\n",
    "    base_files[GWAS_ID] = category_map[df[df['GWAS_ID'] == GWAS_ID].to_numpy()[0, 2]] \n",
    "#     generate_gwas_output_as_tsv_file(inVCF_File=file, writeFile=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ukb-b-770\n",
      "ieu-b-38\n",
      "ukb-d-20405_1\n",
      "ukb-d-20405_0\n",
      "ieu-b-109\n",
      "ieu-b-39\n",
      "ukb-b-13806\n",
      "ukb-b-19953\n",
      "ukb-b-4424\n",
      "ieu-b-25\n",
      "ukb-b-18275\n",
      "ukb-b-12064\n",
      "ukb-b-7663\n",
      "ukb-b-3957\n",
      "ukb-b-8476\n",
      "ukb-b-6134\n",
      "ukb-d-20405_2\n",
      "ukb-b-6324\n"
     ]
    }
   ],
   "source": [
    "# base_files\n",
    "for GWAS_ID in base_files:\n",
    "    print(GWAS_ID)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23164/1785225935.py:2: DtypeWarning: Columns (18,19,20,103,104) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ADNIMERGE = pd.read_csv('ADNIMERGE.csv')\n"
     ]
    }
   ],
   "source": [
    "gender_map = {'Female': 0,'Male': 1}\n",
    "ADNIMERGE = pd.read_csv('ADNIMERGE.csv')\n",
    "def get_gender_and_age(PTID):\n",
    "    gender = ADNIMERGE[ADNIMERGE['PTID'] == PTID]['PTGENDER'].dropna().unique()[0]\n",
    "    age = ADNIMERGE[ADNIMERGE['PTID'] == PTID]['AGE'].dropna().unique()[0]\n",
    "    return str(gender_map[gender]) + ' ' + str(age)\n",
    "\n",
    "# NUM_TRAINING_SAMPLES = int(830 * .7)\n",
    "# print('NUM_TRAINING_SAMPLES:', NUM_TRAINING_SAMPLES)\n",
    "# f_writable = open('./COVAR_FILE.txt', 'w')\n",
    "# f_TRAINING_SAMPLES = open('./TRAINING_SAMPLES.txt', 'w')\n",
    "# with open('/mnt/c/Users/HP/Documents/GWA_tutorial/2_Population_stratification/covar_mds.txt') as f:\n",
    "#     for i, line in enumerate(f):\n",
    "#         if 'FID IID' in line:\n",
    "#             line = line[:-1] + ' GENDER AGE\\n'\n",
    "#         else:\n",
    "#             line = line[:-1] + ' ' + get_gender_and_age(PTID=line.split(' ')[1]) + '\\n'\n",
    "#         if i < NUM_TRAINING_SAMPLES:\n",
    "#             f_TRAINING_SAMPLES.write(' '.join(line.split(' ')[:2])+'\\n')\n",
    "#         f_writable.write(line)\n",
    "# #         print(line)\n",
    "# f_writable.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_prsice(GWAS_ID, redo=False):\n",
    "#     TARGET_DATA = '/mnt/c/Users/HP/Documents/GWA_tutorial/2_Population_stratification/ADNI' # old and smaller dataset\n",
    "    TARGET_DATA = '../larger_dataset/larger_dataset' # new and larger dataset\n",
    "    '''\n",
    "    return_status --> 0: success | 256: Error. Execusion Halted | 2: \n",
    "    '''\n",
    "    if os.path.isfile(f'./PRSice_output/{GWAS_ID}/'):\n",
    "        return_status = os.system(f'mkdir ./PRSice_output/{GWAS_ID}/')\n",
    "        print('0:', return_status)\n",
    "        if return_status == 256 and not redo:\n",
    "            return return_status\n",
    "    print('stat',{base_files[GWAS_ID]})\n",
    "    prsice_command = f'Rscript ./PRSice_linux/PRSice.R \\\n",
    "        --dir ./PRSice_output \\\n",
    "        --prsice ./PRSice_linux/PRSice_linux \\\n",
    "        --base ./tabular_format_gwas_data/{GWAS_ID}.tsv \\\n",
    "        --target {TARGET_DATA} \\\n",
    "        --thread 1 \\\n",
    "        --stat {base_files[GWAS_ID].upper()} \\\n",
    "        --{base_files[GWAS_ID]} \\\n",
    "        --binary-target F \\\n",
    "        --quantile 10 \\\n",
    "        --out ./PRSice_output/{GWAS_ID}/{GWAS_ID} \\\n",
    "        --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat {GWAS_ID.upper()}:ES --pvalue PVAL_generated_from_LP \\\n",
    "        --score std \\\n",
    "        --cov ../larger_dataset/COVAR_FILE_bigger_dataset.txt \\\n",
    "        --extract ./PRSice_output/{GWAS_ID}/{GWAS_ID}.valid'\n",
    "\n",
    "#     return_status = os.system(prsice_command + '  --keep ./TRAINING_SAMPLES.txt') # generate the file named {GWAS_ID}.valid\n",
    "#     return_status = os.system(prsice_command) # generate the file named {GWAS_ID}.valid\n",
    "#     print('1a:', return_status)\n",
    "#     return\n",
    "#     if os.path.isfile(f'./PRSice_output/{GWAS_ID}/{GWAS_ID}.valid'): \n",
    "#         prsice_command += f' --extract ./PRSice_output/{GWAS_ID}/{GWAS_ID}.valid' \n",
    "#         return_status = os.system(prsice_command + '  --keep ./TRAINING_SAMPLES.txt') # perform the regression analysis on the training samples only and choose the best p-value-threshold\n",
    "#         return_status = os.system(prsice_command) # perform the regression analysis on the training samples only and choose the best p-value-threshold\n",
    "#         print('1b:', return_status)\n",
    "#         if return_status != 0:\n",
    "# #             return_status = os.system(prsice_command) # perform the regression analysis on the training samples only and choose the best p-value-threshold\n",
    "#             print('1c:', return_status)\n",
    "#     return_status = os.system(prsice_command + '  --all-score --no-regress') # Do not perform the regression analysis and simply output all PRS.\n",
    "#     return_status = os.system(prsice_command + '  --all-score') # Do not perform the regression analysis and simply output all PRS.\n",
    "#     print('2:', return_status)\n",
    "    # in later steps, select the PRS values for the selected p-value-threshold for all the samples (both training and testing)\n",
    "    print(prsice_command)\n",
    "    print('stat',{base_files[GWAS_ID]})\n",
    "    return_status = os.system(prsice_command) # generate the file named {GWAS_ID}.valid\n",
    "    print('1:', return_status)\n",
    "    return_status = os.system('echo \"===== Done =====\"')\n",
    "    print('2:', return_status) \n",
    "#     os.system(f'mv ./prsice_output/{GWAS_ID}.* ./prsice_output/{GWAS_ID}/')\n",
    "# https://github.com/adiamb/Remove-duplicate-snps-plink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****GWAS ID IS***** ukb-b-6134\n",
      "stat {'beta'}\n",
      "Rscript ./PRSice_linux/PRSice.R         --dir ./PRSice_output         --prsice ./PRSice_linux/PRSice_linux         --base ./tabular_format_gwas_data/ukb-b-6134.tsv         --target ../larger_dataset/larger_dataset         --thread 1         --stat BETA         --beta         --binary-target F         --quantile 10         --out ./PRSice_output/ukb-b-6134/ukb-b-6134         --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat UKB-B-6134:ES --pvalue PVAL_generated_from_LP         --score std         --cov ../larger_dataset/COVAR_FILE_bigger_dataset.txt         --extract ./PRSice_output/ukb-b-6134/ukb-b-6134.valid\n",
      "stat {'beta'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.5 (2021-09-20) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-07-05 06:40:31\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ukb-b-6134.tsv \\\n",
      "    --beta  \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ukb-b-6134/ukb-b-6134.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --out ./PRSice_output/ukb-b-6134/ukb-b-6134 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 1736013754 \\\n",
      "    --snp ID \\\n",
      "    --stat UKB-B-6134:ES \\\n",
      "    --target ../larger_dataset/larger_dataset \\\n",
      "    --thread 1 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset/larger_dataset (bed) \n",
      "\n",
      "Start processing ukb-b-6134 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ukb-b-6134.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tUKB-B-6134:ES\tUKB-B-6134:SE\tUKB-B-6134:LP\tUKB-B-6134:AF\tUKB-B-6134:SS\tUKB-B-6134:EZ\tUKB-B-6134:SI\tUKB-B-6134:NC\tUKB-B-6134:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "9756889 variant(s) observed in base file, with: \n",
      "3186943 variant(s) excluded based on user input \n",
      "6569946 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "1258258 variant(s) not found in previous data \n",
      "29 variant(s) with mismatch information \n",
      "6569946 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 387133 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s) with p-value between 0.1 and 1e-5 \n",
      "(\u001b[1;31mmay not be significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n"
     ]
    }
   ],
   "source": [
    "for GWAS_ID in base_files:\n",
    "    if GWAS_ID == 'ukb-b-6134':\n",
    "        print('*****GWAS ID IS*****',GWAS_ID)\n",
    "        run_prsice(GWAS_ID=GWAS_ID)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_prsice(GWAS_ID='ukb-b-17627')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tabular_format_gwas_data/ukb-b-6134.tsv\r\n"
     ]
    }
   ],
   "source": [
    "!ls 'tabular_format_gwas_data/{GWAS_ID}.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_files\n",
    "GWAS_ID = 'ukb-b-18275'\n",
    "\n",
    "#====\n",
    "\n",
    "def get_prs_values(GWAS_ID):\n",
    "    prsice_output = f'./PRSice_output/{GWAS_ID}/'\n",
    "\n",
    "    if False:\n",
    "        with open(prsice_output+f'{GWAS_ID}.all_score', 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            lines = ['\\t'.join(x.split()) for x in lines]\n",
    "            lines = '\\n'.join(lines)\n",
    "\n",
    "        with open(prsice_output+f'{GWAS_ID}.all_score.tsv', 'w') as f:\n",
    "            f.write(lines)\n",
    "\n",
    "        # best_p_val_threshold = '0.00025005'\n",
    "        best_p_val_threshold = str(open(prsice_output+f'{GWAS_ID}.summary').readlines()[1].split('\\t')[2]) \n",
    "    #     print(best_p_val_threshold) \n",
    "    prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy() \n",
    "    return prs_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23164/1595037025.py:1: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  get_prs_values(GWAS_ID=GWAS_ID).shape[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1816"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prs_values(GWAS_ID=GWAS_ID).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ukb-b-770\n",
      "ieu-b-38\n",
      "ukb-d-20405_1\n",
      "ukb-d-20405_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23164/3576494164.py:9: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_23164/3576494164.py:9: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_23164/3576494164.py:9: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_23164/3576494164.py:9: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ieu-b-109\n",
      "ieu-b-39\n",
      "ukb-b-13806\n",
      "ukb-b-19953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23164/3576494164.py:9: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_23164/3576494164.py:9: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_23164/3576494164.py:9: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_23164/3576494164.py:9: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ukb-b-4424\n",
      "ieu-b-25\n",
      "ukb-b-18275\n",
      "ukb-b-12064\n",
      "ukb-b-7663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23164/3576494164.py:9: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_23164/3576494164.py:9: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_23164/3576494164.py:9: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_23164/3576494164.py:9: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_23164/3576494164.py:9: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ukb-b-3957\n",
      "ukb-b-8476\n",
      "ukb-b-6134\n",
      "ukb-d-20405_2\n",
      "ukb-b-6324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23164/3576494164.py:9: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_23164/3576494164.py:9: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_23164/3576494164.py:9: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_23164/3576494164.py:9: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_23164/3576494164.py:9: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os.path\n",
    "\n",
    "PRS_feature_matrix = np.zeros([len(base_files), 1816])\n",
    "for i, GWAS_ID in enumerate(base_files):\n",
    "    print(GWAS_ID)\n",
    "    prsice_output = f'./PRSice_output/{GWAS_ID}/{GWAS_ID}.best'\n",
    "    if os.path.exists(prsice_output):  \n",
    "        PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRS_feature_matrix = PRS_feature_matrix.T\n",
    "np.save('PRS_feature_matrix', PRS_feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRS_feature_matrix.shape\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[818, 222, 409, 300, 664, 370, 396, 608, 249, 374, 714, 97, 233, 565, 503, 192, 524, 688, 751, 212, 624, 327, 241, 767, 804, 94, 226, 763, 700, 749, 718, 773, 358, 210, 639, 114, 625, 104, 482, 545, 681, 830, 400, 196, 124, 244, 459, 355, 648, 313, 705, 546, 70, 597, 98, 807, 795, 559, 711, 579, 319, 461, 520, 757, 526, 314, 406, 134, 211, 563, 199, 399, 11, 485, 410, 685, 771, 385, 493, 144, 379, 41, 228, 188, 817, 242, 617, 132, 36, 136, 219, 842, 229, 382, 194, 699, 270, 684, 766, 621, 240, 577, 636, 43, 764, 537, 398, 419, 555, 202, 477, 380, 33, 759, 668, 326, 348, 781, 809, 145, 139, 390, 709, 272, 403, 9, 529, 113, 215, 350, 564, 615, 107, 822, 155, 38, 556, 335, 40, 629, 266, 815, 121, 247, 238, 642, 611, 600, 372, 496, 397, 446, 122, 449, 235, 84, 297, 207, 110, 785, 812, 578, 465, 149, 423, 651, 505, 514, 422, 102, 846, 13, 487, 86, 88, 417, 352, 534, 365, 279, 833, 616, 729, 758, 673, 49, 198, 320, 32, 531, 770, 127, 59, 474, 281, 338, 0, 125, 151, 748, 557, 12, 80, 223, 678, 814, 494, 675, 706, 492, 35, 260, 457, 434, 286, 4, 187, 682, 273, 549, 658, 654, 442, 518, 307, 337, 720, 501, 638, 481, 429, 677, 159, 378, 731, 778, 612, 566, 535, 542, 152, 802, 794, 484, 530, 69, 576, 50, 116, 656, 146, 21, 601, 845, 426, 282, 3, 64, 635, 68, 315, 522, 342, 304, 476, 258, 513, 117, 309, 533, 618, 783, 702, 118, 519, 413, 679, 334, 185, 381, 740, 377, 66, 788, 345, 37, 193, 470, 488, 224, 99, 581, 808, 710, 386, 178, 587]\n",
      "550 297 847\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 0.05308238,  0.03451169, -0.21770446, -0.51659621, -0.01568063,\n",
       "         0.02917379, -0.06685639,  0.03581486,  0.12414165, -0.02429693,\n",
       "        -0.57283057, -0.10043958, -0.5589993 ,  0.02353178, -0.64111237,\n",
       "         0.03097957, -0.49644052,  0.0326984 ]),\n",
       " array([1.02887107, 0.98538162, 0.85797973, 0.58797811, 0.98258345,\n",
       "        1.00093132, 0.98533474, 1.01065323, 0.68248991, 0.92532206,\n",
       "        0.59265129, 0.94301748, 0.56555325, 0.94862211, 0.71645114,\n",
       "        0.98800414, 0.53086297, 0.9527379 ]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_SAMPLE_SIZE = 550\n",
    "train_samples = list(range(847))\n",
    "random.shuffle(train_samples)\n",
    "train_samples, test_samples = train_samples[:TRAIN_SAMPLE_SIZE], train_samples[TRAIN_SAMPLE_SIZE:]\n",
    "print(test_samples)\n",
    "print(len(train_samples), len(test_samples), len(train_samples) + len(test_samples))\n",
    "PRS_feature_matrix[train_samples].mean(0), PRS_feature_matrix[train_samples].std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.01081337, -0.01227618, -0.3021462 , -0.52705209,  0.13395638,\n",
       "        -0.05958485, -0.09604769, -0.08230944,  0.12333936,  0.04324866,\n",
       "        -0.60816329, -0.31198319, -0.58261849, -0.00807834, -0.72856645,\n",
       "        -0.06363957, -0.49800506, -0.0407727 ]),\n",
       " array([0.91144598, 0.94008246, 0.8827431 , 0.5577856 , 1.02065063,\n",
       "        0.96791466, 0.97346989, 0.99592809, 0.67461437, 1.03599949,\n",
       "        0.55956999, 0.92293673, 0.53275235, 0.95155192, 0.66512051,\n",
       "        1.02727449, 0.49098899, 1.05159588]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PRS_feature_matrix[test_samples].mean(0), PRS_feature_matrix[test_samples].std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRS_feature_matrix[:].mean(0), PRS_feature_matrix[:].std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "GWAS_ID = 'ieu-b-25'\n",
    "usable_samples_ADNI = pd.read_csv(f'./PRSice_output/{GWAS_ID}/{GWAS_ID}.best', ' ')['IID'].to_numpy().tolist()\n",
    "usable_samples_ADNI = {'_'.join(sample.split('_')[1:]):idx for idx,sample in enumerate(usable_samples_ADNI)}\n",
    "# json.dump(usable_samples_ADNI, open('./usable_samples_ADNI.json', 'w'))\n",
    "type(usable_samples_ADNI), len(usable_samples_ADNI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls prsice_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "PRS_feature_matrix = np.load('./PRS_feature_matrix.npy')\n",
    "# usable_samples_ADNI = json.load(open('./usable_samples_ADNI.json'))\n",
    "print(PRS_feature_matrix.shape, usable_samples_ADNI.__len__())\n",
    "\n",
    "usable_samples_ADNI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "THRESHOLD_MONTH = 12*2\n",
    "ADNIMERGE = pd.read_csv('ADNIMERGE.csv')\n",
    "ADNI_TEMP = ADNIMERGE[['RID', 'PTID', 'DX', 'Month']].dropna().sort_values(by=['PTID', 'Month'])\n",
    "Dementia = ADNI_TEMP[ADNI_TEMP['DX']=='Dementia']\n",
    "Samples_Dementia = set(Dementia['PTID'].unique())\n",
    "Samples_NonDementia = set(ADNI_TEMP['PTID'].unique()) - Samples_Dementia\n",
    "# Samples_NonDementia\n",
    "Final_Samples_Dementia = set()\n",
    "for sample in Samples_Dementia:\n",
    "    last_dx = ADNI_TEMP[ADNI_TEMP['PTID']==sample]['DX'].iloc[-1]\n",
    "    last_month_of_dx = ADNI_TEMP[ADNI_TEMP['PTID']==sample]['Month'].iloc[-1]\n",
    "    if last_month_of_dx >= THRESHOLD_MONTH or True:\n",
    "        if last_dx == 'Dementia' and sample in usable_samples_ADNI:\n",
    "                Final_Samples_Dementia = Final_Samples_Dementia.union({sample})\n",
    "\n",
    "Final_Samples_NonDementia = set()\n",
    "for sample in Samples_NonDementia:\n",
    "    last_month_of_dx = ADNI_TEMP[ADNI_TEMP['PTID']==sample]['Month'].iloc[-1]\n",
    "    if last_month_of_dx >= THRESHOLD_MONTH and sample in usable_samples_ADNI:\n",
    "        Final_Samples_NonDementia = Final_Samples_NonDementia | {sample} # union symbol in python sets\n",
    "    \n",
    "# sum(ADNI_TEMP['Month'] == 6), ADNI_TEMP.shape\n",
    "# Dementia\n",
    "Final_Samples_Dementia = [[x, 1] for x in Final_Samples_Dementia]\n",
    "Final_Samples_NonDementia = [[x, 0] for x in Final_Samples_NonDementia]\n",
    "\n",
    "Final_Samples = Final_Samples_Dementia + Final_Samples_NonDementia\n",
    "json.dump(Final_Samples, open('Final_Samples.json', 'w'))\n",
    "\n",
    "Final_Samples_Dementia.__len__(), Final_Samples_NonDementia.__len__(), Final_Samples.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "GWAS_ID = 'ieu-b-25'\n",
    "usable_samples_ADNI = pd.read_csv(f'./PRSice_output/{GWAS_ID}/{GWAS_ID}.best', ' ')['IID'].to_numpy().tolist()\n",
    "usable_samples_ADNI = {sample:idx for idx,sample in enumerate(usable_samples_ADNI)}\n",
    "json.dump(usable_samples_ADNI, open('./usable_samples_ADNI.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_GWAS_IDS = [key for key in base_files]\n",
    "print(ALL_GWAS_IDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('GWAS_datasets_to_consider.xlsx', engine='openpyxl')[['GWAS_ID', 'Trait', 'Category']]\n",
    "all_traits = []\n",
    "for GWAS_ID in ALL_GWAS_IDS:\n",
    "    trait = str(df[df['GWAS_ID'] == GWAS_ID]['Trait'].to_numpy()[0])\n",
    "    print(GWAS_ID, ':', trait)\n",
    "    all_traits += [trait]\n",
    "print(all_traits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for demo purpose\n",
    "prsice_command = f'Rscript ./PRSice_linux/PRSice.R --dir ./PRSice_linux\t\\\n",
    "--prsice ./PRSice_linux/PRSice_linux     \\\n",
    "--base ./PRSice_linux/simple_table_with_pval.txt     \\\n",
    "--target ./PRSice_linux/ADNI_plink     \\\n",
    "--thread 1     \\\n",
    "--beta     \\\n",
    "--binary-target F\t\\\n",
    "--out ./PRSice_output/PRSice\t\\\n",
    "--snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat UKB-b-6134:ES --pvalue PVAL_generated_from_LP\t\\\n",
    "--extract ./PRSice_output/PRSice.valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # this is for demo purpose\n",
    "    import os\n",
    "    return_status = os.system(prsice_command) # generate the file named {GWAS_ID}.valid\n",
    "    print('1a:', return_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
