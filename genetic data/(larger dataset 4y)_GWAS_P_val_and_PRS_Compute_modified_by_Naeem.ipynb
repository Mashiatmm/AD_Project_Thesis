{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFolder=\"\"\n",
    "folderCounter=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '_io.TextIOWrapper'>\n",
      "0 :\t CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tUKB-b-6134:ES\tUKB-b-6134:SE\tUKB-b-6134:LP\tUKB-b-6134:AF\tUKB-b-6134:SS\tUKB-b-6134:EZ\tUKB-b-6134:SI\tUKB-b-6134:NC\tUKB-b-6134:ID\n",
      "\n",
      "1 :\t 1\t49298\trs10399793\tT\tC\t.\tPASS\t0.623238\t0.0017795\t0.00366743\t0.200659\t0.623238\t.\t.\t.\t.\trs10399793\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# debug cell\n",
    "with open('simple_table.txt', 'r') as f:\n",
    "    print(type(f))\n",
    "    cnt = 2\n",
    "    for i,line in enumerate(f):\n",
    "        print(i, ':\\t', line)\n",
    "        cnt -= 1\n",
    "        if cnt == 0:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './ukb-b-6134.vcf.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# debug cell\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgzip\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mgzip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./ukb-b-6134.vcf.gz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(f)\n",
      "File \u001b[0;32m~/anaconda3/envs/ad_venv/lib/python3.9/gzip.py:58\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(filename, mode, compresslevel, encoding, errors, newline)\u001b[0m\n\u001b[1;32m     56\u001b[0m gz_mode \u001b[38;5;241m=\u001b[39m mode\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filename, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike)):\n\u001b[0;32m---> 58\u001b[0m     binary_file \u001b[38;5;241m=\u001b[39m \u001b[43mGzipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgz_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompresslevel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwrite\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     60\u001b[0m     binary_file \u001b[38;5;241m=\u001b[39m GzipFile(\u001b[38;5;28;01mNone\u001b[39;00m, gz_mode, compresslevel, filename)\n",
      "File \u001b[0;32m~/anaconda3/envs/ad_venv/lib/python3.9/gzip.py:173\u001b[0m, in \u001b[0;36mGzipFile.__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    171\u001b[0m     mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     fileobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmyfileobj \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    175\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fileobj, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './ukb-b-6134.vcf.gz'"
     ]
    }
   ],
   "source": [
    "# debug cell\n",
    "import gzip\n",
    "with gzip.open('./ukb-b-6134.vcf.gz') as f:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to rerun any part of this code\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import time\n",
    "import gzip\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_gwas_output_as_tsv_file(inVCF_File, writeFile=None):\n",
    "    root = './tabular_format_gwas_data/'\n",
    "    t0 = time.time()\n",
    "    if writeFile is None:\n",
    "        writeFile = root + inVCF_File.split('/')[-1].split('.')[0] + '.tsv'\n",
    "    \n",
    "    print(\"Processing:\", inVCF_File)\n",
    "    if \".gz\" == inVCF_File[-3:]:\n",
    "        with gzip.open(inVCF_File, 'rb') as f_in:\n",
    "            with open(root+'temp_vcf.vcf', 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "        inVCF_File = root+'temp_vcf.vcf'\n",
    "    print(\"gzip open done :\", inVCF_File)\n",
    "    \"\"\"\n",
    "    Convert all the VCF into simplified tsv format\n",
    "    Source: https://github.com/everestial/VCF-simplify#table-of-contents\n",
    "    python3 ./VCF-Simplify/VCF-Simplify/VcfSimplify.py SimplifyVCF -toType table -inVCF ./ukb-b-6134.vcf -outFile ./simple_table.txt\n",
    "    \"\"\"\n",
    "    vcf_simplify_path = \"./VCF-Simplify/VCF-Simplify/VcfSimplify.py\"\n",
    "    out_File = root+'temp_table.tsv'\n",
    "    os.system(f\"python3 {vcf_simplify_path} SimplifyVCF -toType table -inVCF {inVCF_File} -outFile {out_File}\")\n",
    "    print(writeFile)\n",
    "        \n",
    "    f_read = open(out_File, 'r')\n",
    "    f_write = open(writeFile, 'w')\n",
    "    cnt = 0\n",
    "    for line in f_read:\n",
    "#         print(line)\n",
    "        newliner = ''\n",
    "        if '\\n' == line[-1]:\n",
    "            newliner = '\\n'\n",
    "            line = line.strip()\n",
    "        if 'CHROM' in line:\n",
    "            line = line.upper() + '\\tPVAL_generated_from_LP'\n",
    "        else:\n",
    "            LP = float(line.split('\\t')[10])\n",
    "#             LP = float(line.split('\\t')[14])\n",
    "            #find out LP column from the tsv file\n",
    "            \n",
    "            p_val = str(10**(-1 * LP))\n",
    "            line = line + '\\t' + p_val\n",
    "        line = line + newliner\n",
    "    #     print(line)\n",
    "        f_write.write(line)\n",
    "        cnt += 1\n",
    "    #     if cnt == 20: break\n",
    "\n",
    "    f_read.close()\n",
    "    f_write.close()\n",
    "    print(f'Total SNPs: {cnt} | Total exec time: {time.time() - t0} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('GWAS_datasets_to_consider.xlsx', engine='openpyxl')[['GWAS_ID', 'Trait', 'Category']]\n",
    "df\n",
    "ALL_GWAS_IDS = list(df['GWAS_ID'].to_numpy().tolist()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: ./tabular_format_gwas_data/ukb-b-13806.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'UKB-b-13806:ES', 'UKB-b-13806:SE', 'UKB-b-13806:LP', 'UKB-b-13806:AF', 'UKB-b-13806:SS', 'UKB-b-13806:EZ', 'UKB-b-13806:SI', 'UKB-b-13806:NC', 'UKB-b-13806:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "elapsed time:  26.839468955993652\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 12,596, after: 12,596, consumed: 0; exec time: 26.842905282974243 seconds\n",
      "./tabular_format_gwas_data/ukb-b-13806.tsv\n",
      "Total SNPs: 4004524 | Total exec time: 33.513527393341064 seconds\n",
      "Processing: ./tabular_format_gwas_data/ukb-d-20405_0.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'ukb-d-20405_0:ES', 'ukb-d-20405_0:SE', 'ukb-d-20405_0:LP', 'ukb-d-20405_0:AF', 'ukb-d-20405_0:SS', 'ukb-d-20405_0:EZ', 'ukb-d-20405_0:SI', 'ukb-d-20405_0:NC', 'ukb-d-20405_0:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "Contig X is being processed ... \n",
      "\n",
      "elapsed time:  98.76685810089111\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 12,128, after: 12,564, consumed: 436; exec time: 98.77012753486633 seconds\n",
      "./tabular_format_gwas_data/ukb-d-20405_0.tsv\n",
      "Total SNPs: 13571660 | Total exec time: 133.7235209941864 seconds\n",
      "Processing: ./tabular_format_gwas_data/ukb-d-20405_1.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'ukb-d-20405_1:ES', 'ukb-d-20405_1:SE', 'ukb-d-20405_1:LP', 'ukb-d-20405_1:AF', 'ukb-d-20405_1:SS', 'ukb-d-20405_1:EZ', 'ukb-d-20405_1:SI', 'ukb-d-20405_1:NC', 'ukb-d-20405_1:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "Contig X is being processed ... \n",
      "\n",
      "elapsed time:  87.73517727851868\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 12,192, after: 12,604, consumed: 412; exec time: 87.73845148086548 seconds\n",
      "./tabular_format_gwas_data/ukb-d-20405_1.tsv\n",
      "Total SNPs: 12203571 | Total exec time: 118.58655738830566 seconds\n",
      "Processing: ./tabular_format_gwas_data/ukb-d-20405_2.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'ukb-d-20405_2:ES', 'ukb-d-20405_2:SE', 'ukb-d-20405_2:LP', 'ukb-d-20405_2:AF', 'ukb-d-20405_2:SS', 'ukb-d-20405_2:EZ', 'ukb-d-20405_2:SI', 'ukb-d-20405_2:NC', 'ukb-d-20405_2:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "Contig X is being processed ... \n",
      "\n",
      "elapsed time:  89.20190215110779\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 12,128, after: 12,564, consumed: 436; exec time: 89.20534467697144 seconds\n",
      "./tabular_format_gwas_data/ukb-d-20405_2.tsv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total SNPs: 12013477 | Total exec time: 120.19564819335938 seconds\n",
      "Processing: ./tabular_format_gwas_data/met-d-Total_C.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'met-d-Total_C:ES', 'met-d-Total_C:SE', 'met-d-Total_C:LP', 'met-d-Total_C:AF', 'met-d-Total_C:SS', 'met-d-Total_C:EZ', 'met-d-Total_C:SI', 'met-d-Total_C:NC', 'met-d-Total_C:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "elapsed time:  89.77770566940308\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 12,200, after: 12,636, consumed: 436; exec time: 89.78113889694214 seconds\n",
      "./tabular_format_gwas_data/met-d-Total_C.tsv\n",
      "Total SNPs: 12216220 | Total exec time: 118.30017375946045 seconds\n",
      "Processing: ./tabular_format_gwas_data/ieu-b-109.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'ieu-b-109:ES', 'ieu-b-109:SE', 'ieu-b-109:LP', 'ieu-b-109:AF', 'ieu-b-109:SS', 'ieu-b-109:EZ', 'ieu-b-109:SI', 'ieu-b-109:NC', 'ieu-b-109:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "Contig X is being processed ... \n",
      "\n",
      "elapsed time:  88.41496968269348\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 12,240, after: 12,616, consumed: 376; exec time: 88.41819524765015 seconds\n",
      "./tabular_format_gwas_data/ieu-b-109.tsv\n",
      "Total SNPs: 12321876 | Total exec time: 117.66976046562195 seconds\n",
      "Processing: ./tabular_format_gwas_data/ieu-b-110.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'ieu-b-110:ES', 'ieu-b-110:SE', 'ieu-b-110:LP', 'ieu-b-110:AF', 'ieu-b-110:SS', 'ieu-b-110:EZ', 'ieu-b-110:SI', 'ieu-b-110:NC', 'ieu-b-110:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "Contig X is being processed ... \n",
      "\n",
      "elapsed time:  87.7367856502533\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 12,068, after: 12,496, consumed: 428; exec time: 87.74034523963928 seconds\n",
      "./tabular_format_gwas_data/ieu-b-110.tsv\n",
      "Total SNPs: 12321876 | Total exec time: 116.33145475387573 seconds\n",
      "Processing: ./tabular_format_gwas_data/ieu-b-111.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'ieu-b-111:ES', 'ieu-b-111:SE', 'ieu-b-111:LP', 'ieu-b-111:AF', 'ieu-b-111:SS', 'ieu-b-111:EZ', 'ieu-b-111:SI', 'ieu-b-111:NC', 'ieu-b-111:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "Contig X is being processed ... \n",
      "\n",
      "elapsed time:  87.67886137962341\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 12,332, after: 12,708, consumed: 376; exec time: 87.68209624290466 seconds\n",
      "./tabular_format_gwas_data/ieu-b-111.tsv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total SNPs: 12321876 | Total exec time: 116.55932235717773 seconds\n",
      "Processing: ./tabular_format_gwas_data/ieu-b-25.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'ieu-b-25:ES', 'ieu-b-25:SE', 'ieu-b-25:LP', 'ieu-b-25:AF', 'ieu-b-25:SS', 'ieu-b-25:EZ', 'ieu-b-25:SI', 'ieu-b-25:NC', 'ieu-b-25:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "Contig X is being processed ... \n",
      "\n",
      "elapsed time:  86.50731873512268\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 12,188, after: 12,620, consumed: 432; exec time: 86.51060366630554 seconds\n",
      "./tabular_format_gwas_data/ieu-b-25.tsv\n",
      "Total SNPs: 11913712 | Total exec time: 114.5762255191803 seconds\n",
      "Processing: ./tabular_format_gwas_data/ieu-b-38.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'ieu-b-38:ES', 'ieu-b-38:SE', 'ieu-b-38:LP', 'ieu-b-38:AF', 'ieu-b-38:SS', 'ieu-b-38:EZ', 'ieu-b-38:SI', 'ieu-b-38:NC', 'ieu-b-38:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "elapsed time:  51.838828325271606\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 12,152, after: 12,520, consumed: 368; exec time: 51.84202241897583 seconds\n",
      "./tabular_format_gwas_data/ieu-b-38.tsv\n",
      "Total SNPs: 7088084 | Total exec time: 69.04240036010742 seconds\n",
      "Processing: ./tabular_format_gwas_data/ieu-b-39.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'ieu-b-39:ES', 'ieu-b-39:SE', 'ieu-b-39:LP', 'ieu-b-39:AF', 'ieu-b-39:SS', 'ieu-b-39:EZ', 'ieu-b-39:SI', 'ieu-b-39:NC', 'ieu-b-39:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "elapsed time:  48.93312859535217\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 12,044, after: 12,468, consumed: 424; exec time: 48.93633580207825 seconds\n",
      "./tabular_format_gwas_data/ieu-b-39.tsv\n",
      "Total SNPs: 7160620 | Total exec time: 65.44685339927673 seconds\n",
      "Processing: ./tabular_format_gwas_data/ukb-a-257.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'UKB-a-257:ES', 'UKB-a-257:SE', 'UKB-a-257:LP', 'UKB-a-257:AF', 'UKB-a-257:SS', 'UKB-a-257:EZ', 'UKB-a-257:SI', 'UKB-a-257:NC', 'UKB-a-257:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "elapsed time:  71.04468536376953\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 12,192, after: 12,556, consumed: 364; exec time: 71.04767751693726 seconds\n",
      "./tabular_format_gwas_data/ukb-a-257.tsv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total SNPs: 10545187 | Total exec time: 96.35626554489136 seconds\n",
      "Processing: ./tabular_format_gwas_data/ukb-b-12064.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'UKB-b-12064:ES', 'UKB-b-12064:SE', 'UKB-b-12064:LP', 'UKB-b-12064:AF', 'UKB-b-12064:SS', 'UKB-b-12064:EZ', 'UKB-b-12064:SI', 'UKB-b-12064:NC', 'UKB-b-12064:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "elapsed time:  50.37080407142639\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 12,152, after: 12,588, consumed: 436; exec time: 50.393691062927246 seconds\n",
      "./tabular_format_gwas_data/ukb-b-12064.tsv\n",
      "Total SNPs: 7338291 | Total exec time: 67.21527647972107 seconds\n",
      "Processing: ./tabular_format_gwas_data/ukb-b-17627.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'UKB-b-17627:ES', 'UKB-b-17627:SE', 'UKB-b-17627:LP', 'UKB-b-17627:AF', 'UKB-b-17627:SS', 'UKB-b-17627:EZ', 'UKB-b-17627:SI', 'UKB-b-17627:NC', 'UKB-b-17627:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "elapsed time:  69.95086646080017\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 12,144, after: 12,580, consumed: 436; exec time: 69.95397663116455 seconds\n",
      "./tabular_format_gwas_data/ukb-b-17627.tsv\n",
      "Total SNPs: 9851867 | Total exec time: 92.47337102890015 seconds\n",
      "Processing: ./tabular_format_gwas_data/ukb-b-18275.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'UKB-b-18275:ES', 'UKB-b-18275:SE', 'UKB-b-18275:LP', 'UKB-b-18275:AF', 'UKB-b-18275:SS', 'UKB-b-18275:EZ', 'UKB-b-18275:SI', 'UKB-b-18275:NC', 'UKB-b-18275:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "elapsed time:  66.75027894973755\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 12,116, after: 12,552, consumed: 436; exec time: 66.75327491760254 seconds\n",
      "./tabular_format_gwas_data/ukb-b-18275.tsv\n",
      "Total SNPs: 9401287 | Total exec time: 88.72575497627258 seconds\n",
      "Processing: ./tabular_format_gwas_data/ukb-b-19953.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'UKB-b-19953:ES', 'UKB-b-19953:SE', 'UKB-b-19953:LP', 'UKB-b-19953:AF', 'UKB-b-19953:SS', 'UKB-b-19953:EZ', 'UKB-b-19953:SI', 'UKB-b-19953:NC', 'UKB-b-19953:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "elapsed time:  70.73083162307739\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 12,220, after: 12,596, consumed: 376; exec time: 70.7340202331543 seconds\n",
      "./tabular_format_gwas_data/ukb-b-19953.tsv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total SNPs: 9851867 | Total exec time: 94.31156206130981 seconds\n",
      "Processing: ./tabular_format_gwas_data/ukb-b-2209.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'UKB-b-2209:ES', 'UKB-b-2209:SE', 'UKB-b-2209:LP', 'UKB-b-2209:AF', 'UKB-b-2209:SS', 'UKB-b-2209:EZ', 'UKB-b-2209:SI', 'UKB-b-2209:NC', 'UKB-b-2209:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "elapsed time:  71.73412585258484\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 12,228, after: 12,604, consumed: 376; exec time: 71.7372498512268 seconds\n",
      "./tabular_format_gwas_data/ukb-b-2209.tsv\n",
      "Total SNPs: 9851867 | Total exec time: 94.74072170257568 seconds\n",
      "Processing: ./tabular_format_gwas_data/ukb-b-3957.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'UKB-b-3957:ES', 'UKB-b-3957:SE', 'UKB-b-3957:LP', 'UKB-b-3957:AF', 'UKB-b-3957:SS', 'UKB-b-3957:EZ', 'UKB-b-3957:SI', 'UKB-b-3957:NC', 'UKB-b-3957:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "elapsed time:  72.3821017742157\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 12,236, after: 12,612, consumed: 376; exec time: 72.3850965499878 seconds\n",
      "./tabular_format_gwas_data/ukb-b-3957.tsv\n",
      "Total SNPs: 9851867 | Total exec time: 97.21226525306702 seconds\n",
      "Processing: ./tabular_format_gwas_data/ukb-b-4424.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'UKB-b-4424:ES', 'UKB-b-4424:SE', 'UKB-b-4424:LP', 'UKB-b-4424:AF', 'UKB-b-4424:SS', 'UKB-b-4424:EZ', 'UKB-b-4424:SI', 'UKB-b-4424:NC', 'UKB-b-4424:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "elapsed time:  68.95079827308655\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 12,252, after: 12,688, consumed: 436; exec time: 68.95365858078003 seconds\n",
      "./tabular_format_gwas_data/ukb-b-4424.tsv\n",
      "Total SNPs: 9851867 | Total exec time: 91.90618109703064 seconds\n",
      "Processing: ./tabular_format_gwas_data/ukb-b-6134.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'UKB-b-6134:ES', 'UKB-b-6134:SE', 'UKB-b-6134:LP', 'UKB-b-6134:AF', 'UKB-b-6134:SS', 'UKB-b-6134:EZ', 'UKB-b-6134:SI', 'UKB-b-6134:NC', 'UKB-b-6134:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "elapsed time:  72.41368174552917\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 12,172, after: 12,588, consumed: 416; exec time: 72.41694927215576 seconds\n",
      "./tabular_format_gwas_data/ukb-b-6134.tsv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total SNPs: 9756890 | Total exec time: 95.25070977210999 seconds\n",
      "Processing: ./tabular_format_gwas_data/ukb-b-6324.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'UKB-b-6324:ES', 'UKB-b-6324:SE', 'UKB-b-6324:LP', 'UKB-b-6324:AF', 'UKB-b-6324:SS', 'UKB-b-6324:EZ', 'UKB-b-6324:SI', 'UKB-b-6324:NC', 'UKB-b-6324:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "elapsed time:  69.76533317565918\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 12,216, after: 12,592, consumed: 376; exec time: 69.76838159561157 seconds\n",
      "./tabular_format_gwas_data/ukb-b-6324.tsv\n",
      "Total SNPs: 9851867 | Total exec time: 94.46715188026428 seconds\n",
      "Processing: ./tabular_format_gwas_data/ukb-b-7663.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'UKB-b-7663:ES', 'UKB-b-7663:SE', 'UKB-b-7663:LP', 'UKB-b-7663:AF', 'UKB-b-7663:SS', 'UKB-b-7663:EZ', 'UKB-b-7663:SI', 'UKB-b-7663:NC', 'UKB-b-7663:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "elapsed time:  59.168426752090454\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 12,276, after: 12,652, consumed: 376; exec time: 59.17144012451172 seconds\n",
      "./tabular_format_gwas_data/ukb-b-7663.tsv\n",
      "Total SNPs: 8164790 | Total exec time: 78.7295835018158 seconds\n",
      "Processing: ./tabular_format_gwas_data/ukb-b-770.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'UKB-b-770:ES', 'UKB-b-770:SE', 'UKB-b-770:LP', 'UKB-b-770:AF', 'UKB-b-770:SS', 'UKB-b-770:EZ', 'UKB-b-770:SI', 'UKB-b-770:NC', 'UKB-b-770:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "elapsed time:  63.366745948791504\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 12,272, after: 12,624, consumed: 352; exec time: 63.36984586715698 seconds\n",
      "./tabular_format_gwas_data/ukb-b-770.tsv\n",
      "Total SNPs: 8625011 | Total exec time: 83.60949778556824 seconds\n",
      "Processing: ./tabular_format_gwas_data/ukb-b-8476.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'UKB-b-8476:ES', 'UKB-b-8476:SE', 'UKB-b-8476:LP', 'UKB-b-8476:AF', 'UKB-b-8476:SS', 'UKB-b-8476:EZ', 'UKB-b-8476:SI', 'UKB-b-8476:NC', 'UKB-b-8476:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "elapsed time:  66.9447968006134\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 12,236, after: 12,608, consumed: 372; exec time: 66.94777202606201 seconds\n",
      "./tabular_format_gwas_data/ukb-b-8476.tsv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total SNPs: 8862762 | Total exec time: 88.1577959060669 seconds\n",
      "Processing: ./tabular_format_gwas_data/ukb-b-323.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'UKB-b-323:ES', 'UKB-b-323:SE', 'UKB-b-323:LP', 'UKB-b-323:AF', 'UKB-b-323:SS', 'UKB-b-323:EZ', 'UKB-b-323:SI', 'UKB-b-323:NC', 'UKB-b-323:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "elapsed time:  50.07173776626587\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 12,188, after: 12,620, consumed: 432; exec time: 50.07473826408386 seconds\n",
      "./tabular_format_gwas_data/ukb-b-323.tsv\n",
      "Total SNPs: 6877802 | Total exec time: 67.82571244239807 seconds\n",
      "Processing: ./tabular_format_gwas_data/ukb-b-14699.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'UKB-b-14699:ES', 'UKB-b-14699:SE', 'UKB-b-14699:LP', 'UKB-b-14699:AF', 'UKB-b-14699:SS', 'UKB-b-14699:EZ', 'UKB-b-14699:SI', 'UKB-b-14699:NC', 'UKB-b-14699:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "elapsed time:  57.203545808792114\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 12,348, after: 12,724, consumed: 376; exec time: 57.20664715766907 seconds\n",
      "./tabular_format_gwas_data/ukb-b-14699.tsv\n",
      "Total SNPs: 7793503 | Total exec time: 75.61604571342468 seconds\n",
      "Processing: ./tabular_format_gwas_data/ukb-b-14180.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'UKB-b-14180:ES', 'UKB-b-14180:SE', 'UKB-b-14180:LP', 'UKB-b-14180:AF', 'UKB-b-14180:SS', 'UKB-b-14180:EZ', 'UKB-b-14180:SI', 'UKB-b-14180:NC', 'UKB-b-14180:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "elapsed time:  67.55441641807556\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 12,084, after: 12,520, consumed: 436; exec time: 67.55753087997437 seconds\n",
      "./tabular_format_gwas_data/ukb-b-14180.tsv\n",
      "Total SNPs: 9515295 | Total exec time: 89.78252744674683 seconds\n",
      "Processing: ./tabular_format_gwas_data/ukb-b-17243.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'UKB-b-17243:ES', 'UKB-b-17243:SE', 'UKB-b-17243:LP', 'UKB-b-17243:AF', 'UKB-b-17243:SS', 'UKB-b-17243:EZ', 'UKB-b-17243:SI', 'UKB-b-17243:NC', 'UKB-b-17243:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "elapsed time:  36.49215388298035\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 12,332, after: 12,708, consumed: 376; exec time: 36.49513053894043 seconds\n",
      "./tabular_format_gwas_data/ukb-b-17243.tsv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total SNPs: 5294160 | Total exec time: 49.026020526885986 seconds\n",
      "Processing: ./tabular_format_gwas_data/ukb-b-6358.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'UKB-b-6358:ES', 'UKB-b-6358:SE', 'UKB-b-6358:LP', 'UKB-b-6358:AF', 'UKB-b-6358:SS', 'UKB-b-6358:EZ', 'UKB-b-6358:SI', 'UKB-b-6358:NC', 'UKB-b-6358:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "elapsed time:  36.7434868812561\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 12,228, after: 12,664, consumed: 436; exec time: 36.74675154685974 seconds\n",
      "./tabular_format_gwas_data/ukb-b-6358.tsv\n",
      "Total SNPs: 5221750 | Total exec time: 49.26273274421692 seconds\n",
      "Processing: ./tabular_format_gwas_data/ukb-b-17006.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'UKB-b-17006:ES', 'UKB-b-17006:SE', 'UKB-b-17006:LP', 'UKB-b-17006:AF', 'UKB-b-17006:SS', 'UKB-b-17006:EZ', 'UKB-b-17006:SI', 'UKB-b-17006:NC', 'UKB-b-17006:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "elapsed time:  18.73118233680725\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 12,248, after: 12,684, consumed: 436; exec time: 18.73429012298584 seconds\n",
      "./tabular_format_gwas_data/ukb-b-17006.tsv\n",
      "Total SNPs: 2541601 | Total exec time: 24.623122930526733 seconds\n",
      "Processing: ./tabular_format_gwas_data/ukb-b-5779.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'UKB-b-5779:ES', 'UKB-b-5779:SE', 'UKB-b-5779:LP', 'UKB-b-5779:AF', 'UKB-b-5779:SS', 'UKB-b-5779:EZ', 'UKB-b-5779:SI', 'UKB-b-5779:NC', 'UKB-b-5779:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "elapsed time:  70.21513366699219\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 12,232, after: 12,608, consumed: 376; exec time: 70.21815180778503 seconds\n",
      "./tabular_format_gwas_data/ukb-b-5779.tsv\n",
      "Total SNPs: 9851867 | Total exec time: 94.62785410881042 seconds\n",
      "Processing: ./tabular_format_gwas_data/ukb-b-15541.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'UKB-b-15541:ES', 'UKB-b-15541:SE', 'UKB-b-15541:LP', 'UKB-b-15541:AF', 'UKB-b-15541:SS', 'UKB-b-15541:EZ', 'UKB-b-15541:SI', 'UKB-b-15541:NC', 'UKB-b-15541:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "elapsed time:  36.08348512649536\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 12,144, after: 12,504, consumed: 360; exec time: 36.08656406402588 seconds\n",
      "./tabular_format_gwas_data/ukb-b-15541.tsv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total SNPs: 4801286 | Total exec time: 47.28146028518677 seconds\n",
      "Processing: ./tabular_format_gwas_data/ukb-b-19732.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'UKB-b-19732:ES', 'UKB-b-19732:SE', 'UKB-b-19732:LP', 'UKB-b-19732:AF', 'UKB-b-19732:SS', 'UKB-b-19732:EZ', 'UKB-b-19732:SI', 'UKB-b-19732:NC', 'UKB-b-19732:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "elapsed time:  53.056336879730225\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 12,220, after: 12,596, consumed: 376; exec time: 53.059468269348145 seconds\n",
      "./tabular_format_gwas_data/ukb-b-19732.tsv\n",
      "Total SNPs: 7112788 | Total exec time: 69.99501037597656 seconds\n",
      "Processing: ./tabular_format_gwas_data/ukb-b-20289.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'UKB-b-20289:ES', 'UKB-b-20289:SE', 'UKB-b-20289:LP', 'UKB-b-20289:AF', 'UKB-b-20289:SS', 'UKB-b-20289:EZ', 'UKB-b-20289:SI', 'UKB-b-20289:NC', 'UKB-b-20289:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "elapsed time:  32.67677354812622\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 12,224, after: 12,600, consumed: 376; exec time: 32.679858922958374 seconds\n",
      "./tabular_format_gwas_data/ukb-b-20289.tsv\n",
      "Total SNPs: 4329980 | Total exec time: 42.972651958465576 seconds\n",
      "Processing: ./tabular_format_gwas_data/ukb-b-14057.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'UKB-b-14057:ES', 'UKB-b-14057:SE', 'UKB-b-14057:LP', 'UKB-b-14057:AF', 'UKB-b-14057:SS', 'UKB-b-14057:EZ', 'UKB-b-14057:SI', 'UKB-b-14057:NC', 'UKB-b-14057:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "elapsed time:  66.8626811504364\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 12,232, after: 12,668, consumed: 436; exec time: 66.86588501930237 seconds\n",
      "./tabular_format_gwas_data/ukb-b-14057.tsv\n",
      "Total SNPs: 9154200 | Total exec time: 88.40664958953857 seconds\n",
      "Processing: ./tabular_format_gwas_data/ukb-b-12963.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'UKB-b-12963:ES', 'UKB-b-12963:SE', 'UKB-b-12963:LP', 'UKB-b-12963:AF', 'UKB-b-12963:SS', 'UKB-b-12963:EZ', 'UKB-b-12963:SI', 'UKB-b-12963:NC', 'UKB-b-12963:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "elapsed time:  71.5572361946106\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 12,240, after: 12,676, consumed: 436; exec time: 71.56030249595642 seconds\n",
      "./tabular_format_gwas_data/ukb-b-12963.tsv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total SNPs: 9851867 | Total exec time: 94.66067051887512 seconds\n",
      "Processing: ./tabular_format_gwas_data/ukb-b-12417.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'UKB-b-12417:ES', 'UKB-b-12417:SE', 'UKB-b-12417:LP', 'UKB-b-12417:AF', 'UKB-b-12417:SS', 'UKB-b-12417:EZ', 'UKB-b-12417:SI', 'UKB-b-12417:NC', 'UKB-b-12417:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "elapsed time:  72.95875000953674\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 12,332, after: 12,708, consumed: 376; exec time: 72.96168327331543 seconds\n",
      "./tabular_format_gwas_data/ukb-b-12417.tsv\n",
      "Total SNPs: 9851867 | Total exec time: 96.252690076828 seconds\n",
      "Processing: ./tabular_format_gwas_data/ukb-b-11495.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'UKB-b-11495:ES', 'UKB-b-11495:SE', 'UKB-b-11495:LP', 'UKB-b-11495:AF', 'UKB-b-11495:SS', 'UKB-b-11495:EZ', 'UKB-b-11495:SI', 'UKB-b-11495:NC', 'UKB-b-11495:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "elapsed time:  69.70263910293579\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 12,232, after: 12,608, consumed: 376; exec time: 69.70581984519958 seconds\n",
      "./tabular_format_gwas_data/ukb-b-11495.tsv\n",
      "Total SNPs: 9606173 | Total exec time: 92.91030836105347 seconds\n",
      "Processing: ./tabular_format_gwas_data/ukb-b-12493.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'UKB-b-12493:ES', 'UKB-b-12493:SE', 'UKB-b-12493:LP', 'UKB-b-12493:AF', 'UKB-b-12493:SS', 'UKB-b-12493:EZ', 'UKB-b-12493:SI', 'UKB-b-12493:NC', 'UKB-b-12493:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "elapsed time:  61.27433109283447\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 12,168, after: 12,600, consumed: 432; exec time: 61.27747201919556 seconds\n",
      "./tabular_format_gwas_data/ukb-b-12493.tsv\n",
      "Total SNPs: 8361395 | Total exec time: 82.44880199432373 seconds\n"
     ]
    }
   ],
   "source": [
    "for GWAS_ID in ALL_GWAS_IDS:\n",
    "\n",
    "    generate_gwas_output_as_tsv_file(inVCF_File='./tabular_format_gwas_data/'+GWAS_ID+'.vcf.gz', writeFile=None)\n",
    "# generate_gwas_output_as_tsv_file(inVCF_File='./tabular_format_gwas_data/ukb-b-12417.vcf.gz', writeFile=None)\n",
    "# generate_gwas_output_as_tsv_file(inVCF_File='./tabular_format_gwas_data/ukb-b-11495.vcf.gz', writeFile=None)\n",
    "# generate_gwas_output_as_tsv_file(inVCF_File='./tabular_format_gwas_data/ukb-b-12493.vcf.gz', writeFile=None)\n",
    "# generate_gwas_output_as_tsv_file(inVCF_File='./tabular_format_gwas_data/ukb-b-19732.vcf.gz', writeFile=None)\n",
    "# generate_gwas_output_as_tsv_file(inVCF_File='./tabular_format_gwas_data/ukb-b-17006.vcf.gz', writeFile=None)\n",
    "# generate_gwas_output_as_tsv_file(inVCF_File='./tabular_format_gwas_data/ukb-b-5779.vcf.gz', writeFile=None)\n",
    "# generate_gwas_output_as_tsv_file(inVCF_File='./tabular_format_gwas_data/ukb-b-15541.vcf.gz', writeFile=None)\n",
    "# need to just specify the file path here\n",
    "# ebi-a-GCST005920.vcf.gz\n",
    "# ebi-a-GCST005923.vcf.gz\n",
    "# ukb-b-14699.vcf.gz\n",
    "# ukb-b-323.vcf.gz\n",
    "# ukb-b-6358\n",
    "# next update in the 'GWAS_datasets_to_consider.xlsx'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ' abc def\\n'.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10**(-1*0.200659) #0.6300007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %pip install openpyxl\n",
    "import pandas as pd\n",
    "\n",
    "category_map = {\n",
    "    'Continuous' : 'beta', \n",
    "    'Categorical Ordered (assumed continuous)': 'beta',\n",
    "    'Binary': 'or',\n",
    "    'NA (Possibly binary)': 'or'\n",
    "}\n",
    "\n",
    "\n",
    "df = pd.read_excel('GWAS_datasets_to_consider.xlsx', engine='openpyxl')[['GWAS_ID', 'Trait', 'Category']]\n",
    "# print(df)\n",
    "# print(df['Category'].unique())\n",
    "# GWAS_ID = 'ieu-b-111'\n",
    "# category = category_map[df[df['GWAS_ID'] == GWAS_ID].to_numpy()[0, 2]] \n",
    "# category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "['ukb-b-13806', 'ukb-d-20405_0', 'ukb-d-20405_1', 'ukb-d-20405_2', 'met-d-Total_C', 'ieu-b-109', 'ieu-b-110', 'ieu-b-111', 'ieu-b-25', 'ieu-b-38', 'ieu-b-39', 'ukb-a-257', 'ukb-b-12064', 'ukb-b-17627', 'ukb-b-18275', 'ukb-b-19953', 'ukb-b-2209', 'ukb-b-3957', 'ukb-b-4424', 'ukb-b-6134', 'ukb-b-6324', 'ukb-b-7663', 'ukb-b-770', 'ukb-b-8476', 'ukb-b-323', 'ukb-b-14699', 'ukb-b-14180', 'ukb-b-17243', 'ukb-b-6358', 'ukb-b-17006', 'ukb-b-5779', 'ukb-b-15541', 'ukb-b-19732', 'ukb-b-20289', 'ukb-b-14057', 'ukb-b-12963', 'ukb-b-12417', 'ukb-b-11495', 'ukb-b-12493']\n",
      "{'ukb-b-13806': 'or', 'ukb-d-20405_0': 'or', 'ukb-d-20405_1': 'or', 'ukb-d-20405_2': 'or', 'met-d-Total_C': 'beta', 'ieu-b-109': 'beta', 'ieu-b-110': 'beta', 'ieu-b-111': 'beta', 'ieu-b-25': 'beta', 'ieu-b-38': 'beta', 'ieu-b-39': 'beta', 'ukb-a-257': 'or', 'ukb-b-12064': 'or', 'ukb-b-17627': 'beta', 'ukb-b-18275': 'or', 'ukb-b-19953': 'beta', 'ukb-b-2209': 'beta', 'ukb-b-3957': 'beta', 'ukb-b-4424': 'beta', 'ukb-b-6134': 'beta', 'ukb-b-6324': 'beta', 'ukb-b-7663': 'or', 'ukb-b-770': 'beta', 'ukb-b-8476': 'or', 'ukb-b-323': 'or', 'ukb-b-14699': 'or', 'ukb-b-14180': 'or', 'ukb-b-17243': 'or', 'ukb-b-6358': 'or', 'ukb-b-17006': 'or', 'ukb-b-5779': 'beta', 'ukb-b-15541': 'or', 'ukb-b-19732': 'or', 'ukb-b-20289': 'or', 'ukb-b-14057': 'or', 'ukb-b-12963': 'beta', 'ukb-b-12417': 'beta', 'ukb-b-11495': 'or', 'ukb-b-12493': 'or'}\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "# df = pd.read_excel('GWAS_datasets_to_consider.xlsx', engine='openpyxl')[['GWAS_ID', 'Trait', 'Category']]\n",
    "# all_gwas_vcf_files = glob('/mnt/c/Users/HP/Downloads/Compressed/GWAS/*')\n",
    "# ROOT = '/mnt/c/Users/HP/Downloads/Compressed/GWAS/'\n",
    "# ALL_GWAS_IDS = list(set(df['GWAS_ID'].to_numpy().tolist()) - {'bbj-a-46', 'bbj-a-78', 'ieu-a-1283', 'ukb-a-257','ukb-b-2209','ukb-b-17627','ieub-109','ieu-b-110','ieu-b-111','met-d-Total_C'})\n",
    "# bbj-a-78,ukb-a-257,bbj-a-46\n",
    "# ALL_GWAS_IDS = list(set(df['GWAS_ID'].to_numpy().tolist()) - { 'ieu-a-1283','bbj-a-46', 'bbj-a-78'})\n",
    "# ALL_GWAS_IDS = list(set(df['GWAS_ID'].to_numpy().tolist()) - {  'ieu-b-109','ieu-b-110','ieu-b-111','met-d-Total_C','ukb-b-2209','ukb-b-17627','ukb-a-257','ieu-a-1283','bbj-a-46', 'bbj-a-78','ukb-b-14180','ukb-b-13806','ukb-b-12064','ukb-b-323','ukb-b-14699','ukb-b-14699','ukb-b-5779'})\n",
    "ALL_GWAS_IDS = list(df['GWAS_ID'].to_numpy().tolist()) \n",
    "\n",
    "print(len(ALL_GWAS_IDS))\n",
    "print(ALL_GWAS_IDS)\n",
    "\n",
    "base_files = {}\n",
    "\n",
    "for GWAS_ID in ALL_GWAS_IDS:\n",
    "    \n",
    "#     file = ROOT + GWAS_ID + '.vcf.gz'\n",
    "#     base_files[GWAS_ID] = category_map[df[df['GWAS_ID'] == GWAS_ID].to_numpy()[0, 2]]\n",
    "    base_files[GWAS_ID] = df[df['GWAS_ID'] == GWAS_ID].to_numpy()[0, 2]\n",
    "#     base_files[GWAS_ID]=category_map[base_files[GWAS_ID]]\n",
    "    \n",
    "print(base_files)\n",
    "#     generate_gwas_output_as_tsv_file(inVCF_File=file, writeFile=None)\n",
    "# print(name_mapping)\n",
    "# print(name_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ukb-b-13806': 'or', 'ukb-d-20405_0': 'or', 'ukb-d-20405_1': 'or', 'ukb-d-20405_2': 'or', 'met-d-Total_C': 'beta', 'ieu-b-109': 'beta', 'ieu-b-110': 'beta', 'ieu-b-111': 'beta', 'ieu-b-25': 'beta', 'ieu-b-38': 'beta', 'ieu-b-39': 'beta', 'ukb-a-257': 'or', 'ukb-b-12064': 'or', 'ukb-b-17627': 'beta', 'ukb-b-18275': 'or', 'ukb-b-19953': 'beta', 'ukb-b-2209': 'beta', 'ukb-b-3957': 'beta', 'ukb-b-4424': 'beta', 'ukb-b-6134': 'beta', 'ukb-b-6324': 'beta', 'ukb-b-7663': 'or', 'ukb-b-770': 'beta', 'ukb-b-8476': 'or', 'ukb-b-323': 'or', 'ukb-b-14699': 'or', 'ukb-b-14180': 'or', 'ukb-b-17243': 'or', 'ukb-b-6358': 'or', 'ukb-b-17006': 'or', 'ukb-b-5779': 'beta', 'ukb-b-15541': 'or', 'ukb-b-19732': 'or', 'ukb-b-20289': 'or', 'ukb-b-14057': 'or', 'ukb-b-12963': 'beta', 'ukb-b-12417': 'beta', 'ukb-b-11495': 'or', 'ukb-b-12493': 'or'}\n",
      "ukb-b-13806\n",
      "ukb-d-20405_0\n",
      "ukb-d-20405_1\n",
      "ukb-d-20405_2\n",
      "met-d-Total_C\n",
      "ieu-b-109\n",
      "ieu-b-110\n",
      "ieu-b-111\n",
      "ieu-b-25\n",
      "ieu-b-38\n",
      "ieu-b-39\n",
      "ukb-a-257\n",
      "ukb-b-12064\n",
      "ukb-b-17627\n",
      "ukb-b-18275\n",
      "ukb-b-19953\n",
      "ukb-b-2209\n",
      "ukb-b-3957\n",
      "ukb-b-4424\n",
      "ukb-b-6134\n",
      "ukb-b-6324\n",
      "ukb-b-7663\n",
      "ukb-b-770\n",
      "ukb-b-8476\n",
      "ukb-b-323\n",
      "ukb-b-14699\n",
      "ukb-b-14180\n",
      "ukb-b-17243\n",
      "ukb-b-6358\n",
      "ukb-b-17006\n",
      "ukb-b-5779\n",
      "ukb-b-15541\n",
      "ukb-b-19732\n",
      "ukb-b-20289\n",
      "ukb-b-14057\n",
      "ukb-b-12963\n",
      "ukb-b-12417\n",
      "ukb-b-11495\n",
      "ukb-b-12493\n"
     ]
    }
   ],
   "source": [
    "# base_files\n",
    "print(base_files)\n",
    "for GWAS_ID in base_files:\n",
    "    print(GWAS_ID)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ADNIMERGE.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m gender_map \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFemale\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMale\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m}\n\u001b[0;32m----> 2\u001b[0m ADNIMERGE \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mADNIMERGE.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_gender_and_age\u001b[39m(PTID):\n\u001b[1;32m      4\u001b[0m     gender \u001b[38;5;241m=\u001b[39m ADNIMERGE[ADNIMERGE[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPTID\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m PTID][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPTGENDER\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39munique()[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/ad_venv_2/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ad_venv_2/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ad_venv_2/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ad_venv_2/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/envs/ad_venv_2/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ad_venv_2/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/envs/ad_venv_2/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ADNIMERGE.csv'"
     ]
    }
   ],
   "source": [
    "gender_map = {'Female': 0,'Male': 1}\n",
    "ADNIMERGE = pd.read_csv('ADNIMERGE.csv')\n",
    "def get_gender_and_age(PTID):\n",
    "    gender = ADNIMERGE[ADNIMERGE['PTID'] == PTID]['PTGENDER'].dropna().unique()[0]\n",
    "    age = ADNIMERGE[ADNIMERGE['PTID'] == PTID]['AGE'].dropna().unique()[0]\n",
    "    return str(gender_map[gender]) + ' ' + str(age)\n",
    "\n",
    "# NUM_TRAINING_SAMPLES = int(830 * .7)\n",
    "# print('NUM_TRAINING_SAMPLES:', NUM_TRAINING_SAMPLES)\n",
    "# f_writable = open('./COVAR_FILE.txt', 'w')\n",
    "# f_TRAINING_SAMPLES = open('./TRAINING_SAMPLES.txt', 'w')\n",
    "# with open('/mnt/c/Users/HP/Documents/GWA_tutorial/2_Population_stratification/covar_mds.txt') as f:\n",
    "#     for i, line in enumerate(f):\n",
    "#         if 'FID IID' in line:\n",
    "#             line = line[:-1] + ' GENDER AGE\\n'\n",
    "#         else:\n",
    "#             line = line[:-1] + ' ' + get_gender_and_age(PTID=line.split(' ')[1]) + '\\n'\n",
    "#         if i < NUM_TRAINING_SAMPLES:\n",
    "#             f_TRAINING_SAMPLES.write(' '.join(line.split(' ')[:2])+'\\n')\n",
    "#         f_writable.write(line)\n",
    "# #         print(line)\n",
    "# f_writable.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_prsice(GWAS_ID, redo=False):\n",
    "#     TARGET_DATA = '/mnt/c/Users/HP/Documents/GWA_tutorial/2_Population_stratification/ADNI' # old and smaller dataset\n",
    "    #jei data diye ultimate train kora hocche model e\n",
    "    #larger dataset er protita data er jnno protita trait er prscore ber kora hocche\n",
    "    TARGET_DATA = '../larger_dataset/larger_dataset' # new and larger dataset\n",
    "    '''\n",
    "    return_status --> 0: success | 256: Error. Execusion Halted | 2: \n",
    "    '''\n",
    "#     need to alter between these two if needed\n",
    "    if os.path.isfile(f'./PRSice_output/{GWAS_ID}/'):\n",
    "#     if True:\n",
    "        return_status = os.system(f'mkdir ./PRSice_output/{GWAS_ID}/')\n",
    "        print('0:', return_status)\n",
    "        if return_status == 256 and not redo:\n",
    "            return return_status\n",
    "    print('stat',{base_files[GWAS_ID]})\n",
    "#     prsice_command = f'Rscript ./PRSice_linux/PRSice.R \\\n",
    "#         --dir ./PRSice_output \\\n",
    "#         --prsice ./PRSice_linux/PRSice_linux \\\n",
    "#         --base ./tabular_format_gwas_data/{GWAS_ID}.tsv \\\n",
    "#         --target {TARGET_DATA} \\\n",
    "#         --thread 2 \\\n",
    "#         --stat {base_files[GWAS_ID].upper()} \\\n",
    "#         --{base_files[GWAS_ID]} \\\n",
    "#         --binary-target F \\\n",
    "#         --quantile 10 \\\n",
    "#         --out ./PRSice_output/{GWAS_ID}/{GWAS_ID} \\\n",
    "#         --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat {GWAS_ID.upper()}:ES --pvalue PVAL_generated_from_LP \\\n",
    "#         --score std \\\n",
    "#         --cov ../larger_dataset/COVAR_FILE_bigger_dataset.txt \\\n",
    "#         --extract ./PRSice_output/{GWAS_ID}/{GWAS_ID}.valid'\n",
    "    if os.path.isfile(f'./PRSice_output/{GWAS_ID}/{GWAS_ID}.valid'):\n",
    "        prsice_command = f'Rscript ./PRSice_linux/PRSice.R \\\n",
    "            --dir ./PRSice_output \\\n",
    "            --prsice ./PRSice_linux/PRSice_linux \\\n",
    "            --base ./tabular_format_gwas_data/{GWAS_ID}.tsv \\\n",
    "            --target {TARGET_DATA} \\\n",
    "            --thread 2 \\\n",
    "            --stat {base_files[GWAS_ID].upper()} \\\n",
    "            --{base_files[GWAS_ID]} \\\n",
    "            --binary-target F \\\n",
    "            --quantile 10 \\\n",
    "            --out ./PRSice_output/{GWAS_ID}/{GWAS_ID} \\\n",
    "            --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat {GWAS_ID.upper()}:ES --pvalue PVAL_generated_from_LP \\\n",
    "            --score std \\\n",
    "            --cov ../larger_dataset/COVAR_FILE_bigger_dataset.txt \\\n",
    "            --extract ./PRSice_output/{GWAS_ID}/{GWAS_ID}.valid'\n",
    "    else :\n",
    "        prsice_command = f'Rscript ./PRSice_linux/PRSice.R \\\n",
    "            --dir ./PRSice_output \\\n",
    "            --prsice ./PRSice_linux/PRSice_linux \\\n",
    "            --base ./tabular_format_gwas_data/{GWAS_ID}.tsv \\\n",
    "            --target {TARGET_DATA} \\\n",
    "            --thread 2 \\\n",
    "            --stat {base_files[GWAS_ID].upper()} \\\n",
    "            --{base_files[GWAS_ID]} \\\n",
    "            --binary-target F \\\n",
    "            --quantile 10 \\\n",
    "            --out ./PRSice_output/{GWAS_ID}/{GWAS_ID} \\\n",
    "            --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat {GWAS_ID.upper()}:ES --pvalue PVAL_generated_from_LP \\\n",
    "            --score std \\\n",
    "            --cov ../larger_dataset/COVAR_FILE_bigger_dataset.txt '\n",
    "#         print(prsice_command)\n",
    "#         print('stat',{base_files[GWAS_ID]})\n",
    "#         return_status = os.system(prsice_command) # generate the file named {GWAS_ID}.valid\n",
    "#         print('1:', return_status)\n",
    "#         return_status = os.system('echo \"===== Done =====\"')\n",
    "#         print('2:', return_status) \n",
    "\n",
    "    #             running second time with .valid extraction\n",
    "#         prsice_command = f'Rscript ./PRSice_linux/PRSice.R \\\n",
    "#             --dir ./PRSice_output \\\n",
    "#             --prsice ./PRSice_linux/PRSice_linux \\\n",
    "#             --base ./tabular_format_gwas_data/{GWAS_ID}.tsv \\\n",
    "#             --target {TARGET_DATA} \\\n",
    "#             --thread 2 \\\n",
    "#             --stat {base_files[GWAS_ID].upper()} \\\n",
    "#             --{base_files[GWAS_ID]} \\\n",
    "#             --binary-target F \\\n",
    "#             --quantile 10 \\\n",
    "#             --out ./PRSice_output/{GWAS_ID}/{GWAS_ID} \\\n",
    "#             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat {GWAS_ID.upper()}:ES --pvalue PVAL_generated_from_LP \\\n",
    "#             --score std \\\n",
    "#             --cov ../larger_dataset/COVAR_FILE_bigger_dataset.txt \\\n",
    "#             --extract ./PRSice_output/{GWAS_ID}/{GWAS_ID}.valid'\n",
    "        \n",
    "\n",
    "# #     return_status = os.system(prsice_command + '  --keep ./TRAINING_SAMPLES.txt') # generate the file named {GWAS_ID}.valid\n",
    "# #     return_status = os.system(prsice_command) # generate the file named {GWAS_ID}.validukb-b-12963\n",
    "# #     print('1a:', return_status)\n",
    "# #     return\n",
    "# #     if os.path.isfile(f'./PRSice_output/{GWAS_ID}/{GWAS_ID}.valid'): \n",
    "# #         prsice_command += f' --extract ./PRSice_output/{GWAS_ID}/{GWAS_ID}.valid' \n",
    "# #         return_status = os.system(prsice_command + '  --keep ./TRAINING_SAMPLES.txt') # perform the regression analysis on the training samples only and choose the best p-value-threshold\n",
    "# #         return_status = os.system(prsice_command) # perform the regression analysis on the training samples only and choose the best p-value-threshold\n",
    "# #         print('1b:', return_status)\n",
    "# #         if return_status != 0:\n",
    "# # #             return_status = os.system(prsice_command) # perform the regression analysis on the training samples only and choose the best p-value-threshold\n",
    "# #             print('1c:', return_status)\n",
    "# #     return_status = os.system(prsice_command + '  --all-score --no-regress') # Do not perform the regression analysis and simply output all PRS.\n",
    "# #     return_status = os.system(prsice_command + '  --all-score') # Do not perform the regression analysis and simply output all PRS.\n",
    "# #     print('2:', return_status)\n",
    "#     # in later steps, select the PRS values for the selected p-value-threshold for all the samples (both training and testing)\n",
    "    print(prsice_command)\n",
    "    print('stat',{base_files[GWAS_ID]})\n",
    "    return_status = os.system(prsice_command) # generate the file named {GWAS_ID}.valid\n",
    "    print('1:', return_status)\n",
    "    return_status = os.system('echo \"===== Done =====\"')\n",
    "    print('2:', return_status) \n",
    "#     os.system(f'mv ./prsice_output/{GWAS_ID}.* ./prsice_output/{GWAS_ID}/')\n",
    "# https://github.com/adiamb/Remove-duplicate-snps-plink"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For ADNI Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prsice_for_adni(GWAS_ID, redo=False):\n",
    "#     TARGET_DATA = '/mnt/c/Users/HP/Documents/GWA_tutorial/2_Population_stratification/ADNI' # old and smaller dataset\n",
    "\n",
    "#     TARGET_DATA = '../larger_dataset/larger_dataset' # new and larger dataset\n",
    "\n",
    "#     TARGET_DATA = \"../../../GWA_tutorial-master/1_QC_GWAS/HapMap_3_r3_12\" \n",
    "    TARGET_DATA = \"../../../GWA_tutorial-master/2_Population_stratification/HapMap_3_r3_13\" \n",
    "    \n",
    "#     this dataset may need to be changed\n",
    "\n",
    "    '''\n",
    "    return_status --> 0: success | 256: Error. Execusion Halted | 2: \n",
    "    '''\n",
    "#     need to alter between these two if needed\n",
    "    if os.path.isfile(f'./PRSice_output/{GWAS_ID}/'):\n",
    "#     if True:\n",
    "        return_status = os.system(f'mkdir ./PRSice_output/{GWAS_ID}/')\n",
    "        print('0:', return_status)\n",
    "        if return_status == 256 and not redo:\n",
    "            return return_status\n",
    "    print('stat',{base_files[GWAS_ID]})\n",
    "#     prsice_command = f'Rscript ./PRSice_linux/PRSice.R \\\n",
    "#         --dir ./PRSice_output \\\n",
    "#         --prsice ./PRSice_linux/PRSice_linux \\\n",
    "#         --base ./tabular_format_gwas_data/{GWAS_ID}.tsv \\\n",
    "#         --target {TARGET_DATA} \\\n",
    "#         --thread 2 \\\n",
    "#         --stat {base_files[GWAS_ID].upper()} \\\n",
    "#         --{base_files[GWAS_ID]} \\\n",
    "#         --binary-target F \\\n",
    "#         --quantile 10 \\\n",
    "#         --out ./PRSice_output/{GWAS_ID}/{GWAS_ID} \\\n",
    "#         --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat {GWAS_ID.upper()}:ES --pvalue PVAL_generated_from_LP \\\n",
    "#         --score std \\\n",
    "#         --cov ../larger_dataset/COVAR_FILE_bigger_dataset.txt \\\n",
    "#         --extract ./PRSice_output/{GWAS_ID}/{GWAS_ID}.valid'\n",
    "    if os.path.isfile(f'./PRSice_output/{GWAS_ID}/{GWAS_ID}.valid'):\n",
    "        prsice_command = f'Rscript ./PRSice_linux/PRSice.R \\\n",
    "            --dir ./PRSice_output \\\n",
    "            --prsice ./PRSice_linux/PRSice_linux \\\n",
    "            --base ./tabular_format_gwas_data/{GWAS_ID}.tsv \\\n",
    "            --target {TARGET_DATA} \\\n",
    "            --thread 2 \\\n",
    "            --stat {base_files[GWAS_ID].upper()} \\\n",
    "            --{base_files[GWAS_ID]} \\\n",
    "            --binary-target F \\\n",
    "            --quantile 10 \\\n",
    "            --out ./PRSice_output/{GWAS_ID}/{GWAS_ID} \\\n",
    "            --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat {GWAS_ID.upper()}:ES --pvalue PVAL_generated_from_LP \\\n",
    "            --score std \\\n",
    "            --cov \"../../../GWA_tutorial-master/2_Population_stratification/covar_mds.txt\" \\\n",
    "            --extract ./PRSice_output/{GWAS_ID}/{GWAS_ID}.valid'\n",
    "    else :\n",
    "        prsice_command = f'Rscript ./PRSice_linux/PRSice.R \\\n",
    "            --dir ./PRSice_output \\\n",
    "            --prsice ./PRSice_linux/PRSice_linux \\\n",
    "            --base ./tabular_format_gwas_data/{GWAS_ID}.tsv \\\n",
    "            --target {TARGET_DATA} \\\n",
    "            --thread 2 \\\n",
    "            --stat {base_files[GWAS_ID].upper()} \\\n",
    "            --{base_files[GWAS_ID]} \\\n",
    "            --binary-target F \\\n",
    "            --quantile 10 \\\n",
    "            --out ./PRSice_output/{GWAS_ID}/{GWAS_ID} \\\n",
    "            --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat {GWAS_ID.upper()}:ES --pvalue PVAL_generated_from_LP \\\n",
    "            --score std \\\n",
    "            --cov \"../../../GWA_tutorial-master/2_Population_stratification/covar_mds.txt\" '\n",
    "#         print(prsice_command)\n",
    "#         print('stat',{base_files[GWAS_ID]})\n",
    "#         return_status = os.system(prsice_command) # generate the file named {GWAS_ID}.valid\n",
    "#         print('1:', return_status)\n",
    "#         return_status = os.system('echo \"===== Done =====\"')\n",
    "#         print('2:', return_status) \n",
    "\n",
    "    #             running second time with .valid extraction\n",
    "#         prsice_command = f'Rscript ./PRSice_linux/PRSice.R \\\n",
    "#             --dir ./PRSice_output \\\n",
    "#             --prsice ./PRSice_linux/PRSice_linux \\\n",
    "#             --base ./tabular_format_gwas_data/{GWAS_ID}.tsv \\\n",
    "#             --target {TARGET_DATA} \\\n",
    "#             --thread 2 \\\n",
    "#             --stat {base_files[GWAS_ID].upper()} \\\n",
    "#             --{base_files[GWAS_ID]} \\\n",
    "#             --binary-target F \\\n",
    "#             --quantile 10 \\\n",
    "#             --out ./PRSice_output/{GWAS_ID}/{GWAS_ID} \\\n",
    "#             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat {GWAS_ID.upper()}:ES --pvalue PVAL_generated_from_LP \\\n",
    "#             --score std \\\n",
    "#             --cov ../larger_dataset/COVAR_FILE_bigger_dataset.txt \\\n",
    "#             --extract ./PRSice_output/{GWAS_ID}/{GWAS_ID}.valid'\n",
    "        \n",
    "\n",
    "# #     return_status = os.system(prsice_command + '  --keep ./TRAINING_SAMPLES.txt') # generate the file named {GWAS_ID}.valid\n",
    "# #     return_status = os.system(prsice_command) # generate the file named {GWAS_ID}.validukb-b-12963\n",
    "# #     print('1a:', return_status)\n",
    "# #     return\n",
    "# #     if os.path.isfile(f'./PRSice_output/{GWAS_ID}/{GWAS_ID}.valid'): \n",
    "# #         prsice_command += f' --extract ./PRSice_output/{GWAS_ID}/{GWAS_ID}.valid' \n",
    "# #         return_status = os.system(prsice_command + '  --keep ./TRAINING_SAMPLES.txt') # perform the regression analysis on the training samples only and choose the best p-value-threshold\n",
    "# #         return_status = os.system(prsice_command) # perform the regression analysis on the training samples only and choose the best p-value-threshold\n",
    "# #         print('1b:', return_status)\n",
    "# #         if return_status != 0:\n",
    "# # #             return_status = os.system(prsice_command) # perform the regression analysis on the training samples only and choose the best p-value-threshold\n",
    "# #             print('1c:', return_status)\n",
    "# #     return_status = os.system(prsice_command + '  --all-score --no-regress') # Do not perform the regression analysis and simply output all PRS.\n",
    "# #     return_status = os.system(prsice_command + '  --all-score') # Do not perform the regression analysis and simply output all PRS.\n",
    "# #     print('2:', return_status)\n",
    "#     # in later steps, select the PRS values for the selected p-value-threshold for all the samples (both training and testing)\n",
    "    print(prsice_command)\n",
    "    print('stat',{base_files[GWAS_ID]})\n",
    "    return_status = os.system(prsice_command) # generate the file named {GWAS_ID}.valid\n",
    "    print('1:', return_status)\n",
    "    return_status = os.system('echo \"===== Done =====\"')\n",
    "    print('2:', return_status) \n",
    "#     os.system(f'mv ./prsice_output/{GWAS_ID}.* ./prsice_output/{GWAS_ID}/')\n",
    "# https://github.com/adiamb/Remove-duplicate-snps-plink"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For larger dataset generated by us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Change the TARGET_DATA folder and also in the script change the cov source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prsice_for_larger_by_us(GWAS_ID, redo=False):\n",
    "#     TARGET_DATA = '/mnt/c/Users/HP/Documents/GWA_tutorial/2_Population_stratification/ADNI' # old and smaller dataset\n",
    "    #jei data diye ultimate train kora hocche model e\n",
    "    #larger dataset er protita data er jnno protita trait er prscore ber kora hocche\n",
    "    TARGET_DATA = '../larger_dataset_by_naeem2/larger_dataset' # new and larger dataset\n",
    "    '''\n",
    "    return_status --> 0: success | 256: Error. Execusion Halted | 2: \n",
    "    '''\n",
    "#     need to alter between these two if needed\n",
    "#     if not os.path.isfile(f'./PRSice_output/{GWAS_ID}/'):\n",
    "#     if True:\n",
    "#         return_status = os.system(f'mkdir ./PRSice_output/{GWAS_ID}/')\n",
    "#         print('0:', return_status)\n",
    "#         if return_status == 256 and not redo:\n",
    "#             return return_status\n",
    "    print('stat',{base_files[GWAS_ID]})\n",
    "#     prsice_command = f'Rscript ./PRSice_linux/PRSice.R \\\n",
    "#         --dir ./PRSice_output \\\n",
    "#         --prsice ./PRSice_linux/PRSice_linux \\\n",
    "#         --base ./tabular_format_gwas_data/{GWAS_ID}.tsv \\\n",
    "#         --target {TARGET_DATA} \\\n",
    "#         --thread 2 \\\n",
    "#         --stat {base_files[GWAS_ID].upper()} \\\n",
    "#         --{base_files[GWAS_ID]} \\\n",
    "#         --binary-target F \\\n",
    "#         --quantile 10 \\\n",
    "#         --out ./PRSice_output/{GWAS_ID}/{GWAS_ID} \\\n",
    "#         --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat {GWAS_ID.upper()}:ES --pvalue PVAL_generated_from_LP \\\n",
    "#         --score std \\\n",
    "#         --cov ../larger_dataset/COVAR_FILE_bigger_dataset.txt \\\n",
    "#         --extract ./PRSice_output/{GWAS_ID}/{GWAS_ID}.valid'\n",
    "    if os.path.isfile(f'./PRSice_output/{GWAS_ID}/{GWAS_ID}.valid'):\n",
    "        prsice_command = f'Rscript ./PRSice_linux/PRSice.R \\\n",
    "            --dir ./PRSice_output \\\n",
    "            --prsice ./PRSice_linux/PRSice_linux \\\n",
    "            --base ./tabular_format_gwas_data/{GWAS_ID}.tsv \\\n",
    "            --target {TARGET_DATA} \\\n",
    "            --thread 8 \\\n",
    "            --stat {base_files[GWAS_ID].upper()} \\\n",
    "            --{base_files[GWAS_ID]} \\\n",
    "            --binary-target F \\\n",
    "            --quantile 10 \\\n",
    "            --out ./PRSice_output/{GWAS_ID}/{GWAS_ID} \\\n",
    "            --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat {GWAS_ID.upper()}:ES --pvalue PVAL_generated_from_LP \\\n",
    "            --score std \\\n",
    "            --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \\\n",
    "            --extract ./PRSice_output/{GWAS_ID}/{GWAS_ID}.valid'\n",
    "    else :\n",
    "        prsice_command = f'Rscript ./PRSice_linux/PRSice.R \\\n",
    "            --dir ./PRSice_output \\\n",
    "            --prsice ./PRSice_linux/PRSice_linux \\\n",
    "            --base ./tabular_format_gwas_data/{GWAS_ID}.tsv \\\n",
    "            --target {TARGET_DATA} \\\n",
    "            --thread 8 \\\n",
    "            --stat {base_files[GWAS_ID].upper()} \\\n",
    "            --{base_files[GWAS_ID]} \\\n",
    "            --binary-target F \\\n",
    "            --quantile 10 \\\n",
    "            --out ./PRSice_output/{GWAS_ID}/{GWAS_ID} \\\n",
    "            --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat {GWAS_ID.upper()}:ES --pvalue PVAL_generated_from_LP \\\n",
    "            --score std \\\n",
    "            --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt '\n",
    "#         print(prsice_command)\n",
    "#         print('stat',{base_files[GWAS_ID]})\n",
    "#         return_status = os.system(prsice_command) # generate the file named {GWAS_ID}.valid\n",
    "#         print('1:', return_status)\n",
    "#         return_status = os.system('echo \"===== Done =====\"')\n",
    "#         print('2:', return_status) \n",
    "\n",
    "    #             running second time with .valid extraction\n",
    "#         prsice_command = f'Rscript ./PRSice_linux/PRSice.R \\\n",
    "#             --dir ./PRSice_output \\\n",
    "#             --prsice ./PRSice_linux/PRSice_linux \\\n",
    "#             --base ./tabular_format_gwas_data/{GWAS_ID}.tsv \\\n",
    "#             --target {TARGET_DATA} \\\n",
    "#             --thread 2 \\\n",
    "#             --stat {base_files[GWAS_ID].upper()} \\\n",
    "#             --{base_files[GWAS_ID]} \\\n",
    "#             --binary-target F \\\n",
    "#             --quantile 10 \\\n",
    "#             --out ./PRSice_output/{GWAS_ID}/{GWAS_ID} \\\n",
    "#             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat {GWAS_ID.upper()}:ES --pvalue PVAL_generated_from_LP \\\n",
    "#             --score std \\\n",
    "#             --cov ../larger_dataset/COVAR_FILE_bigger_dataset.txt \\\n",
    "#             --extract ./PRSice_output/{GWAS_ID}/{GWAS_ID}.valid'\n",
    "        \n",
    "\n",
    "# #     return_status = os.system(prsice_command + '  --keep ./TRAINING_SAMPLES.txt') # generate the file named {GWAS_ID}.valid\n",
    "# #     return_status = os.system(prsice_command) # generate the file named {GWAS_ID}.validukb-b-12963\n",
    "# #     print('1a:', return_status)\n",
    "# #     return\n",
    "# #     if os.path.isfile(f'./PRSice_output/{GWAS_ID}/{GWAS_ID}.valid'): \n",
    "# #         prsice_command += f' --extract ./PRSice_output/{GWAS_ID}/{GWAS_ID}.valid' \n",
    "# #         return_status = os.system(prsice_command + '  --keep ./TRAINING_SAMPLES.txt') # perform the regression analysis on the training samples only and choose the best p-value-threshold\n",
    "# #         return_status = os.system(prsice_command) # perform the regression analysis on the training samples only and choose the best p-value-threshold\n",
    "# #         print('1b:', return_status)\n",
    "# #         if return_status != 0:\n",
    "# # #             return_status = os.system(prsice_command) # perform the regression analysis on the training samples only and choose the best p-value-threshold\n",
    "# #             print('1c:', return_status)\n",
    "# #     return_status = os.system(prsice_command + '  --all-score --no-regress') # Do not perform the regression analysis and simply output all PRS.\n",
    "# #     return_status = os.system(prsice_command + '  --all-score') # Do not perform the regression analysis and simply output all PRS.\n",
    "# #     print('2:', return_status)\n",
    "#     # in later steps, select the PRS values for the selected p-value-threshold for all the samples (both training and testing)\n",
    "    print(prsice_command)\n",
    "    print('stat',{base_files[GWAS_ID]})\n",
    "    return_status = os.system(prsice_command) # generate the file named {GWAS_ID}.valid\n",
    "    print('1:', return_status)\n",
    "    return_status = os.system('echo \"===== Done =====\"')\n",
    "    print('2:', return_status) \n",
    "#     os.system(f'mv ./prsice_output/{GWAS_ID}.* ./prsice_output/{GWAS_ID}/')\n",
    "# https://github.com/adiamb/Remove-duplicate-snps-plink"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes on run_prsice\n",
    "\n",
    "for each of the data ( individual ) that we have in target dataset, we use our built psrice framework to find out the prs value. so we now know the PRS for target dataset IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------counter  2  ------------------------------------\n",
      "*****GWAS ID IS***** ukb-d-20405_0\n",
      "stat {'or'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ukb-d-20405_0.tsv             --target ../larger_dataset_by_naeem2/larger_dataset             --thread 8             --stat OR             --or             --binary-target F             --quantile 10             --out ./PRSice_output/ukb-d-20405_0/ukb-d-20405_0             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat UKB-D-20405_0:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ukb-d-20405_0/ukb-d-20405_0.valid\n",
      "stat {'or'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.3 (2020-08-05) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-11-19 05:07:22\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ukb-d-20405_0.tsv \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ukb-d-20405_0/ukb-d-20405_0.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --or  \\\n",
      "    --out ./PRSice_output/ukb-d-20405_0/ukb-d-20405_0 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 1294743028 \\\n",
      "    --snp ID \\\n",
      "    --stat UKB-D-20405_0:ES \\\n",
      "    --target ../larger_dataset_by_naeem2/larger_dataset \\\n",
      "    --thread 8 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset_by_naeem2/larger_dataset (bed) \n",
      "\n",
      "Start processing ukb-d-20405_0 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ukb-d-20405_0.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tUKB-D-20405_0:ES\tUKB-D-20405_0:SE\tUKB-D-20405_0:LP\tUKB-D-20405_0:AF\tUKB-D-20405_0:SS\tUKB-D-20405_0:EZ\tUKB-D-20405_0:SI\tUKB-D-20405_0:NC\tUKB-D-20405_0:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "13571659 variant(s) observed in base file, with: \n",
      "10323716 variant(s) excluded based on user input \n",
      "3247943 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "4579903 variant(s) not found in previous data \n",
      "387 variant(s) with mismatch information \n",
      "3247943 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 246387 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s) with p-value between 0.1 and 1e-5 \n",
      "(\u001b[1;31mmay not be significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n",
      "-----------------------counter  3  ------------------------------------\n",
      "*****GWAS ID IS***** ukb-d-20405_1\n",
      "stat {'or'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ukb-d-20405_1.tsv             --target ../larger_dataset_by_naeem2/larger_dataset             --thread 8             --stat OR             --or             --binary-target F             --quantile 10             --out ./PRSice_output/ukb-d-20405_1/ukb-d-20405_1             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat UKB-D-20405_1:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ukb-d-20405_1/ukb-d-20405_1.valid\n",
      "stat {'or'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.3 (2020-08-05) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-11-19 05:08:16\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ukb-d-20405_1.tsv \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ukb-d-20405_1/ukb-d-20405_1.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --or  \\\n",
      "    --out ./PRSice_output/ukb-d-20405_1/ukb-d-20405_1 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 2008716090 \\\n",
      "    --snp ID \\\n",
      "    --stat UKB-D-20405_1:ES \\\n",
      "    --target ../larger_dataset_by_naeem2/larger_dataset \\\n",
      "    --thread 8 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset_by_naeem2/larger_dataset (bed) \n",
      "\n",
      "Start processing ukb-d-20405_1 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ukb-d-20405_1.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tUKB-D-20405_1:ES\tUKB-D-20405_1:SE\tUKB-D-20405_1:LP\tUKB-D-20405_1:AF\tUKB-D-20405_1:SS\tUKB-D-20405_1:EZ\tUKB-D-20405_1:SI\tUKB-D-20405_1:NC\tUKB-D-20405_1:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "12203570 variant(s) observed in base file, with: \n",
      "8963735 variant(s) excluded based on user input \n",
      "3239835 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "4588021 variant(s) not found in previous data \n",
      "377 variant(s) with mismatch information \n",
      "3239835 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 243543 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s) with p-value between 0.1 and 1e-5 \n",
      "(\u001b[1;31mmay not be significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n",
      "-----------------------counter  4  ------------------------------------\n",
      "*****GWAS ID IS***** ukb-d-20405_2\n",
      "stat {'or'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ukb-d-20405_2.tsv             --target ../larger_dataset_by_naeem2/larger_dataset             --thread 8             --stat OR             --or             --binary-target F             --quantile 10             --out ./PRSice_output/ukb-d-20405_2/ukb-d-20405_2             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat UKB-D-20405_2:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ukb-d-20405_2/ukb-d-20405_2.valid\n",
      "stat {'or'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.3 (2020-08-05) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-11-19 05:09:09\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ukb-d-20405_2.tsv \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ukb-d-20405_2/ukb-d-20405_2.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --or  \\\n",
      "    --out ./PRSice_output/ukb-d-20405_2/ukb-d-20405_2 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 357268353 \\\n",
      "    --snp ID \\\n",
      "    --stat UKB-D-20405_2:ES \\\n",
      "    --target ../larger_dataset_by_naeem2/larger_dataset \\\n",
      "    --thread 8 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset_by_naeem2/larger_dataset (bed) \n",
      "\n",
      "Start processing ukb-d-20405_2 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ukb-d-20405_2.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tUKB-D-20405_2:ES\tUKB-D-20405_2:SE\tUKB-D-20405_2:LP\tUKB-D-20405_2:AF\tUKB-D-20405_2:SS\tUKB-D-20405_2:EZ\tUKB-D-20405_2:SI\tUKB-D-20405_2:NC\tUKB-D-20405_2:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "12013476 variant(s) observed in base file, with: \n",
      "8799398 variant(s) excluded based on user input \n",
      "3214078 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "4613757 variant(s) not found in previous data \n",
      "398 variant(s) with mismatch information \n",
      "3214078 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 243660 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s) with p-value between 0.1 and 1e-5 \n",
      "(\u001b[1;31mmay not be significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n",
      "-----------------------counter  5  ------------------------------------\n",
      "*****GWAS ID IS***** met-d-Total_C\n",
      "stat {'beta'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/met-d-Total_C.tsv             --target ../larger_dataset_by_naeem2/larger_dataset             --thread 8             --stat BETA             --beta             --binary-target F             --quantile 10             --out ./PRSice_output/met-d-Total_C/met-d-Total_C             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat MET-D-TOTAL_C:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/met-d-Total_C/met-d-Total_C.valid\n",
      "stat {'beta'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.3 (2020-08-05) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-11-19 05:10:00\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/met-d-Total_C.tsv \\\n",
      "    --beta  \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/met-d-Total_C/met-d-Total_C.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --out ./PRSice_output/met-d-Total_C/met-d-Total_C \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 2906530446 \\\n",
      "    --snp ID \\\n",
      "    --stat MET-D-TOTAL_C:ES \\\n",
      "    --target ../larger_dataset_by_naeem2/larger_dataset \\\n",
      "    --thread 8 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset_by_naeem2/larger_dataset (bed) \n",
      "\n",
      "Start processing met-d-Total_C \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/met-d-Total_C.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tMET-D-TOTAL_C:ES\tMET-D-TOTAL_C:SE\tMET-D-TOTAL_C:LP\tMET-D-TOTAL_C:AF\tMET-D-TOTAL_C:SS\tMET-D-TOTAL_C:EZ\tMET-D-TOTAL_C:SI\tMET-D-TOTAL_C:NC\tMET-D-TOTAL_C:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "12216219 variant(s) observed in base file, with: \n",
      "5655401 variant(s) excluded based on user input \n",
      "6560818 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "1267385 variant(s) not found in previous data \n",
      "30 variant(s) with mismatch information \n",
      "6560818 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 385478 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s) with p-value between 0.1 and 1e-5 \n",
      "(\u001b[1;31mmay not be significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n",
      "-----------------------counter  6  ------------------------------------\n",
      "*****GWAS ID IS***** ieu-b-109\n",
      "stat {'beta'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ieu-b-109.tsv             --target ../larger_dataset_by_naeem2/larger_dataset             --thread 8             --stat BETA             --beta             --binary-target F             --quantile 10             --out ./PRSice_output/ieu-b-109/ieu-b-109             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat IEU-B-109:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ieu-b-109/ieu-b-109.valid\n",
      "stat {'beta'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.3 (2020-08-05) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-11-19 05:11:22\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ieu-b-109.tsv \\\n",
      "    --beta  \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ieu-b-109/ieu-b-109.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --out ./PRSice_output/ieu-b-109/ieu-b-109 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 3133829065 \\\n",
      "    --snp ID \\\n",
      "    --stat IEU-B-109:ES \\\n",
      "    --target ../larger_dataset_by_naeem2/larger_dataset \\\n",
      "    --thread 8 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset_by_naeem2/larger_dataset (bed) \n",
      "\n",
      "Start processing ieu-b-109 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ieu-b-109.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tIEU-B-109:ES\tIEU-B-109:SE\tIEU-B-109:LP\tIEU-B-109:AF\tIEU-B-109:SS\tIEU-B-109:EZ\tIEU-B-109:SI\tIEU-B-109:NC\tIEU-B-109:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "12321875 variant(s) observed in base file, with: \n",
      "6200594 variant(s) excluded based on user input \n",
      "6121281 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "1706923 variant(s) not found in previous data \n",
      "29 variant(s) with mismatch information \n",
      "6121281 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 374779 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s) with p-value between 0.1 and 1e-5 \n",
      "(\u001b[1;31mmay not be significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n",
      "-----------------------counter  7  ------------------------------------\n",
      "*****GWAS ID IS***** ieu-b-110\n",
      "stat {'beta'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ieu-b-110.tsv             --target ../larger_dataset_by_naeem2/larger_dataset             --thread 8             --stat BETA             --beta             --binary-target F             --quantile 10             --out ./PRSice_output/ieu-b-110/ieu-b-110             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat IEU-B-110:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ieu-b-110/ieu-b-110.valid\n",
      "stat {'beta'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.3 (2020-08-05) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-11-19 05:12:39\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ieu-b-110.tsv \\\n",
      "    --beta  \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ieu-b-110/ieu-b-110.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --out ./PRSice_output/ieu-b-110/ieu-b-110 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 278410053 \\\n",
      "    --snp ID \\\n",
      "    --stat IEU-B-110:ES \\\n",
      "    --target ../larger_dataset_by_naeem2/larger_dataset \\\n",
      "    --thread 8 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset_by_naeem2/larger_dataset (bed) \n",
      "\n",
      "Start processing ieu-b-110 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ieu-b-110.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tIEU-B-110:ES\tIEU-B-110:SE\tIEU-B-110:LP\tIEU-B-110:AF\tIEU-B-110:SS\tIEU-B-110:EZ\tIEU-B-110:SI\tIEU-B-110:NC\tIEU-B-110:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "12321875 variant(s) observed in base file, with: \n",
      "6200603 variant(s) excluded based on user input \n",
      "6121272 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "1706932 variant(s) not found in previous data \n",
      "29 variant(s) with mismatch information \n",
      "6121272 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 375168 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s) with p-value between 0.1 and 1e-5 \n",
      "(\u001b[1;31mmay not be significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n",
      "-----------------------counter  8  ------------------------------------\n",
      "*****GWAS ID IS***** ieu-b-111\n",
      "stat {'beta'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ieu-b-111.tsv             --target ../larger_dataset_by_naeem2/larger_dataset             --thread 8             --stat BETA             --beta             --binary-target F             --quantile 10             --out ./PRSice_output/ieu-b-111/ieu-b-111             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat IEU-B-111:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ieu-b-111/ieu-b-111.valid\n",
      "stat {'beta'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.3 (2020-08-05) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-11-19 05:13:59\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ieu-b-111.tsv \\\n",
      "    --beta  \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ieu-b-111/ieu-b-111.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --out ./PRSice_output/ieu-b-111/ieu-b-111 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 3731095791 \\\n",
      "    --snp ID \\\n",
      "    --stat IEU-B-111:ES \\\n",
      "    --target ../larger_dataset_by_naeem2/larger_dataset \\\n",
      "    --thread 8 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset_by_naeem2/larger_dataset (bed) \n",
      "\n",
      "Start processing ieu-b-111 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ieu-b-111.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tIEU-B-111:ES\tIEU-B-111:SE\tIEU-B-111:LP\tIEU-B-111:AF\tIEU-B-111:SS\tIEU-B-111:EZ\tIEU-B-111:SI\tIEU-B-111:NC\tIEU-B-111:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "12321875 variant(s) observed in base file, with: \n",
      "6200615 variant(s) excluded based on user input \n",
      "6121260 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "1706944 variant(s) not found in previous data \n",
      "29 variant(s) with mismatch information \n",
      "6121260 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 374742 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s) with p-value between 0.1 and 1e-5 \n",
      "(\u001b[1;31mmay not be significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n",
      "-----------------------counter  9  ------------------------------------\n",
      "*****GWAS ID IS***** ieu-b-25\n",
      "stat {'beta'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ieu-b-25.tsv             --target ../larger_dataset_by_naeem2/larger_dataset             --thread 8             --stat BETA             --beta             --binary-target F             --quantile 10             --out ./PRSice_output/ieu-b-25/ieu-b-25             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat IEU-B-25:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ieu-b-25/ieu-b-25.valid\n",
      "stat {'beta'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.3 (2020-08-05) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-11-19 05:15:16\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ieu-b-25.tsv \\\n",
      "    --beta  \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ieu-b-25/ieu-b-25.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --out ./PRSice_output/ieu-b-25/ieu-b-25 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 3183877302 \\\n",
      "    --snp ID \\\n",
      "    --stat IEU-B-25:ES \\\n",
      "    --target ../larger_dataset_by_naeem2/larger_dataset \\\n",
      "    --thread 8 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset_by_naeem2/larger_dataset (bed) \n",
      "\n",
      "Start processing ieu-b-25 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ieu-b-25.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tIEU-B-25:ES\tIEU-B-25:SE\tIEU-B-25:LP\tIEU-B-25:AF\tIEU-B-25:SS\tIEU-B-25:EZ\tIEU-B-25:SI\tIEU-B-25:NC\tIEU-B-25:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "11913711 variant(s) observed in base file, with: \n",
      "1834376 variant(s) excluded based on user input \n",
      "10079335 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "1720438 variant(s) not found in previous data \n",
      "1 variant(s) with mismatch information \n",
      "6107794 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 378764 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s) with p-value between 0.1 and 1e-5 \n",
      "(\u001b[1;31mmay not be significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n",
      "-----------------------counter  10  ------------------------------------\n",
      "*****GWAS ID IS***** ieu-b-38\n",
      "stat {'beta'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ieu-b-38.tsv             --target ../larger_dataset_by_naeem2/larger_dataset             --thread 8             --stat BETA             --beta             --binary-target F             --quantile 10             --out ./PRSice_output/ieu-b-38/ieu-b-38             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat IEU-B-38:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ieu-b-38/ieu-b-38.valid\n",
      "stat {'beta'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.3 (2020-08-05) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-11-19 05:16:58\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ieu-b-38.tsv \\\n",
      "    --beta  \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ieu-b-38/ieu-b-38.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --out ./PRSice_output/ieu-b-38/ieu-b-38 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 3331972287 \\\n",
      "    --snp ID \\\n",
      "    --stat IEU-B-38:ES \\\n",
      "    --target ../larger_dataset_by_naeem2/larger_dataset \\\n",
      "    --thread 8 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset_by_naeem2/larger_dataset (bed) \n",
      "\n",
      "Start processing ieu-b-38 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ieu-b-38.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tIEU-B-38:ES\tIEU-B-38:SE\tIEU-B-38:LP\tIEU-B-38:AF\tIEU-B-38:SS\tIEU-B-38:EZ\tIEU-B-38:SI\tIEU-B-38:NC\tIEU-B-38:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "7088083 variant(s) observed in base file, with: \n",
      "1536723 variant(s) excluded based on user input \n",
      "5551360 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "2275828 variant(s) not found in previous data \n",
      "1045 variant(s) with mismatch information \n",
      "5551360 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 260235 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s) with p-value between 0.1 and 1e-5 \n",
      "(\u001b[1;31mmay not be significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n",
      "-----------------------counter  11  ------------------------------------\n",
      "*****GWAS ID IS***** ieu-b-39\n",
      "stat {'beta'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ieu-b-39.tsv             --target ../larger_dataset_by_naeem2/larger_dataset             --thread 8             --stat BETA             --beta             --binary-target F             --quantile 10             --out ./PRSice_output/ieu-b-39/ieu-b-39             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat IEU-B-39:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ieu-b-39/ieu-b-39.valid\n",
      "stat {'beta'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.3 (2020-08-05) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-11-19 05:18:02\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ieu-b-39.tsv \\\n",
      "    --beta  \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ieu-b-39/ieu-b-39.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --out ./PRSice_output/ieu-b-39/ieu-b-39 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 1728424571 \\\n",
      "    --snp ID \\\n",
      "    --stat IEU-B-39:ES \\\n",
      "    --target ../larger_dataset_by_naeem2/larger_dataset \\\n",
      "    --thread 8 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset_by_naeem2/larger_dataset (bed) \n",
      "\n",
      "Start processing ieu-b-39 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ieu-b-39.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tIEU-B-39:ES\tIEU-B-39:SE\tIEU-B-39:LP\tIEU-B-39:AF\tIEU-B-39:SS\tIEU-B-39:EZ\tIEU-B-39:SI\tIEU-B-39:NC\tIEU-B-39:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "7160619 variant(s) observed in base file, with: \n",
      "1558246 variant(s) excluded based on user input \n",
      "5602373 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "2224824 variant(s) not found in previous data \n",
      "1036 variant(s) with mismatch information \n",
      "5602373 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 271689 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s)/phenotype(s) with p-value > 0.1 (\u001b[1;31mnot \n",
      "significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n",
      "-----------------------counter  12  ------------------------------------\n",
      "*****GWAS ID IS***** ukb-a-257\n",
      "stat {'or'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ukb-a-257.tsv             --target ../larger_dataset_by_naeem2/larger_dataset             --thread 8             --stat OR             --or             --binary-target F             --quantile 10             --out ./PRSice_output/ukb-a-257/ukb-a-257             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat UKB-A-257:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ukb-a-257/ukb-a-257.valid\n",
      "stat {'or'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.3 (2020-08-05) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-11-19 05:19:07\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ukb-a-257.tsv \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ukb-a-257/ukb-a-257.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --or  \\\n",
      "    --out ./PRSice_output/ukb-a-257/ukb-a-257 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 1011562909 \\\n",
      "    --snp ID \\\n",
      "    --stat UKB-A-257:ES \\\n",
      "    --target ../larger_dataset_by_naeem2/larger_dataset \\\n",
      "    --thread 8 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset_by_naeem2/larger_dataset (bed) \n",
      "\n",
      "Start processing ukb-a-257 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ukb-a-257.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tUKB-A-257:ES\tUKB-A-257:SE\tUKB-A-257:LP\tUKB-A-257:AF\tUKB-A-257:SS\tUKB-A-257:EZ\tUKB-A-257:SI\tUKB-A-257:NC\tUKB-A-257:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "10545186 variant(s) observed in base file, with: \n",
      "7313579 variant(s) excluded based on user input \n",
      "3231607 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "4596292 variant(s) not found in previous data \n",
      "334 variant(s) with mismatch information \n",
      "3231607 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 245183 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s) with p-value between 0.1 and 1e-5 \n",
      "(\u001b[1;31mmay not be significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n",
      "-----------------------counter  13  ------------------------------------\n",
      "*****GWAS ID IS***** ukb-b-12064\n",
      "stat {'or'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ukb-b-12064.tsv             --target ../larger_dataset_by_naeem2/larger_dataset             --thread 8             --stat OR             --or             --binary-target F             --quantile 10             --out ./PRSice_output/ukb-b-12064/ukb-b-12064             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat UKB-B-12064:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ukb-b-12064/ukb-b-12064.valid\n",
      "stat {'or'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.3 (2020-08-05) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-11-19 05:19:57\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ukb-b-12064.tsv \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ukb-b-12064/ukb-b-12064.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --or  \\\n",
      "    --out ./PRSice_output/ukb-b-12064/ukb-b-12064 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 352538004 \\\n",
      "    --snp ID \\\n",
      "    --stat UKB-B-12064:ES \\\n",
      "    --target ../larger_dataset_by_naeem2/larger_dataset \\\n",
      "    --thread 8 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset_by_naeem2/larger_dataset (bed) \n",
      "\n",
      "Start processing ukb-b-12064 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ukb-b-12064.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tUKB-B-12064:ES\tUKB-B-12064:SE\tUKB-B-12064:LP\tUKB-B-12064:AF\tUKB-B-12064:SS\tUKB-B-12064:EZ\tUKB-B-12064:SI\tUKB-B-12064:NC\tUKB-B-12064:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "7338290 variant(s) observed in base file, with: \n",
      "4248672 variant(s) excluded based on user input \n",
      "3089618 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "4738600 variant(s) not found in previous data \n",
      "15 variant(s) with mismatch information \n",
      "3089618 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 226689 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s) with p-value between 0.1 and 1e-5 \n",
      "(\u001b[1;31mmay not be significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n",
      "-----------------------counter  14  ------------------------------------\n",
      "*****GWAS ID IS***** ukb-b-17627\n",
      "stat {'beta'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ukb-b-17627.tsv             --target ../larger_dataset_by_naeem2/larger_dataset             --thread 8             --stat BETA             --beta             --binary-target F             --quantile 10             --out ./PRSice_output/ukb-b-17627/ukb-b-17627             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat UKB-B-17627:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ukb-b-17627/ukb-b-17627.valid\n",
      "stat {'beta'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.3 (2020-08-05) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-11-19 05:20:40\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ukb-b-17627.tsv \\\n",
      "    --beta  \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ukb-b-17627/ukb-b-17627.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --out ./PRSice_output/ukb-b-17627/ukb-b-17627 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 706089071 \\\n",
      "    --snp ID \\\n",
      "    --stat UKB-B-17627:ES \\\n",
      "    --target ../larger_dataset_by_naeem2/larger_dataset \\\n",
      "    --thread 8 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset_by_naeem2/larger_dataset (bed) \n",
      "\n",
      "Start processing ukb-b-17627 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ukb-b-17627.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tUKB-B-17627:ES\tUKB-B-17627:SE\tUKB-B-17627:LP\tUKB-B-17627:AF\tUKB-B-17627:SS\tUKB-B-17627:EZ\tUKB-B-17627:SI\tUKB-B-17627:NC\tUKB-B-17627:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "9851866 variant(s) observed in base file, with: \n",
      "3268847 variant(s) excluded based on user input \n",
      "6583019 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "1245185 variant(s) not found in previous data \n",
      "29 variant(s) with mismatch information \n",
      "6583019 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 388396 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s) with p-value between 0.1 and 1e-5 \n",
      "(\u001b[1;31mmay not be significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n",
      "-----------------------counter  15  ------------------------------------\n",
      "*****GWAS ID IS***** ukb-b-18275\n",
      "stat {'or'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ukb-b-18275.tsv             --target ../larger_dataset_by_naeem2/larger_dataset             --thread 8             --stat OR             --or             --binary-target F             --quantile 10             --out ./PRSice_output/ukb-b-18275/ukb-b-18275             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat UKB-B-18275:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ukb-b-18275/ukb-b-18275.valid\n",
      "stat {'or'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.3 (2020-08-05) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-11-19 05:21:58\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ukb-b-18275.tsv \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ukb-b-18275/ukb-b-18275.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --or  \\\n",
      "    --out ./PRSice_output/ukb-b-18275/ukb-b-18275 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 639436291 \\\n",
      "    --snp ID \\\n",
      "    --stat UKB-B-18275:ES \\\n",
      "    --target ../larger_dataset_by_naeem2/larger_dataset \\\n",
      "    --thread 8 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset_by_naeem2/larger_dataset (bed) \n",
      "\n",
      "Start processing ukb-b-18275 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ukb-b-18275.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tUKB-B-18275:ES\tUKB-B-18275:SE\tUKB-B-18275:LP\tUKB-B-18275:AF\tUKB-B-18275:SS\tUKB-B-18275:EZ\tUKB-B-18275:SI\tUKB-B-18275:NC\tUKB-B-18275:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "9401286 variant(s) observed in base file, with: \n",
      "6133847 variant(s) excluded based on user input \n",
      "3267439 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "4560778 variant(s) not found in previous data \n",
      "16 variant(s) with mismatch information \n",
      "3267439 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 253852 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s) with p-value between 0.1 and 1e-5 \n",
      "(\u001b[1;31mmay not be significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n",
      "-----------------------counter  16  ------------------------------------\n",
      "*****GWAS ID IS***** ukb-b-19953\n",
      "stat {'beta'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ukb-b-19953.tsv             --target ../larger_dataset_by_naeem2/larger_dataset             --thread 8             --stat BETA             --beta             --binary-target F             --quantile 10             --out ./PRSice_output/ukb-b-19953/ukb-b-19953             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat UKB-B-19953:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ukb-b-19953/ukb-b-19953.valid\n",
      "stat {'beta'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.3 (2020-08-05) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-11-19 05:22:45\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ukb-b-19953.tsv \\\n",
      "    --beta  \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ukb-b-19953/ukb-b-19953.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --out ./PRSice_output/ukb-b-19953/ukb-b-19953 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 3416551328 \\\n",
      "    --snp ID \\\n",
      "    --stat UKB-B-19953:ES \\\n",
      "    --target ../larger_dataset_by_naeem2/larger_dataset \\\n",
      "    --thread 8 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset_by_naeem2/larger_dataset (bed) \n",
      "\n",
      "Start processing ukb-b-19953 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ukb-b-19953.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tUKB-B-19953:ES\tUKB-B-19953:SE\tUKB-B-19953:LP\tUKB-B-19953:AF\tUKB-B-19953:SS\tUKB-B-19953:EZ\tUKB-B-19953:SI\tUKB-B-19953:NC\tUKB-B-19953:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "9851866 variant(s) observed in base file, with: \n",
      "3268847 variant(s) excluded based on user input \n",
      "6583019 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "1245185 variant(s) not found in previous data \n",
      "29 variant(s) with mismatch information \n",
      "6583019 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 387647 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s) with p-value between 0.1 and 1e-5 \n",
      "(\u001b[1;31mmay not be significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n",
      "-----------------------counter  17  ------------------------------------\n",
      "*****GWAS ID IS***** ukb-b-2209\n",
      "stat {'beta'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ukb-b-2209.tsv             --target ../larger_dataset_by_naeem2/larger_dataset             --thread 8             --stat BETA             --beta             --binary-target F             --quantile 10             --out ./PRSice_output/ukb-b-2209/ukb-b-2209             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat UKB-B-2209:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ukb-b-2209/ukb-b-2209.valid\n",
      "stat {'beta'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.3 (2020-08-05) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-11-19 05:24:04\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ukb-b-2209.tsv \\\n",
      "    --beta  \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ukb-b-2209/ukb-b-2209.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --out ./PRSice_output/ukb-b-2209/ukb-b-2209 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 1152795657 \\\n",
      "    --snp ID \\\n",
      "    --stat UKB-B-2209:ES \\\n",
      "    --target ../larger_dataset_by_naeem2/larger_dataset \\\n",
      "    --thread 8 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset_by_naeem2/larger_dataset (bed) \n",
      "\n",
      "Start processing ukb-b-2209 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ukb-b-2209.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tUKB-B-2209:ES\tUKB-B-2209:SE\tUKB-B-2209:LP\tUKB-B-2209:AF\tUKB-B-2209:SS\tUKB-B-2209:EZ\tUKB-B-2209:SI\tUKB-B-2209:NC\tUKB-B-2209:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "9851866 variant(s) observed in base file, with: \n",
      "3268847 variant(s) excluded based on user input \n",
      "6583019 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "1245185 variant(s) not found in previous data \n",
      "29 variant(s) with mismatch information \n",
      "6583019 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 388041 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s) with p-value between 0.1 and 1e-5 \n",
      "(\u001b[1;31mmay not be significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n",
      "-----------------------counter  18  ------------------------------------\n",
      "*****GWAS ID IS***** ukb-b-3957\n",
      "stat {'beta'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ukb-b-3957.tsv             --target ../larger_dataset_by_naeem2/larger_dataset             --thread 8             --stat BETA             --beta             --binary-target F             --quantile 10             --out ./PRSice_output/ukb-b-3957/ukb-b-3957             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat UKB-B-3957:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ukb-b-3957/ukb-b-3957.valid\n",
      "stat {'beta'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.3 (2020-08-05) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-11-19 05:25:22\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ukb-b-3957.tsv \\\n",
      "    --beta  \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ukb-b-3957/ukb-b-3957.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --out ./PRSice_output/ukb-b-3957/ukb-b-3957 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 4017315683 \\\n",
      "    --snp ID \\\n",
      "    --stat UKB-B-3957:ES \\\n",
      "    --target ../larger_dataset_by_naeem2/larger_dataset \\\n",
      "    --thread 8 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset_by_naeem2/larger_dataset (bed) \n",
      "\n",
      "Start processing ukb-b-3957 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ukb-b-3957.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tUKB-B-3957:ES\tUKB-B-3957:SE\tUKB-B-3957:LP\tUKB-B-3957:AF\tUKB-B-3957:SS\tUKB-B-3957:EZ\tUKB-B-3957:SI\tUKB-B-3957:NC\tUKB-B-3957:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "9851866 variant(s) observed in base file, with: \n",
      "3268847 variant(s) excluded based on user input \n",
      "6583019 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "1245185 variant(s) not found in previous data \n",
      "29 variant(s) with mismatch information \n",
      "6583019 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 388051 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s) with p-value between 0.1 and 1e-5 \n",
      "(\u001b[1;31mmay not be significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n",
      "-----------------------counter  19  ------------------------------------\n",
      "*****GWAS ID IS***** ukb-b-4424\n",
      "stat {'beta'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ukb-b-4424.tsv             --target ../larger_dataset_by_naeem2/larger_dataset             --thread 8             --stat BETA             --beta             --binary-target F             --quantile 10             --out ./PRSice_output/ukb-b-4424/ukb-b-4424             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat UKB-B-4424:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ukb-b-4424/ukb-b-4424.valid\n",
      "stat {'beta'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.3 (2020-08-05) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-11-19 05:26:40\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ukb-b-4424.tsv \\\n",
      "    --beta  \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ukb-b-4424/ukb-b-4424.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --out ./PRSice_output/ukb-b-4424/ukb-b-4424 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 793386483 \\\n",
      "    --snp ID \\\n",
      "    --stat UKB-B-4424:ES \\\n",
      "    --target ../larger_dataset_by_naeem2/larger_dataset \\\n",
      "    --thread 8 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset_by_naeem2/larger_dataset (bed) \n",
      "\n",
      "Start processing ukb-b-4424 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ukb-b-4424.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tUKB-B-4424:ES\tUKB-B-4424:SE\tUKB-B-4424:LP\tUKB-B-4424:AF\tUKB-B-4424:SS\tUKB-B-4424:EZ\tUKB-B-4424:SI\tUKB-B-4424:NC\tUKB-B-4424:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "9851866 variant(s) observed in base file, with: \n",
      "3268847 variant(s) excluded based on user input \n",
      "6583019 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "1245185 variant(s) not found in previous data \n",
      "29 variant(s) with mismatch information \n",
      "6583019 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 387991 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s)/phenotype(s) with p-value > 0.1 (\u001b[1;31mnot \n",
      "significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n",
      "-----------------------counter  20  ------------------------------------\n",
      "*****GWAS ID IS***** ukb-b-6134\n",
      "stat {'beta'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ukb-b-6134.tsv             --target ../larger_dataset_by_naeem2/larger_dataset             --thread 8             --stat BETA             --beta             --binary-target F             --quantile 10             --out ./PRSice_output/ukb-b-6134/ukb-b-6134             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat UKB-B-6134:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ukb-b-6134/ukb-b-6134.valid\n",
      "stat {'beta'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.3 (2020-08-05) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-11-19 05:27:59\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ukb-b-6134.tsv \\\n",
      "    --beta  \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ukb-b-6134/ukb-b-6134.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --out ./PRSice_output/ukb-b-6134/ukb-b-6134 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 4168921395 \\\n",
      "    --snp ID \\\n",
      "    --stat UKB-B-6134:ES \\\n",
      "    --target ../larger_dataset_by_naeem2/larger_dataset \\\n",
      "    --thread 8 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset_by_naeem2/larger_dataset (bed) \n",
      "\n",
      "Start processing ukb-b-6134 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ukb-b-6134.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tUKB-B-6134:ES\tUKB-B-6134:SE\tUKB-B-6134:LP\tUKB-B-6134:AF\tUKB-B-6134:SS\tUKB-B-6134:EZ\tUKB-B-6134:SI\tUKB-B-6134:NC\tUKB-B-6134:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "9756889 variant(s) observed in base file, with: \n",
      "3186943 variant(s) excluded based on user input \n",
      "6569946 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "1258258 variant(s) not found in previous data \n",
      "29 variant(s) with mismatch information \n",
      "6569946 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 387133 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s) with p-value between 0.1 and 1e-5 \n",
      "(\u001b[1;31mmay not be significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n",
      "-----------------------counter  21  ------------------------------------\n",
      "*****GWAS ID IS***** ukb-b-6324\n",
      "stat {'beta'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ukb-b-6324.tsv             --target ../larger_dataset_by_naeem2/larger_dataset             --thread 8             --stat BETA             --beta             --binary-target F             --quantile 10             --out ./PRSice_output/ukb-b-6324/ukb-b-6324             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat UKB-B-6324:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ukb-b-6324/ukb-b-6324.valid\n",
      "stat {'beta'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.3 (2020-08-05) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-11-19 05:29:18\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ukb-b-6324.tsv \\\n",
      "    --beta  \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ukb-b-6324/ukb-b-6324.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --out ./PRSice_output/ukb-b-6324/ukb-b-6324 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 1659056226 \\\n",
      "    --snp ID \\\n",
      "    --stat UKB-B-6324:ES \\\n",
      "    --target ../larger_dataset_by_naeem2/larger_dataset \\\n",
      "    --thread 8 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset_by_naeem2/larger_dataset (bed) \n",
      "\n",
      "Start processing ukb-b-6324 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ukb-b-6324.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tUKB-B-6324:ES\tUKB-B-6324:SE\tUKB-B-6324:LP\tUKB-B-6324:AF\tUKB-B-6324:SS\tUKB-B-6324:EZ\tUKB-B-6324:SI\tUKB-B-6324:NC\tUKB-B-6324:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "9851866 variant(s) observed in base file, with: \n",
      "3268847 variant(s) excluded based on user input \n",
      "6583019 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "1245185 variant(s) not found in previous data \n",
      "29 variant(s) with mismatch information \n",
      "6583019 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 388197 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s)/phenotype(s) with p-value > 0.1 (\u001b[1;31mnot \n",
      "significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n",
      "-----------------------counter  22  ------------------------------------\n",
      "*****GWAS ID IS***** ukb-b-7663\n",
      "stat {'or'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ukb-b-7663.tsv             --target ../larger_dataset_by_naeem2/larger_dataset             --thread 8             --stat OR             --or             --binary-target F             --quantile 10             --out ./PRSice_output/ukb-b-7663/ukb-b-7663             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat UKB-B-7663:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ukb-b-7663/ukb-b-7663.valid\n",
      "stat {'or'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.3 (2020-08-05) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-11-19 05:30:36\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ukb-b-7663.tsv \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ukb-b-7663/ukb-b-7663.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --or  \\\n",
      "    --out ./PRSice_output/ukb-b-7663/ukb-b-7663 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 3007825766 \\\n",
      "    --snp ID \\\n",
      "    --stat UKB-B-7663:ES \\\n",
      "    --target ../larger_dataset_by_naeem2/larger_dataset \\\n",
      "    --thread 8 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset_by_naeem2/larger_dataset (bed) \n",
      "\n",
      "Start processing ukb-b-7663 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ukb-b-7663.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tUKB-B-7663:ES\tUKB-B-7663:SE\tUKB-B-7663:LP\tUKB-B-7663:AF\tUKB-B-7663:SS\tUKB-B-7663:EZ\tUKB-B-7663:SI\tUKB-B-7663:NC\tUKB-B-7663:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "8164789 variant(s) observed in base file, with: \n",
      "4945458 variant(s) excluded based on user input \n",
      "3219331 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "4608890 variant(s) not found in previous data \n",
      "12 variant(s) with mismatch information \n",
      "3219331 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 248716 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s) with p-value between 0.1 and 1e-5 \n",
      "(\u001b[1;31mmay not be significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n",
      "-----------------------counter  23  ------------------------------------\n",
      "*****GWAS ID IS***** ukb-b-770\n",
      "stat {'beta'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ukb-b-770.tsv             --target ../larger_dataset_by_naeem2/larger_dataset             --thread 8             --stat BETA             --beta             --binary-target F             --quantile 10             --out ./PRSice_output/ukb-b-770/ukb-b-770             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat UKB-B-770:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ukb-b-770/ukb-b-770.valid\n",
      "stat {'beta'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.3 (2020-08-05) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-11-19 05:31:22\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ukb-b-770.tsv \\\n",
      "    --beta  \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ukb-b-770/ukb-b-770.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --out ./PRSice_output/ukb-b-770/ukb-b-770 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 866146539 \\\n",
      "    --snp ID \\\n",
      "    --stat UKB-B-770:ES \\\n",
      "    --target ../larger_dataset_by_naeem2/larger_dataset \\\n",
      "    --thread 8 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset_by_naeem2/larger_dataset (bed) \n",
      "\n",
      "Start processing ukb-b-770 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ukb-b-770.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tUKB-B-770:ES\tUKB-B-770:SE\tUKB-B-770:LP\tUKB-B-770:AF\tUKB-B-770:SS\tUKB-B-770:EZ\tUKB-B-770:SI\tUKB-B-770:NC\tUKB-B-770:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "8625010 variant(s) observed in base file, with: \n",
      "2140663 variant(s) excluded based on user input \n",
      "6484347 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "1343857 variant(s) not found in previous data \n",
      "29 variant(s) with mismatch information \n",
      "6484347 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 379754 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s)/phenotype(s) with p-value > 0.1 (\u001b[1;31mnot \n",
      "significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n",
      "-----------------------counter  24  ------------------------------------\n",
      "*****GWAS ID IS***** ukb-b-8476\n",
      "stat {'or'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ukb-b-8476.tsv             --target ../larger_dataset_by_naeem2/larger_dataset             --thread 8             --stat OR             --or             --binary-target F             --quantile 10             --out ./PRSice_output/ukb-b-8476/ukb-b-8476             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat UKB-B-8476:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ukb-b-8476/ukb-b-8476.valid\n",
      "stat {'or'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.3 (2020-08-05) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-11-19 05:32:38\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ukb-b-8476.tsv \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ukb-b-8476/ukb-b-8476.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --or  \\\n",
      "    --out ./PRSice_output/ukb-b-8476/ukb-b-8476 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 3536413579 \\\n",
      "    --snp ID \\\n",
      "    --stat UKB-B-8476:ES \\\n",
      "    --target ../larger_dataset_by_naeem2/larger_dataset \\\n",
      "    --thread 8 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset_by_naeem2/larger_dataset (bed) \n",
      "\n",
      "Start processing ukb-b-8476 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ukb-b-8476.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tUKB-B-8476:ES\tUKB-B-8476:SE\tUKB-B-8476:LP\tUKB-B-8476:AF\tUKB-B-8476:SS\tUKB-B-8476:EZ\tUKB-B-8476:SI\tUKB-B-8476:NC\tUKB-B-8476:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "8862761 variant(s) observed in base file, with: \n",
      "5585986 variant(s) excluded based on user input \n",
      "3276775 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "4551441 variant(s) not found in previous data \n",
      "17 variant(s) with mismatch information \n",
      "3276775 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 251181 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s) with p-value between 0.1 and 1e-5 \n",
      "(\u001b[1;31mmay not be significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n",
      "-----------------------counter  25  ------------------------------------\n",
      "*****GWAS ID IS***** ukb-b-323\n",
      "stat {'or'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ukb-b-323.tsv             --target ../larger_dataset_by_naeem2/larger_dataset             --thread 8             --stat OR             --or             --binary-target F             --quantile 10             --out ./PRSice_output/ukb-b-323/ukb-b-323             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat UKB-B-323:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ukb-b-323/ukb-b-323.valid\n",
      "stat {'or'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.3 (2020-08-05) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-11-19 05:33:24\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ukb-b-323.tsv \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ukb-b-323/ukb-b-323.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --or  \\\n",
      "    --out ./PRSice_output/ukb-b-323/ukb-b-323 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 2945658600 \\\n",
      "    --snp ID \\\n",
      "    --stat UKB-B-323:ES \\\n",
      "    --target ../larger_dataset_by_naeem2/larger_dataset \\\n",
      "    --thread 8 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset_by_naeem2/larger_dataset (bed) \n",
      "\n",
      "Start processing ukb-b-323 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ukb-b-323.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tUKB-B-323:ES\tUKB-B-323:SE\tUKB-B-323:LP\tUKB-B-323:AF\tUKB-B-323:SS\tUKB-B-323:EZ\tUKB-B-323:SI\tUKB-B-323:NC\tUKB-B-323:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "6877801 variant(s) observed in base file, with: \n",
      "3986564 variant(s) excluded based on user input \n",
      "2891237 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "4936982 variant(s) not found in previous data \n",
      "14 variant(s) with mismatch information \n",
      "2891237 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 196007 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s) with p-value less than 1e-5. Please \n",
      "note that these results are inflated due to the overfitting \n",
      "inherent in finding the best-fit PRS (but it's still best \n",
      "to find the best-fit PRS!). \n",
      "You can use the --perm option (see manual) to calculate an \n",
      "empirical P-value. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n",
      "-----------------------counter  26  ------------------------------------\n",
      "*****GWAS ID IS***** ukb-b-14699\n",
      "stat {'or'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ukb-b-14699.tsv             --target ../larger_dataset_by_naeem2/larger_dataset             --thread 8             --stat OR             --or             --binary-target F             --quantile 10             --out ./PRSice_output/ukb-b-14699/ukb-b-14699             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat UKB-B-14699:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ukb-b-14699/ukb-b-14699.valid\n",
      "stat {'or'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.3 (2020-08-05) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-11-19 05:34:05\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ukb-b-14699.tsv \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ukb-b-14699/ukb-b-14699.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --or  \\\n",
      "    --out ./PRSice_output/ukb-b-14699/ukb-b-14699 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 1307756778 \\\n",
      "    --snp ID \\\n",
      "    --stat UKB-B-14699:ES \\\n",
      "    --target ../larger_dataset_by_naeem2/larger_dataset \\\n",
      "    --thread 8 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset_by_naeem2/larger_dataset (bed) \n",
      "\n",
      "Start processing ukb-b-14699 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ukb-b-14699.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tUKB-B-14699:ES\tUKB-B-14699:SE\tUKB-B-14699:LP\tUKB-B-14699:AF\tUKB-B-14699:SS\tUKB-B-14699:EZ\tUKB-B-14699:SI\tUKB-B-14699:NC\tUKB-B-14699:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "7793502 variant(s) observed in base file, with: \n",
      "4628047 variant(s) excluded based on user input \n",
      "3165455 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "4662765 variant(s) not found in previous data \n",
      "13 variant(s) with mismatch information \n",
      "3165455 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 245376 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s) with p-value less than 1e-5. Please \n",
      "note that these results are inflated due to the overfitting \n",
      "inherent in finding the best-fit PRS (but it's still best \n",
      "to find the best-fit PRS!). \n",
      "You can use the --perm option (see manual) to calculate an \n",
      "empirical P-value. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n",
      "-----------------------counter  27  ------------------------------------\n",
      "*****GWAS ID IS***** ukb-b-14180\n",
      "stat {'or'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ukb-b-14180.tsv             --target ../larger_dataset_by_naeem2/larger_dataset             --thread 8             --stat OR             --or             --binary-target F             --quantile 10             --out ./PRSice_output/ukb-b-14180/ukb-b-14180             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat UKB-B-14180:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ukb-b-14180/ukb-b-14180.valid\n",
      "stat {'or'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.3 (2020-08-05) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-11-19 05:34:51\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ukb-b-14180.tsv \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ukb-b-14180/ukb-b-14180.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --or  \\\n",
      "    --out ./PRSice_output/ukb-b-14180/ukb-b-14180 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 2466912892 \\\n",
      "    --snp ID \\\n",
      "    --stat UKB-B-14180:ES \\\n",
      "    --target ../larger_dataset_by_naeem2/larger_dataset \\\n",
      "    --thread 8 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset_by_naeem2/larger_dataset (bed) \n",
      "\n",
      "Start processing ukb-b-14180 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ukb-b-14180.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tUKB-B-14180:ES\tUKB-B-14180:SE\tUKB-B-14180:LP\tUKB-B-14180:AF\tUKB-B-14180:SS\tUKB-B-14180:EZ\tUKB-B-14180:SI\tUKB-B-14180:NC\tUKB-B-14180:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "9515294 variant(s) observed in base file, with: \n",
      "6213501 variant(s) excluded based on user input \n",
      "3301793 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "4526423 variant(s) not found in previous data \n",
      "17 variant(s) with mismatch information \n",
      "3301793 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 254214 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s) with p-value between 0.1 and 1e-5 \n",
      "(\u001b[1;31mmay not be significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n",
      "-----------------------counter  28  ------------------------------------\n",
      "*****GWAS ID IS***** ukb-b-17243\n",
      "stat {'or'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ukb-b-17243.tsv             --target ../larger_dataset_by_naeem2/larger_dataset             --thread 8             --stat OR             --or             --binary-target F             --quantile 10             --out ./PRSice_output/ukb-b-17243/ukb-b-17243             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat UKB-B-17243:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ukb-b-17243/ukb-b-17243.valid\n",
      "stat {'or'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.3 (2020-08-05) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-11-19 05:35:39\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ukb-b-17243.tsv \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ukb-b-17243/ukb-b-17243.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --or  \\\n",
      "    --out ./PRSice_output/ukb-b-17243/ukb-b-17243 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 812319109 \\\n",
      "    --snp ID \\\n",
      "    --stat UKB-B-17243:ES \\\n",
      "    --target ../larger_dataset_by_naeem2/larger_dataset \\\n",
      "    --thread 8 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset_by_naeem2/larger_dataset (bed) \n",
      "\n",
      "Start processing ukb-b-17243 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ukb-b-17243.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tUKB-B-17243:ES\tUKB-B-17243:SE\tUKB-B-17243:LP\tUKB-B-17243:AF\tUKB-B-17243:SS\tUKB-B-17243:EZ\tUKB-B-17243:SI\tUKB-B-17243:NC\tUKB-B-17243:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "5294159 variant(s) observed in base file, with: \n",
      "3064138 variant(s) excluded based on user input \n",
      "2230021 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "5598199 variant(s) not found in previous data \n",
      "13 variant(s) with mismatch information \n",
      "2230021 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 109551 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s) with p-value between 0.1 and 1e-5 \n",
      "(\u001b[1;31mmay not be significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n",
      "-----------------------counter  29  ------------------------------------\n",
      "*****GWAS ID IS***** ukb-b-6358\n",
      "stat {'or'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ukb-b-6358.tsv             --target ../larger_dataset_by_naeem2/larger_dataset             --thread 8             --stat OR             --or             --binary-target F             --quantile 10             --out ./PRSice_output/ukb-b-6358/ukb-b-6358             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat UKB-B-6358:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ukb-b-6358/ukb-b-6358.valid\n",
      "stat {'or'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.3 (2020-08-05) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-11-19 05:36:11\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ukb-b-6358.tsv \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ukb-b-6358/ukb-b-6358.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --or  \\\n",
      "    --out ./PRSice_output/ukb-b-6358/ukb-b-6358 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 1012127823 \\\n",
      "    --snp ID \\\n",
      "    --stat UKB-B-6358:ES \\\n",
      "    --target ../larger_dataset_by_naeem2/larger_dataset \\\n",
      "    --thread 8 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset_by_naeem2/larger_dataset (bed) \n",
      "\n",
      "Start processing ukb-b-6358 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ukb-b-6358.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tUKB-B-6358:ES\tUKB-B-6358:SE\tUKB-B-6358:LP\tUKB-B-6358:AF\tUKB-B-6358:SS\tUKB-B-6358:EZ\tUKB-B-6358:SI\tUKB-B-6358:NC\tUKB-B-6358:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "5221749 variant(s) observed in base file, with: \n",
      "3016985 variant(s) excluded based on user input \n",
      "2204764 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "5623458 variant(s) not found in previous data \n",
      "11 variant(s) with mismatch information \n",
      "2204764 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 107100 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s)/phenotype(s) with p-value > 0.1 (\u001b[1;31mnot \n",
      "significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n",
      "-----------------------counter  30  ------------------------------------\n",
      "*****GWAS ID IS***** ukb-b-17006\n",
      "stat {'or'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ukb-b-17006.tsv             --target ../larger_dataset_by_naeem2/larger_dataset             --thread 8             --stat OR             --or             --binary-target F             --quantile 10             --out ./PRSice_output/ukb-b-17006/ukb-b-17006             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat UKB-B-17006:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ukb-b-17006/ukb-b-17006.valid\n",
      "stat {'or'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.3 (2020-08-05) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-11-19 05:36:42\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ukb-b-17006.tsv \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ukb-b-17006/ukb-b-17006.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --or  \\\n",
      "    --out ./PRSice_output/ukb-b-17006/ukb-b-17006 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 145707317 \\\n",
      "    --snp ID \\\n",
      "    --stat UKB-B-17006:ES \\\n",
      "    --target ../larger_dataset_by_naeem2/larger_dataset \\\n",
      "    --thread 8 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset_by_naeem2/larger_dataset (bed) \n",
      "\n",
      "Start processing ukb-b-17006 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ukb-b-17006.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tUKB-B-17006:ES\tUKB-B-17006:SE\tUKB-B-17006:LP\tUKB-B-17006:AF\tUKB-B-17006:SS\tUKB-B-17006:EZ\tUKB-B-17006:SI\tUKB-B-17006:NC\tUKB-B-17006:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "2541600 variant(s) observed in base file, with: \n",
      "1474139 variant(s) excluded based on user input \n",
      "1067461 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "6760764 variant(s) not found in previous data \n",
      "8 variant(s) with mismatch information \n",
      "1067461 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 48686 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s) with p-value between 0.1 and 1e-5 \n",
      "(\u001b[1;31mmay not be significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n",
      "-----------------------counter  31  ------------------------------------\n",
      "*****GWAS ID IS***** ukb-b-5779\n",
      "stat {'beta'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ukb-b-5779.tsv             --target ../larger_dataset_by_naeem2/larger_dataset             --thread 8             --stat BETA             --beta             --binary-target F             --quantile 10             --out ./PRSice_output/ukb-b-5779/ukb-b-5779             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat UKB-B-5779:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ukb-b-5779/ukb-b-5779.valid\n",
      "stat {'beta'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.3 (2020-08-05) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-11-19 05:37:02\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ukb-b-5779.tsv \\\n",
      "    --beta  \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ukb-b-5779/ukb-b-5779.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --out ./PRSice_output/ukb-b-5779/ukb-b-5779 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 3812487397 \\\n",
      "    --snp ID \\\n",
      "    --stat UKB-B-5779:ES \\\n",
      "    --target ../larger_dataset_by_naeem2/larger_dataset \\\n",
      "    --thread 8 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset_by_naeem2/larger_dataset (bed) \n",
      "\n",
      "Start processing ukb-b-5779 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ukb-b-5779.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tUKB-B-5779:ES\tUKB-B-5779:SE\tUKB-B-5779:LP\tUKB-B-5779:AF\tUKB-B-5779:SS\tUKB-B-5779:EZ\tUKB-B-5779:SI\tUKB-B-5779:NC\tUKB-B-5779:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "9851866 variant(s) observed in base file, with: \n",
      "3268847 variant(s) excluded based on user input \n",
      "6583019 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "1245185 variant(s) not found in previous data \n",
      "29 variant(s) with mismatch information \n",
      "6583019 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 387777 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s) with p-value between 0.1 and 1e-5 \n",
      "(\u001b[1;31mmay not be significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n",
      "-----------------------counter  32  ------------------------------------\n",
      "*****GWAS ID IS***** ukb-b-15541\n",
      "stat {'or'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ukb-b-15541.tsv             --target ../larger_dataset_by_naeem2/larger_dataset             --thread 8             --stat OR             --or             --binary-target F             --quantile 10             --out ./PRSice_output/ukb-b-15541/ukb-b-15541             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat UKB-B-15541:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ukb-b-15541/ukb-b-15541.valid\n",
      "stat {'or'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.3 (2020-08-05) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-11-19 05:38:20\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ukb-b-15541.tsv \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ukb-b-15541/ukb-b-15541.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --or  \\\n",
      "    --out ./PRSice_output/ukb-b-15541/ukb-b-15541 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 1831862542 \\\n",
      "    --snp ID \\\n",
      "    --stat UKB-B-15541:ES \\\n",
      "    --target ../larger_dataset_by_naeem2/larger_dataset \\\n",
      "    --thread 8 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset_by_naeem2/larger_dataset (bed) \n",
      "\n",
      "Start processing ukb-b-15541 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ukb-b-15541.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tUKB-B-15541:ES\tUKB-B-15541:SE\tUKB-B-15541:LP\tUKB-B-15541:AF\tUKB-B-15541:SS\tUKB-B-15541:EZ\tUKB-B-15541:SI\tUKB-B-15541:NC\tUKB-B-15541:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "4801285 variant(s) observed in base file, with: \n",
      "2775682 variant(s) excluded based on user input \n",
      "2025603 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "5802618 variant(s) not found in previous data \n",
      "12 variant(s) with mismatch information \n",
      "2025603 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 93706 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s)/phenotype(s) with p-value > 0.1 (\u001b[1;31mnot \n",
      "significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n",
      "-----------------------counter  33  ------------------------------------\n",
      "*****GWAS ID IS***** ukb-b-19732\n",
      "stat {'or'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ukb-b-19732.tsv             --target ../larger_dataset_by_naeem2/larger_dataset             --thread 8             --stat OR             --or             --binary-target F             --quantile 10             --out ./PRSice_output/ukb-b-19732/ukb-b-19732             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat UKB-B-19732:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ukb-b-19732/ukb-b-19732.valid\n",
      "stat {'or'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.3 (2020-08-05) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-11-19 05:38:49\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ukb-b-19732.tsv \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ukb-b-19732/ukb-b-19732.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --or  \\\n",
      "    --out ./PRSice_output/ukb-b-19732/ukb-b-19732 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 3776324529 \\\n",
      "    --snp ID \\\n",
      "    --stat UKB-B-19732:ES \\\n",
      "    --target ../larger_dataset_by_naeem2/larger_dataset \\\n",
      "    --thread 8 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset_by_naeem2/larger_dataset (bed) \n",
      "\n",
      "Start processing ukb-b-19732 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ukb-b-19732.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tUKB-B-19732:ES\tUKB-B-19732:SE\tUKB-B-19732:LP\tUKB-B-19732:AF\tUKB-B-19732:SS\tUKB-B-19732:EZ\tUKB-B-19732:SI\tUKB-B-19732:NC\tUKB-B-19732:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "7112787 variant(s) observed in base file, with: \n",
      "4114633 variant(s) excluded based on user input \n",
      "2998154 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "4830065 variant(s) not found in previous data \n",
      "14 variant(s) with mismatch information \n",
      "2998154 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 211898 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s) with p-value between 0.1 and 1e-5 \n",
      "(\u001b[1;31mmay not be significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "2: 0\n",
      "-----------------------counter  ===== Done =====\n",
      "34  ------------------------------------\n",
      "*****GWAS ID IS***** ukb-b-20289\n",
      "stat {'or'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ukb-b-20289.tsv             --target ../larger_dataset_by_naeem2/larger_dataset             --thread 8             --stat OR             --or             --binary-target F             --quantile 10             --out ./PRSice_output/ukb-b-20289/ukb-b-20289             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat UKB-B-20289:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ukb-b-20289/ukb-b-20289.valid\n",
      "stat {'or'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.3 (2020-08-05) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-11-19 05:39:31\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ukb-b-20289.tsv \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ukb-b-20289/ukb-b-20289.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --or  \\\n",
      "    --out ./PRSice_output/ukb-b-20289/ukb-b-20289 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 3720958838 \\\n",
      "    --snp ID \\\n",
      "    --stat UKB-B-20289:ES \\\n",
      "    --target ../larger_dataset_by_naeem2/larger_dataset \\\n",
      "    --thread 8 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset_by_naeem2/larger_dataset (bed) \n",
      "\n",
      "Start processing ukb-b-20289 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ukb-b-20289.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tUKB-B-20289:ES\tUKB-B-20289:SE\tUKB-B-20289:LP\tUKB-B-20289:AF\tUKB-B-20289:SS\tUKB-B-20289:EZ\tUKB-B-20289:SI\tUKB-B-20289:NC\tUKB-B-20289:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "4329979 variant(s) observed in base file, with: \n",
      "2504040 variant(s) excluded based on user input \n",
      "1825939 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "6002282 variant(s) not found in previous data \n",
      "12 variant(s) with mismatch information \n",
      "1825939 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 81321 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s)/phenotype(s) with p-value > 0.1 (\u001b[1;31mnot \n",
      "significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n",
      "-----------------------counter  35  ------------------------------------\n",
      "*****GWAS ID IS***** ukb-b-14057\n",
      "stat {'or'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ukb-b-14057.tsv             --target ../larger_dataset_by_naeem2/larger_dataset             --thread 8             --stat OR             --or             --binary-target F             --quantile 10             --out ./PRSice_output/ukb-b-14057/ukb-b-14057             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat UKB-B-14057:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ukb-b-14057/ukb-b-14057.valid\n",
      "stat {'or'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.3 (2020-08-05) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-11-19 05:39:58\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ukb-b-14057.tsv \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ukb-b-14057/ukb-b-14057.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --or  \\\n",
      "    --out ./PRSice_output/ukb-b-14057/ukb-b-14057 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 494323126 \\\n",
      "    --snp ID \\\n",
      "    --stat UKB-B-14057:ES \\\n",
      "    --target ../larger_dataset_by_naeem2/larger_dataset \\\n",
      "    --thread 8 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset_by_naeem2/larger_dataset (bed) \n",
      "\n",
      "Start processing ukb-b-14057 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ukb-b-14057.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tUKB-B-14057:ES\tUKB-B-14057:SE\tUKB-B-14057:LP\tUKB-B-14057:AF\tUKB-B-14057:SS\tUKB-B-14057:EZ\tUKB-B-14057:SI\tUKB-B-14057:NC\tUKB-B-14057:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "9154199 variant(s) observed in base file, with: \n",
      "5899687 variant(s) excluded based on user input \n",
      "3254512 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "4573705 variant(s) not found in previous data \n",
      "16 variant(s) with mismatch information \n",
      "3254512 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 251713 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s) with p-value between 0.1 and 1e-5 \n",
      "(\u001b[1;31mmay not be significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n",
      "-----------------------counter  36  ------------------------------------\n",
      "*****GWAS ID IS***** ukb-b-12963\n",
      "stat {'beta'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ukb-b-12963.tsv             --target ../larger_dataset_by_naeem2/larger_dataset             --thread 8             --stat BETA             --beta             --binary-target F             --quantile 10             --out ./PRSice_output/ukb-b-12963/ukb-b-12963             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat UKB-B-12963:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ukb-b-12963/ukb-b-12963.valid\n",
      "stat {'beta'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.3 (2020-08-05) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-11-19 05:40:44\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ukb-b-12963.tsv \\\n",
      "    --beta  \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ukb-b-12963/ukb-b-12963.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --out ./PRSice_output/ukb-b-12963/ukb-b-12963 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 3804171823 \\\n",
      "    --snp ID \\\n",
      "    --stat UKB-B-12963:ES \\\n",
      "    --target ../larger_dataset_by_naeem2/larger_dataset \\\n",
      "    --thread 8 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset_by_naeem2/larger_dataset (bed) \n",
      "\n",
      "Start processing ukb-b-12963 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ukb-b-12963.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tUKB-B-12963:ES\tUKB-B-12963:SE\tUKB-B-12963:LP\tUKB-B-12963:AF\tUKB-B-12963:SS\tUKB-B-12963:EZ\tUKB-B-12963:SI\tUKB-B-12963:NC\tUKB-B-12963:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "9851866 variant(s) observed in base file, with: \n",
      "3268847 variant(s) excluded based on user input \n",
      "6583019 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "1245185 variant(s) not found in previous data \n",
      "29 variant(s) with mismatch information \n",
      "6583019 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 388490 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s)/phenotype(s) with p-value > 0.1 (\u001b[1;31mnot \n",
      "significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n",
      "-----------------------counter  37  ------------------------------------\n",
      "*****GWAS ID IS***** ukb-b-12417\n",
      "stat {'beta'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ukb-b-12417.tsv             --target ../larger_dataset_by_naeem2/larger_dataset             --thread 8             --stat BETA             --beta             --binary-target F             --quantile 10             --out ./PRSice_output/ukb-b-12417/ukb-b-12417             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat UKB-B-12417:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ukb-b-12417/ukb-b-12417.valid\n",
      "stat {'beta'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.3 (2020-08-05) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-11-19 05:42:04\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ukb-b-12417.tsv \\\n",
      "    --beta  \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ukb-b-12417/ukb-b-12417.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --out ./PRSice_output/ukb-b-12417/ukb-b-12417 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 2840032872 \\\n",
      "    --snp ID \\\n",
      "    --stat UKB-B-12417:ES \\\n",
      "    --target ../larger_dataset_by_naeem2/larger_dataset \\\n",
      "    --thread 8 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset_by_naeem2/larger_dataset (bed) \n",
      "\n",
      "Start processing ukb-b-12417 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ukb-b-12417.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tUKB-B-12417:ES\tUKB-B-12417:SE\tUKB-B-12417:LP\tUKB-B-12417:AF\tUKB-B-12417:SS\tUKB-B-12417:EZ\tUKB-B-12417:SI\tUKB-B-12417:NC\tUKB-B-12417:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "9851866 variant(s) observed in base file, with: \n",
      "3268847 variant(s) excluded based on user input \n",
      "6583019 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "1245185 variant(s) not found in previous data \n",
      "29 variant(s) with mismatch information \n",
      "6583019 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 388543 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s)/phenotype(s) with p-value > 0.1 (\u001b[1;31mnot \n",
      "significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n",
      "-----------------------counter  38  ------------------------------------\n",
      "*****GWAS ID IS***** ukb-b-11495\n",
      "stat {'or'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ukb-b-11495.tsv             --target ../larger_dataset_by_naeem2/larger_dataset             --thread 8             --stat OR             --or             --binary-target F             --quantile 10             --out ./PRSice_output/ukb-b-11495/ukb-b-11495             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat UKB-B-11495:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ukb-b-11495/ukb-b-11495.valid\n",
      "stat {'or'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.3 (2020-08-05) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-11-19 05:43:23\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ukb-b-11495.tsv \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ukb-b-11495/ukb-b-11495.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --or  \\\n",
      "    --out ./PRSice_output/ukb-b-11495/ukb-b-11495 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 4252418098 \\\n",
      "    --snp ID \\\n",
      "    --stat UKB-B-11495:ES \\\n",
      "    --target ../larger_dataset_by_naeem2/larger_dataset \\\n",
      "    --thread 8 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset_by_naeem2/larger_dataset (bed) \n",
      "\n",
      "Start processing ukb-b-11495 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ukb-b-11495.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tUKB-B-11495:ES\tUKB-B-11495:SE\tUKB-B-11495:LP\tUKB-B-11495:AF\tUKB-B-11495:SS\tUKB-B-11495:EZ\tUKB-B-11495:SI\tUKB-B-11495:NC\tUKB-B-11495:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "9606172 variant(s) observed in base file, with: \n",
      "6370208 variant(s) excluded based on user input \n",
      "3235964 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "4592254 variant(s) not found in previous data \n",
      "15 variant(s) with mismatch information \n",
      "3235964 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 255065 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s) with p-value between 0.1 and 1e-5 \n",
      "(\u001b[1;31mmay not be significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n",
      "-----------------------counter  39  ------------------------------------\n",
      "*****GWAS ID IS***** ukb-b-12493\n",
      "stat {'or'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ukb-b-12493.tsv             --target ../larger_dataset_by_naeem2/larger_dataset             --thread 8             --stat OR             --or             --binary-target F             --quantile 10             --out ./PRSice_output/ukb-b-12493/ukb-b-12493             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat UKB-B-12493:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ukb-b-12493/ukb-b-12493.valid\n",
      "stat {'or'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.3 (2020-08-05) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-11-19 05:44:10\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ukb-b-12493.tsv \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ukb-b-12493/ukb-b-12493.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --or  \\\n",
      "    --out ./PRSice_output/ukb-b-12493/ukb-b-12493 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 1195936060 \\\n",
      "    --snp ID \\\n",
      "    --stat UKB-B-12493:ES \\\n",
      "    --target ../larger_dataset_by_naeem2/larger_dataset \\\n",
      "    --thread 8 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset_by_naeem2/larger_dataset (bed) \n",
      "\n",
      "Start processing ukb-b-12493 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ukb-b-12493.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tUKB-B-12493:ES\tUKB-B-12493:SE\tUKB-B-12493:LP\tUKB-B-12493:AF\tUKB-B-12493:SS\tUKB-B-12493:EZ\tUKB-B-12493:SI\tUKB-B-12493:NC\tUKB-B-12493:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "8361394 variant(s) observed in base file, with: \n",
      "5141254 variant(s) excluded based on user input \n",
      "3220140 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "4608077 variant(s) not found in previous data \n",
      "16 variant(s) with mismatch information \n",
      "3220140 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 249405 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset_by_naeem2/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s) with p-value between 0.1 and 1e-5 \n",
      "(\u001b[1;31mmay not be significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n"
     ]
    }
   ],
   "source": [
    "# here for some files a weird error occurs: \"reporter not initialized\"\n",
    "# soln : create corresponding directory\n",
    "# bbj-a-78\n",
    "# ukb-a-257\n",
    "# bbj-a-46\n",
    "# these are not included due to not being in the EUR ancestry\n",
    "counter = 0\n",
    "for GWAS_ID in base_files:\n",
    "#     if GWAS_ID == 'ukb-b-6134':\n",
    "    counter += 1\n",
    "    if counter > 1:\n",
    "        print('-----------------------counter ',counter,' ------------------------------------')\n",
    "        print('*****GWAS ID IS*****',GWAS_ID)\n",
    "    #         run_prsice(GWAS_ID=GWAS_ID)\n",
    "        run_prsice_for_larger_by_us(GWAS_ID=GWAS_ID)\n",
    "\n",
    "#         problem -> they do not have corresponding entries in prsice_output folder->create those folders manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_prsice(GWAS_ID='ukb-b-17627')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls 'tabular_format_gwas_data/{GWAS_ID}.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# base_files=[] #naeem mod\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m GWAS_ID \u001b[38;5;129;01min\u001b[39;00m ALL_GWAS_IDS:\n\u001b[1;32m     26\u001b[0m \n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#     file = ROOT + GWAS_ID + '.vcf.gz'\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m     base_files[GWAS_ID] \u001b[38;5;241m=\u001b[39m category_map[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGWAS_ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mGWAS_ID\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m]\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#     generate_gwas_output_as_tsv_file(inVCF_File=file, writeFile=None)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# print(name_mapping)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# print(name_mapping)\u001b[39;00m\n\u001b[1;32m     34\u001b[0m gender_map \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFemale\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMale\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m}\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "# # need to remove this\n",
    "# from glob import glob\n",
    "# import pandas as pd\n",
    "# category_map = {\n",
    "#     'Continuous' : 'beta', \n",
    "#     'Categorical Ordered (assumed continuous)': 'beta',\n",
    "#     'Binary': 'or',\n",
    "#     'NA (Possibly binary)': 'or'\n",
    "# }\n",
    "\n",
    "# df = pd.read_excel('GWAS_datasets_to_consider.xlsx', engine='openpyxl')[['GWAS_ID', 'Trait', 'Category']]\n",
    "# # all_gwas_vcf_files = glob('/mnt/c/Users/HP/Downloads/Compressed/GWAS/*')\n",
    "# # ROOT = '/mnt/c/Users/HP/Downloads/Compressed/GWAS/'\n",
    "# # ALL_GWAS_IDS = list(set(df['GWAS_ID'].to_numpy().tolist()) - {'bbj-a-46', 'bbj-a-78', 'ieu-a-1283', 'ukb-a-257','ukb-b-2209','ukb-b-17627','ieub-109','ieu-b-110','ieu-b-111','met-d-Total_C'})\n",
    "# # bbj-a-78,ukb-a-257,bbj-a-46\n",
    "# # ALL_GWAS_IDS = list(set(df['GWAS_ID'].to_numpy().tolist()) - { 'ieu-a-1283','bbj-a-46', 'bbj-a-78'})\n",
    "# ALL_GWAS_IDS = list(set(df['GWAS_ID'].to_numpy().tolist()) - { 'ieu-a-1283','bbj-a-46', 'bbj-a-78','ukb-b-13806','ukb-b-12064','ukb-b-323','ukb-b-14699','ukb-b-14699','ukb-b-5779'})\n",
    "# print(len(ALL_GWAS_IDS))\n",
    "\n",
    "# ALL_GWAS_IDS= {'ukb-b-17006','ukb-b-5779','ukb-b-15541','ukb-b-20289','ukb-b-19732','ukb-b-6324','ukb-b-7663','ukb-b-770','ukb-b-323','ukb-b-14699','ukb-b-14180','ukb-b-17243','ukb-b-6358','','ukb-b-8476','','ukb-b-6134','ukb-b-4424','ukb-b-3957','ukb-b-2209','ukb-b-19953','ukb-b-18275','ukb-b-17627','ukb-b-12064','ukb-a-257','ieu-b-39','ieu-b-38','ieu-b-25','ieu-b-111','ieu-b-110','ieu-b-109','met-d-Total_C','ukb-d-20405_2','ukb-d-20405_1','ukb-d-20405_0','ukb-b-13806','ukb-b-13806','ukb-b-12064','ukb-b-323','ukb-b-14699','ukb-b-14699','ukb-b-5779'}\n",
    "\n",
    "# base_files = {}\n",
    "\n",
    "# # base_files=[] #naeem mod\n",
    "# for GWAS_ID in ALL_GWAS_IDS:\n",
    "\n",
    "# #     file = ROOT + GWAS_ID + '.vcf.gz'\n",
    "#     base_files[GWAS_ID] = category_map[df[df['GWAS_ID'] == GWAS_ID].to_numpy()[0, 2]]\n",
    "\n",
    "# #     generate_gwas_output_as_tsv_file(inVCF_File=file, writeFile=None)\n",
    "# # print(name_mapping)\n",
    "# # print(name_mapping)\n",
    "\n",
    "# gender_map = {'Female': 0,'Male': 1}\n",
    "# ADNIMERGE = pd.read_csv('ADNIMERGE.csv')\n",
    "# def get_gender_and_age(PTID):\n",
    "#     gender = ADNIMERGE[ADNIMERGE['PTID'] == PTID]['PTGENDER'].dropna().unique()[0]\n",
    "#     age = ADNIMERGE[ADNIMERGE['PTID'] == PTID]['AGE'].dropna().unique()[0]\n",
    "#     return str(gender_map[gender]) + ' ' + str(age)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_files\n",
    "GWAS_ID = 'ukb-b-14057'\n",
    "\n",
    "#====\n",
    "\n",
    "def get_prs_values(GWAS_ID):\n",
    "    prsice_output = f'./PRSice_output/{GWAS_ID}/'\n",
    "\n",
    "    if False:\n",
    "        with open(prsice_output+f'{GWAS_ID}.all_score', 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            lines = ['\\t'.join(x.split()) for x in lines]\n",
    "            lines = '\\n'.join(lines)\n",
    "\n",
    "        with open(prsice_output+f'{GWAS_ID}.all_score.tsv', 'w') as f:\n",
    "            f.write(lines)\n",
    "\n",
    "        # best_p_val_threshold = '0.00025005'\n",
    "        best_p_val_threshold = str(open(prsice_output+f'{GWAS_ID}.summary').readlines()[1].split('\\t')[2]) \n",
    "    #     print(best_p_val_threshold) \n",
    "    prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy() \n",
    "    return prs_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16760/1595037025.py:1: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  get_prs_values(GWAS_ID=GWAS_ID).shape[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1816"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prs_values(GWAS_ID=GWAS_ID).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "folderCounter=14\n",
    "folderCounter=folderCounter+1\n",
    "# inputFolder=\"input/\"+str(folderCounter)+\"/\"\n",
    "inputFolder=\"\"\n",
    "# os.mkdir(inputFolder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base files {'ukb-b-13806': 'or', 'ukb-d-20405_0': 'or', 'ukb-d-20405_1': 'or', 'ukb-d-20405_2': 'or', 'met-d-Total_C': 'beta', 'ieu-b-109': 'beta', 'ieu-b-110': 'beta', 'ieu-b-111': 'beta', 'ieu-b-25': 'beta', 'ieu-b-38': 'beta', 'ieu-b-39': 'beta', 'ukb-a-257': 'or', 'ukb-b-12064': 'or', 'ukb-b-17627': 'beta', 'ukb-b-18275': 'or', 'ukb-b-19953': 'beta', 'ukb-b-2209': 'beta', 'ukb-b-3957': 'beta', 'ukb-b-4424': 'beta', 'ukb-b-6134': 'beta', 'ukb-b-6324': 'beta', 'ukb-b-7663': 'or', 'ukb-b-770': 'beta', 'ukb-b-8476': 'or', 'ukb-b-323': 'or', 'ukb-b-14699': 'or', 'ukb-b-14180': 'or', 'ukb-b-17243': 'or', 'ukb-b-6358': 'or', 'ukb-b-17006': 'or', 'ukb-b-5779': 'beta', 'ukb-b-15541': 'or', 'ukb-b-19732': 'or', 'ukb-b-20289': 'or', 'ukb-b-14057': 'or', 'ukb-b-12963': 'beta', 'ukb-b-12417': 'beta', 'ukb-b-11495': 'or', 'ukb-b-12493': 'or'}\n",
      "new base files ['ukb-b-13806', 'ukb-d-20405_0', 'ukb-d-20405_1', 'ukb-d-20405_2', 'met-d-Total_C', 'ieu-b-109', 'ieu-b-110', 'ieu-b-111', 'ieu-b-25', 'ieu-b-38', 'ieu-b-39', 'ukb-a-257', 'ukb-b-12064', 'ukb-b-17627', 'ukb-b-18275', 'ukb-b-19953', 'ukb-b-2209', 'ukb-b-3957', 'ukb-b-4424', 'ukb-b-6134', 'ukb-b-6324', 'ukb-b-7663', 'ukb-b-770', 'ukb-b-8476', 'ukb-b-323', 'ukb-b-14699', 'ukb-b-14180', 'ukb-b-17243', 'ukb-b-6358', 'ukb-b-17006', 'ukb-b-5779', 'ukb-b-15541', 'ukb-b-19732', 'ukb-b-20289', 'ukb-b-14057', 'ukb-b-12963', 'ukb-b-12417', 'ukb-b-11495', 'ukb-b-12493']\n",
      "ukb-b-13806\n",
      "ukb-d-20405_0\n",
      "ukb-d-20405_1\n",
      "ukb-d-20405_2\n",
      "met-d-Total_C\n",
      "ieu-b-109\n",
      "ieu-b-110\n",
      "ieu-b-111\n",
      "ieu-b-25\n",
      "ieu-b-38\n",
      "ieu-b-39\n",
      "ukb-a-257\n",
      "ukb-b-12064\n",
      "ukb-b-17627\n",
      "ukb-b-18275\n",
      "ukb-b-19953\n",
      "ukb-b-2209\n",
      "ukb-b-3957\n",
      "ukb-b-4424\n",
      "ukb-b-6134\n",
      "ukb-b-6324\n",
      "ukb-b-7663\n",
      "ukb-b-770\n",
      "ukb-b-8476\n",
      "ukb-b-323\n",
      "ukb-b-14699\n",
      "ukb-b-14180\n",
      "ukb-b-17243\n",
      "ukb-b-6358\n",
      "ukb-b-17006\n",
      "ukb-b-5779\n",
      "ukb-b-15541\n",
      "ukb-b-19732\n",
      "ukb-b-20289\n",
      "ukb-b-14057\n",
      "ukb-b-12963\n",
      "ukb-b-12417\n",
      "ukb-b-11495\n",
      "ukb-b-12493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12328/1739813349.py:21: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy()\n",
      "/tmp/ipykernel_12328/1739813349.py:21: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy()\n",
      "/tmp/ipykernel_12328/1739813349.py:21: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy()\n",
      "/tmp/ipykernel_12328/1739813349.py:21: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy()\n",
      "/tmp/ipykernel_12328/1739813349.py:21: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy()\n",
      "/tmp/ipykernel_12328/1739813349.py:21: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy()\n",
      "/tmp/ipykernel_12328/1739813349.py:21: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy()\n",
      "/tmp/ipykernel_12328/1739813349.py:21: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy()\n",
      "/tmp/ipykernel_12328/1739813349.py:21: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy()\n",
      "/tmp/ipykernel_12328/1739813349.py:21: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy()\n",
      "/tmp/ipykernel_12328/1739813349.py:21: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy()\n",
      "/tmp/ipykernel_12328/1739813349.py:21: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy()\n",
      "/tmp/ipykernel_12328/1739813349.py:21: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy()\n",
      "/tmp/ipykernel_12328/1739813349.py:21: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy()\n",
      "/tmp/ipykernel_12328/1739813349.py:21: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy()\n",
      "/tmp/ipykernel_12328/1739813349.py:21: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy()\n",
      "/tmp/ipykernel_12328/1739813349.py:21: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy()\n",
      "/tmp/ipykernel_12328/1739813349.py:21: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy()\n",
      "/tmp/ipykernel_12328/1739813349.py:21: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy()\n",
      "/tmp/ipykernel_12328/1739813349.py:21: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy()\n",
      "/tmp/ipykernel_12328/1739813349.py:21: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy()\n",
      "/tmp/ipykernel_12328/1739813349.py:21: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy()\n",
      "/tmp/ipykernel_12328/1739813349.py:21: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy()\n",
      "/tmp/ipykernel_12328/1739813349.py:21: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy()\n",
      "/tmp/ipykernel_12328/1739813349.py:21: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy()\n",
      "/tmp/ipykernel_12328/1739813349.py:21: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy()\n",
      "/tmp/ipykernel_12328/1739813349.py:21: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy()\n",
      "/tmp/ipykernel_12328/1739813349.py:21: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy()\n",
      "/tmp/ipykernel_12328/1739813349.py:21: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy()\n",
      "/tmp/ipykernel_12328/1739813349.py:21: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy()\n",
      "/tmp/ipykernel_12328/1739813349.py:21: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy()\n",
      "/tmp/ipykernel_12328/1739813349.py:21: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy()\n",
      "/tmp/ipykernel_12328/1739813349.py:21: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy()\n",
      "/tmp/ipykernel_12328/1739813349.py:21: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy()\n",
      "/tmp/ipykernel_12328/1739813349.py:21: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy()\n",
      "/tmp/ipykernel_12328/1739813349.py:21: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy()\n",
      "/tmp/ipykernel_12328/1739813349.py:21: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy()\n",
      "/tmp/ipykernel_12328/1739813349.py:21: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy()\n",
      "/tmp/ipykernel_12328/1739813349.py:21: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os.path\n",
    "import json\n",
    "name_mapping={}\n",
    "# GWAS_ID\n",
    "# ukb-b-13806\n",
    "# ukb-b-12064\n",
    "# ukb-b-323\n",
    "# ukb-b-14699\n",
    "# ukb-b-5779\n",
    "# base_files=base_files-\n",
    "print('base files',base_files)\n",
    "newBaseFiles=[]\n",
    "for GWAS_ID in base_files:\n",
    "    prsice_output = f'./PRSice_output/{GWAS_ID}/{GWAS_ID}.best'\n",
    "    if os.path.exists(prsice_output):  \n",
    "        newBaseFiles.append(GWAS_ID)\n",
    "print('new base files',newBaseFiles)\n",
    "\n",
    "PRS_feature_matrix = np.zeros([len(newBaseFiles), 1816])\n",
    "# PRS_feature_matrix = np.zeros([len(newBaseFiles), 846])\n",
    "\n",
    "for i, GWAS_ID in enumerate(newBaseFiles):\n",
    "    print(GWAS_ID)\n",
    "    prsice_output = f'./PRSice_output/{GWAS_ID}/{GWAS_ID}.best'\n",
    "    if os.path.exists(prsice_output):  \n",
    "        PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
    "        name_mapping[GWAS_ID] =df[df['GWAS_ID'] == GWAS_ID].to_numpy()[0, 1]\n",
    "    else :\n",
    "        print(\"no path exists\")\n",
    "        \n",
    "# with open(inputFolder+\"traits_map.json\", \"w\") as outfile:\n",
    "with open(\"traits_map.json\", \"w\") as outfile:\n",
    "    \n",
    "    json.dump(name_mapping, outfile)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRS_feature_matrix = PRS_feature_matrix.T\n",
    "np.save(inputFolder+'PRS_feature_matrix', PRS_feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRS_feature_matrix.shape\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[914, 1589, 500, 1620, 1260, 1759, 482, 1317, 1700, 436, 1547, 1697, 888, 1045, 271, 144, 920, 385, 611, 249, 340, 1012, 1143, 1164, 919, 1651, 1635, 1537, 406, 878, 605, 886, 968, 861, 1500, 1484, 416, 1172, 534, 1053, 1202, 670, 516, 1015, 1116, 851, 891, 496, 1679, 1430, 1030, 1609, 1174, 995, 844, 127, 368, 1556, 1236, 88, 590, 132, 1420, 1208, 1475, 1517, 1684, 758, 880, 469, 12, 1585, 660, 211, 1627, 1719, 657, 1743, 1111, 606, 1810, 780, 170, 1314, 1487, 1076, 242, 831, 1442, 27, 1005, 180, 1705, 717, 1306, 739, 1622, 60, 671, 30, 169, 1136, 841, 1061, 638, 1319, 163, 1805, 1001, 1166, 1300, 837, 1189, 1263, 535, 405, 1675, 494, 597, 802, 707, 234, 458, 44, 897, 1206, 1227, 1542, 579, 403, 31, 1707, 410, 607, 585, 367, 1125, 501, 1521, 59, 447, 1417, 75, 817, 1513, 1105, 1100, 539, 917, 1595, 687, 859, 877, 1477, 103, 83, 1289, 787, 1040, 1405, 1795, 722, 703, 41, 1390, 1775, 1617, 139, 280, 1503, 1815, 1472, 1063, 1064, 505, 1029, 1545, 613, 836, 875, 1386, 1415, 344, 1766, 286, 1068, 3, 1370, 1205, 138, 239, 1067, 1581, 812, 1327, 514, 1251, 905, 813, 1147, 756, 1546, 1416, 457, 442, 1666, 650, 666, 1746, 1747, 1355, 706, 1499, 1286, 1408, 1080, 1704, 4, 1124, 1128, 152, 1060, 1593, 86, 1433, 65, 397, 473, 736, 1756, 1682, 77, 1197, 1501, 167, 808, 651, 1471, 1388, 1560, 547, 731, 1275, 598, 66, 348, 916, 1580, 955, 1439, 1358, 719, 137, 773, 1564, 1233, 1582, 1343, 335, 1454, 1504, 1650, 1075, 399, 408, 725, 1603, 1539, 338, 140, 1792, 1381, 1478, 1038, 938, 1165, 437, 541, 804, 76, 600, 1218, 433, 654, 1738, 1757, 1152, 1184, 653, 109, 1167, 1561, 342, 1628, 570, 550, 732, 386, 465, 1198, 1443, 1479, 1669, 1379, 304, 883, 1265, 1491, 1148, 165, 111, 809, 693, 507, 887, 969, 1554, 860, 395, 1601, 297, 1, 1672, 158, 662, 678, 1046, 1290, 273, 1806, 1441, 154, 1685, 1586, 1734, 612, 1328, 113, 1769, 1295, 409, 502, 698, 1350, 663, 826, 774, 1680, 298, 1605, 363, 1363, 1373, 1309, 347, 479, 1698, 1042, 633, 189, 388, 1257, 980, 1313, 470, 1009, 1458, 1723, 480, 1536, 522, 1529, 1725, 1612, 1368, 577, 337, 283, 1342, 538, 918, 262, 1035, 204, 1776, 1089, 237, 492, 536, 73, 108, 572, 186, 509, 1549, 157, 675, 741, 1778, 117, 1014, 293, 1544, 219, 1632, 1618, 1706, 1365, 1631, 993, 329, 1088, 1789, 1590, 1567, 131, 417, 471, 727, 658, 296, 1404, 769, 559, 37, 688, 1239, 676, 1667, 568, 1486, 1274, 1392, 1377, 1325, 1168, 1699, 510, 311, 997, 677, 1653, 1055, 246, 328, 308, 424, 1050, 986, 784, 1524, 527, 1193, 1262, 1797, 1104, 114, 398, 1287, 967, 354, 1473, 854, 1771, 939, 264, 664, 93, 1494, 845, 1025, 1246, 1312, 1069, 100, 292, 543, 1338, 35, 1110, 45, 1767, 1802, 299, 58, 70, 1447, 491, 184, 1508, 1791, 434, 28, 573, 1435, 202, 982, 815, 32, 956, 419, 243, 1742, 1161, 356, 745, 266, 1139, 586, 265, 1359, 960, 380, 1459, 499, 1098, 526, 63, 818, 712, 628, 1793, 1389, 285, 870, 317, 595, 418, 744, 716, 763, 1445, 1156, 1133, 798, 738, 357, 954, 519, 1448, 1398, 68, 220, 1464, 561, 913, 1758, 1102, 1077, 52, 36, 873, 785, 208, 957, 302, 172, 1765, 1256, 733, 40, 975, 355, 1497, 227, 1678, 981, 1644, 1754, 934, 926, 1142, 238, 1485, 1387, 1270, 94, 542, 300, 375, 173, 524, 62, 1784, 765, 240, 558, 223, 1534, 623, 358, 898, 1376, 153, 762, 885, 749, 1135, 1423, 118, 95, 487, 389, 994, 33, 1694, 1683, 943, 1640, 463, 1051, 1419, 617, 928, 1129, 1563, 1016, 47, 1573, 796, 1403, 1422, 270, 291, 868, 1712, 1285, 1170, 1395, 178, 1483, 1049, 69, 80, 674, 1149, 1356, 525, 964, 1813, 1333, 1331, 757, 1557, 306, 1258, 1476, 1613, 96, 1583, 1396, 1413, 333, 364, 820, 1173, 235, 1532, 1516, 511, 1117, 1480, 655, 584, 1003, 426, 958, 1241, 553, 1267, 596, 332, 567, 316, 625, 241, 490, 1271, 822, 124, 250, 1234, 1412, 846, 1739, 1638, 1681, 320, 1753, 775, 1608, 1509, 907, 708, 155, 1272, 723, 668, 1465, 587, 531, 1803, 1090, 901, 950, 196, 866, 1226, 1259, 8, 1028, 1782, 1186, 488, 799, 1455, 7, 1278, 303, 376, 1158, 1112, 1654, 1019, 1741, 464, 110, 983, 1400, 104, 423, 1151, 640, 314, 269, 949, 1162, 904, 256, 497, 1224, 1597, 1094, 448, 1013, 1335, 1652, 989, 414, 1735, 855, 54, 940, 217, 102, 1187, 295, 1641, 686, 1702, 937, 1728, 1378, 1663, 852, 1496, 618, 272, 1673, 1781, 142, 1244, 1032, 747, 1421, 1196, 1021, 1578, 126, 1600, 11, 1036, 1264, 621, 1221, 439, 1283, 404, 909, 1460, 207, 1204, 365, 1123, 970, 1402, 1809, 1243, 911, 643, 427, 695, 151, 38, 441, 646, 263, 432, 21, 771, 1648, 1250, 691, 112, 565, 267, 495, 215, 428, 1703, 1372, 425, 1530, 1446, 254, 721, 1559, 1505, 1130, 1520, 71, 1017, 700, 1602, 1207, 616, 991, 1535, 1551, 372, 190, 231, 1526, 673, 315, 1538, 1664, 210, 697, 702, 801, 450, 1630, 472, 230, 261, 659, 1108, 475, 1519, 1023, 1469, 1383, 1715, 135, 225, 1091, 1253, 49, 622, 14, 1772, 87, 503, 1426, 330, 714, 1247, 563, 413, 481, 752, 1330, 641, 635, 456, 1339, 1814, 709, 1629, 125, 0, 478, 1571, 1238, 755, 684, 760, 209, 1000, 343, 353, 1533, 483, 74, 18, 893, 555, 636, 1245, 1774, 233, 1079, 1525, 1248, 459, 374, 466, 750, 751, 656, 97, 645, 1615, 1371, 179, 177, 1155, 341, 390, 1662, 1137, 129, 1292, 1599, 783, 451, 120, 9, 1157, 143, 604, 24, 1543, 952, 816, 1341, 965, 1726, 279, 1591, 608, 393, 1344, 226, 996, 1101, 1713, 435, 610, 119, 294, 665, 1507, 705, 1180, 148, 789, 1115, 394, 858, 1411, 1175, 81, 1081, 647, 392, 1305, 594, 1268, 1541, 923, 1277, 484, 1315, 1385, 545, 821, 720, 1225, 1351, 1614, 162, 900, 1054, 383, 1106, 795, 1570, 1360, 978, 932, 1626, 564, 770, 1353, 187, 1153, 1799, 1548, 793, 1073, 1384, 1320, 945, 710, 1375, 766, 966, 1621, 268, 1744, 902, 772, 191, 445, 1369, 788, 1052, 50, 1190, 99, 847, 288, 941, 1352, 1008, 1231, 1452, 903, 832, 1382, 90, 1562, 1522, 1752, 309, 1255, 689, 402, 1212, 680, 1336, 468, 1210, 1279, 1179, 1096, 460, 1616, 1203, 1181, 1492, 1647, 1240, 313, 504, 370, 630, 915, 1506, 1361, 166, 1780, 583, 1041, 1299, 1027, 951, 1461, 185, 373, 637, 931, 1086, 1059, 1201, 476, 415, 1518, 1670, 188, 1297, 1686, 1321, 1176, 828, 391, 1146, 244, 589, 614, 121, 454, 1807, 1345, 19, 862, 591, 626, 580, 1169, 1531, 1462, 924, 894, 1467, 876, 1812, 1796, 17, 1002, 1302, 1451, 247, 690, 835, 145, 1048, 1043, 1577, 493, 1801, 1126, 1122, 22, 1087, 1566, 1020, 988, 1463, 1716, 1391, 116, 1689, 1429, 82, 197, 1444, 214, 1291, 1639, 1474, 786, 929, 1160, 1607, 1493, 1033, 182, 648, 1230, 1457, 551, 857, 1642, 1037, 593, 806, 260, 1354, 1066, 946, 39, 212, 149, 411, 161, 128, 1220, 856, 592, 1127, 171, 1729, 523, 1511, 1347, 759, 829, 1720, 962, 1348, 1223, 201, 115, 825, 369, 1083, 834, 20, 1209, 890, 781, 1800, 661, 1074, 1018, 1808, 1024, 245, 743, 1288, 378, 319, 1308, 453, 1393, 1649, 1318, 42, 1334, 1011, 1242, 1144, 761, 420, 1191, 346, 1575, 183, 1657, 1072, 324, 889, 557, 1082, 1004, 78, 1228, 1039, 1324, 1588, 644, 1056, 282, 1625, 1113, 824, 289, 101, 800, 1724, 1569, 754, 549, 1558, 1177, 603, 1696, 1269, 1213, 325, 498, 1194, 1610]\n",
      "550 1266 1816\n"
     ]
    }
   ],
   "source": [
    "TRAIN_SAMPLE_SIZE = 550\n",
    "train_samples = list(range(1816))\n",
    "random.shuffle(train_samples)\n",
    "train_samples, test_samples = train_samples[:TRAIN_SAMPLE_SIZE], train_samples[TRAIN_SAMPLE_SIZE:]\n",
    "print(test_samples)\n",
    "print(len(train_samples), len(test_samples), len(train_samples) + len(test_samples))\n",
    "# PRS_feature_matrix[train_samples].mean(0), PRS_feature_matrix[train_samples].std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.01031536, -0.02281834, -0.00394759, -0.02264448, -0.0193774 ,\n",
       "         0.00632123, -0.00650544, -0.00742301, -0.02755314,  0.01118149,\n",
       "        -0.00981811, -0.02792764, -0.00815029,  0.00993923, -0.0237625 ,\n",
       "        -0.00446245,  0.00538661,  0.01710965,  0.01374963,  0.010898  ,\n",
       "        -0.00243885, -0.02328532, -0.01074045, -0.01649424,  0.00676362,\n",
       "         0.00941212, -0.02498994, -0.01983584, -0.02850219, -0.03180173,\n",
       "        -0.04444718, -0.01293681, -0.0255557 , -0.01489494, -0.02831349,\n",
       "        -0.0313447 , -0.02836364, -0.0244011 , -0.02474088]),\n",
       " array([0.96742415, 0.91450364, 0.97581383, 0.92597209, 1.01119581,\n",
       "        0.99183426, 0.99871367, 1.00089391, 1.00691625, 0.9990749 ,\n",
       "        1.00174667, 0.92199834, 0.97453648, 0.9970049 , 0.93051232,\n",
       "        1.01008579, 1.01134924, 1.01171729, 0.93070884, 0.99717131,\n",
       "        1.00201104, 0.9215018 , 1.00674744, 0.96450593, 0.99960003,\n",
       "        1.01833358, 0.95689942, 0.9501297 , 0.96951256, 0.98937893,\n",
       "        0.90405369, 0.98500742, 0.91720564, 1.00564947, 0.93059207,\n",
       "        0.89007359, 0.92688609, 0.91876293, 0.9317471 ]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PRS_feature_matrix[test_samples].mean(0), PRS_feature_matrix[test_samples].std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.80121253e-11, -7.23843658e-11, -4.03398744e-11, -1.24741255e-11,\n",
       "         1.19856782e-11,  8.02313086e-12, -3.06668484e-11,  6.21563858e-11,\n",
       "        -2.72191628e-11,  7.99063703e-12,  7.19383295e-11, -1.15251910e-12,\n",
       "        -3.74664176e-11,  1.85110097e-11, -5.24669764e-11,  1.11084739e-11,\n",
       "         5.59416361e-11,  3.21943862e-11, -5.24559427e-11, -2.76734093e-12,\n",
       "        -1.95044098e-11,  9.72282264e-12,  5.42070353e-12,  6.10582832e-11,\n",
       "         3.02257739e-11,  1.54763251e-11,  3.52919065e-11, -6.37114248e-12,\n",
       "        -8.16188233e-12,  4.53524247e-11, -1.82294982e-11,  3.02863363e-12,\n",
       "         6.98566804e-12,  3.05832070e-11, -1.58479201e-13,  4.16432195e-11,\n",
       "         2.62714803e-11,  1.76151057e-11, -4.53576677e-12]),\n",
       " array([0.99972463, 0.99972463, 0.99972463, 0.99972463, 0.99972463,\n",
       "        0.99972463, 0.99972463, 0.99972463, 0.99972463, 0.99972463,\n",
       "        0.99972463, 0.99972463, 0.99972463, 0.99972463, 0.99972463,\n",
       "        0.99972463, 0.99972463, 0.99972463, 0.99972463, 0.99972463,\n",
       "        0.99972463, 0.99972463, 0.99972463, 0.99972463, 0.99972463,\n",
       "        0.99972463, 0.99972463, 0.99972463, 0.99972463, 0.99972463,\n",
       "        0.99972463, 0.99972463, 0.99972463, 0.99972463, 0.99972463,\n",
       "        0.99972463, 0.99972463, 0.99972463, 0.99972463]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PRS_feature_matrix[:].mean(0), PRS_feature_matrix[:].std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12328/1558320868.py:4: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  usable_samples_ADNI_unsplitted = pd.read_csv(f'./PRSice_output/{GWAS_ID}/{GWAS_ID}.best', ' ')['IID'].to_numpy().tolist()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'036_S_6231': 'ADNI3_036_S_6231',\n",
       " '006_S_6277': 'ADNI3_006_S_6277',\n",
       " '129_S_6146': 'ADNI3_129_S_6146',\n",
       " '033_S_6352': 'ADNI3_033_S_6352',\n",
       " '027_S_6183': 'ADNI3_027_S_6183',\n",
       " '005_S_6427': 'ADNI3_005_S_6427',\n",
       " '127_S_6147': 'ADNI3_127_S_6147',\n",
       " '114_S_6251': 'ADNI3_114_S_6251',\n",
       " '129_S_6228': 'ADNI3_129_S_6228',\n",
       " '114_S_6309': 'ADNI3_114_S_6309',\n",
       " '135_S_6110': 'ADNI3_135_S_6110',\n",
       " '020_S_6358': 'ADNI3_020_S_6358',\n",
       " '135_S_6411': 'ADNI3_135_S_6411',\n",
       " '024_S_6202': 'ADNI3_024_S_6202',\n",
       " '018_S_6414': 'ADNI3_018_S_6414',\n",
       " '002_S_6103': 'ADNI3_002_S_6103',\n",
       " '177_S_6408': 'ADNI3_177_S_6408',\n",
       " '014_S_6148': 'ADNI3_014_S_6148',\n",
       " '036_S_6466': 'ADNI3_036_S_6466',\n",
       " '036_S_6134': 'ADNI3_036_S_6134',\n",
       " '007_S_6455': 'ADNI3_007_S_6455',\n",
       " '037_S_6271': 'ADNI3_037_S_6271',\n",
       " '116_S_6100': 'ADNI3_116_S_6100',\n",
       " '027_S_6327': 'ADNI3_027_S_6327',\n",
       " '099_S_6097': 'ADNI3_099_S_6097',\n",
       " '127_S_6330': 'ADNI3_127_S_6330',\n",
       " '127_S_6168': 'ADNI3_127_S_6168',\n",
       " '018_S_6351': 'ADNI3_018_S_6351',\n",
       " '009_S_6212': 'ADNI3_009_S_6212',\n",
       " '168_S_6180': 'ADNI3_168_S_6180',\n",
       " '116_S_6119': 'ADNI3_116_S_6119',\n",
       " '023_S_6346': 'ADNI3_023_S_6346',\n",
       " '168_S_6065': 'ADNI3_168_S_6065',\n",
       " '035_S_6200': 'ADNI3_035_S_6200',\n",
       " '023_S_6399': 'ADNI3_023_S_6399',\n",
       " '037_S_6125': 'ADNI3_037_S_6125',\n",
       " '116_S_6428': 'ADNI3_116_S_6428',\n",
       " '041_S_6192': 'ADNI3_041_S_6192',\n",
       " '941_S_6333': 'ADNI3_941_S_6333',\n",
       " '006_S_6209': 'ADNI3_006_S_6209',\n",
       " '033_S_6497': 'ADNI3_033_S_6497',\n",
       " '127_S_6436': 'ADNI3_127_S_6436',\n",
       " '141_S_6178': 'ADNI3_141_S_6178',\n",
       " '002_S_6456': 'ADNI3_002_S_6456',\n",
       " '168_S_6062': 'ADNI3_168_S_6062',\n",
       " '033_S_6298': 'ADNI3_033_S_6298',\n",
       " '002_S_6053': 'ADNI3_002_S_6053',\n",
       " '135_S_6359': 'ADNI3_135_S_6359',\n",
       " '141_S_6015': 'ADNI3_141_S_6015',\n",
       " '027_S_6317': 'ADNI3_027_S_6317',\n",
       " '002_S_6009': 'ADNI3_002_S_6009',\n",
       " '098_S_6343': 'ADNI3_098_S_6343',\n",
       " '024_S_6033': 'ADNI3_024_S_6033',\n",
       " '941_S_6384': 'ADNI3_941_S_6384',\n",
       " '141_S_6008': 'ADNI3_141_S_6008',\n",
       " '023_S_6400': 'ADNI3_023_S_6400',\n",
       " '027_S_6034': 'ADNI3_027_S_6034',\n",
       " '002_S_6404': 'ADNI3_002_S_6404',\n",
       " '037_S_6031': 'ADNI3_037_S_6031',\n",
       " '941_S_6017': 'ADNI3_941_S_6017',\n",
       " '130_S_6329': 'ADNI3_130_S_6329',\n",
       " '941_S_6044': 'ADNI3_941_S_6044',\n",
       " '020_S_6470': 'ADNI3_020_S_6470',\n",
       " '941_S_6052': 'ADNI3_941_S_6052',\n",
       " '082_S_6197': 'ADNI3_082_S_6197',\n",
       " '130_S_6019': 'ADNI3_130_S_6019',\n",
       " '023_S_6356': 'ADNI3_023_S_6356',\n",
       " '002_S_6030': 'ADNI3_002_S_6030',\n",
       " '094_S_6419': 'ADNI3_094_S_6419',\n",
       " '130_S_6037': 'ADNI3_130_S_6037',\n",
       " '007_S_6310': 'ADNI3_007_S_6310',\n",
       " '941_S_6054': 'ADNI3_941_S_6054',\n",
       " '041_S_6354': 'ADNI3_041_S_6354',\n",
       " '141_S_6041': 'ADNI3_141_S_6041',\n",
       " '135_S_6360': 'ADNI3_135_S_6360',\n",
       " '067_S_6045': 'ADNI3_067_S_6045',\n",
       " '011_S_6367': 'ADNI3_011_S_6367',\n",
       " '099_S_6016': 'ADNI3_099_S_6016',\n",
       " '035_S_6306': 'ADNI3_035_S_6306',\n",
       " '024_S_6005': 'ADNI3_024_S_6005',\n",
       " '168_S_6318': 'ADNI3_168_S_6318',\n",
       " '130_S_6047': 'ADNI3_130_S_6047',\n",
       " '082_S_6287': 'ADNI3_082_S_6287',\n",
       " '941_S_6068': 'ADNI3_941_S_6068',\n",
       " '037_S_6222': 'ADNI3_037_S_6222',\n",
       " '022_S_6013': 'ADNI3_022_S_6013',\n",
       " '941_S_6422': 'ADNI3_941_S_6422',\n",
       " '114_S_6039': 'ADNI3_114_S_6039',\n",
       " '006_S_6375': 'ADNI3_006_S_6375',\n",
       " '002_S_6066': 'ADNI3_002_S_6066',\n",
       " '094_S_6250': 'ADNI3_094_S_6250',\n",
       " '305_S_6188': 'ADNI3_305_S_6188',\n",
       " '941_S_6471': 'ADNI3_941_S_6471',\n",
       " '003_S_6258': 'ADNI3_003_S_6258',\n",
       " '041_S_6159': 'ADNI3_041_S_6159',\n",
       " '100_S_6349': 'ADNI3_100_S_6349',\n",
       " '141_S_6240': 'ADNI3_141_S_6240',\n",
       " '131_S_6170': 'ADNI3_131_S_6170',\n",
       " '018_S_6207': 'ADNI3_018_S_6207',\n",
       " '003_S_6256': 'ADNI3_003_S_6256',\n",
       " '301_S_6224': 'ADNI3_301_S_6224',\n",
       " '023_S_6334': 'ADNI3_023_S_6334',\n",
       " '007_S_6255': 'ADNI3_007_S_6255',\n",
       " '003_S_6260': 'ADNI3_003_S_6260',\n",
       " '100_S_6164': 'ADNI3_100_S_6164',\n",
       " '070_S_6394': 'ADNI3_070_S_6394',\n",
       " '014_S_6145': 'ADNI3_014_S_6145',\n",
       " '099_S_6396': 'ADNI3_099_S_6396',\n",
       " '109_S_6213': 'ADNI3_109_S_6213',\n",
       " '129_S_6452': 'ADNI3_129_S_6452',\n",
       " '009_S_6163': 'ADNI3_009_S_6163',\n",
       " '116_S_6543': 'ADNI3_116_S_6543',\n",
       " '003_S_6158': 'ADNI3_003_S_6158',\n",
       " '130_S_6161': 'ADNI3_130_S_6161',\n",
       " '006_S_6252': 'ADNI3_006_S_6252',\n",
       " '135_S_6446': 'ADNI3_135_S_6446',\n",
       " '014_S_6199': 'ADNI3_014_S_6199',\n",
       " '130_S_6319': 'ADNI3_130_S_6319',\n",
       " '129_S_6244': 'ADNI3_129_S_6244',\n",
       " '032_S_6279': 'ADNI3_032_S_6279',\n",
       " '006_S_6243': 'ADNI3_006_S_6243',\n",
       " '301_S_6326': 'ADNI3_301_S_6326',\n",
       " '114_S_6113': 'ADNI3_114_S_6113',\n",
       " '007_S_6323': 'ADNI3_007_S_6323',\n",
       " '153_S_6274': 'ADNI3_153_S_6274',\n",
       " '094_S_6269': 'ADNI3_094_S_6269',\n",
       " '037_S_6141': 'ADNI3_037_S_6141',\n",
       " '037_S_6187': 'ADNI3_037_S_6187',\n",
       " '168_S_6049': 'ADNI3_168_S_6049',\n",
       " '177_S_6335': 'ADNI3_177_S_6335',\n",
       " '033_S_6266': 'ADNI3_033_S_6266',\n",
       " '129_S_6459': 'ADNI3_129_S_6459',\n",
       " '130_S_6372': 'ADNI3_130_S_6372',\n",
       " '141_S_6253': 'ADNI3_141_S_6253',\n",
       " '006_S_6500': 'ADNI3_006_S_6500',\n",
       " '130_S_6072': 'ADNI3_130_S_6072',\n",
       " '082_S_6283': 'ADNI3_082_S_6283',\n",
       " '141_S_6061': 'ADNI3_141_S_6061',\n",
       " '007_S_6341': 'ADNI3_007_S_6341',\n",
       " '007_S_6120': 'ADNI3_007_S_6120',\n",
       " '094_S_6275': 'ADNI3_094_S_6275',\n",
       " '941_S_6080': 'ADNI3_941_S_6080',\n",
       " '016_S_6381': 'ADNI3_016_S_6381',\n",
       " '941_S_6094': 'ADNI3_941_S_6094',\n",
       " '941_S_6345': 'ADNI3_941_S_6345',\n",
       " '003_S_6067': 'ADNI3_003_S_6067',\n",
       " '023_S_6374': 'ADNI3_023_S_6374',\n",
       " '012_S_6073': 'ADNI3_012_S_6073',\n",
       " '037_S_6216': 'ADNI3_037_S_6216',\n",
       " '135_S_6104': 'ADNI3_135_S_6104',\n",
       " '168_S_6320': 'ADNI3_168_S_6320',\n",
       " '067_S_6117': 'ADNI3_067_S_6117',\n",
       " '041_S_6401': 'ADNI3_041_S_6401',\n",
       " '014_S_6076': 'ADNI3_014_S_6076',\n",
       " '011_S_6418': 'ADNI3_011_S_6418',\n",
       " '036_S_6088': 'ADNI3_036_S_6088',\n",
       " '003_S_6432': 'ADNI3_003_S_6432',\n",
       " '037_S_6083': 'ADNI3_037_S_6083',\n",
       " '116_S_6550': 'ADNI3_116_S_6550',\n",
       " '130_S_6043': 'ADNI3_130_S_6043',\n",
       " '070_S_6386': 'ADNI3_070_S_6386',\n",
       " '127_S_6024': 'ADNI3_127_S_6024',\n",
       " '027_S_6370': 'ADNI3_027_S_6370',\n",
       " '023_S_6369': 'ADNI3_023_S_6369',\n",
       " '130_S_6035': 'ADNI3_130_S_6035',\n",
       " '168_S_6371': 'ADNI3_168_S_6371',\n",
       " '099_S_6038': 'ADNI3_099_S_6038',\n",
       " '168_S_6350': 'ADNI3_168_S_6350',\n",
       " '301_S_6056': 'ADNI3_301_S_6056',\n",
       " '099_S_6025': 'ADNI3_099_S_6025',\n",
       " '135_S_6389': 'ADNI3_135_S_6389',\n",
       " '130_S_6105': 'ADNI3_130_S_6105',\n",
       " '127_S_6241': 'ADNI3_127_S_6241',\n",
       " '022_S_6069': 'ADNI3_022_S_6069',\n",
       " '009_S_6402': 'ADNI3_009_S_6402',\n",
       " '941_S_6058': 'ADNI3_941_S_6058',\n",
       " '035_S_6488': 'ADNI3_035_S_6488',\n",
       " '141_S_6116': 'ADNI3_141_S_6116',\n",
       " '116_S_6439': 'ADNI3_116_S_6439',\n",
       " '116_S_6133': 'ADNI3_116_S_6133',\n",
       " '037_S_6204': 'ADNI3_037_S_6204',\n",
       " '114_S_6429': 'ADNI3_114_S_6429',\n",
       " '041_S_6292': 'ADNI3_041_S_6292',\n",
       " '013_S_6206': 'ADNI3_013_S_6206',\n",
       " '153_S_6336': 'ADNI3_153_S_6336',\n",
       " '014_S_6437': 'ADNI3_014_S_6437',\n",
       " '100_S_6273': 'ADNI3_100_S_6273',\n",
       " '027_S_6577': 'ADNI3_027_S_6577',\n",
       " '941_S_6575': 'ADNI3_941_S_6575',\n",
       " '036_S_6189': 'ADNI3_036_S_6189',\n",
       " '135_S_6545': 'ADNI3_135_S_6545',\n",
       " '036_S_6179': 'ADNI3_036_S_6179',\n",
       " '135_S_6473': 'ADNI3_135_S_6473',\n",
       " '029_S_6289': 'ADNI3_029_S_6289',\n",
       " '014_S_6522': 'ADNI3_014_S_6522',\n",
       " '019_S_6186': 'ADNI3_019_S_6186',\n",
       " '014_S_6502': 'ADNI3_014_S_6502',\n",
       " '070_S_6236': 'ADNI3_070_S_6236',\n",
       " '027_S_6582': 'ADNI3_027_S_6582',\n",
       " '168_S_6085': 'ADNI3_168_S_6085',\n",
       " '019_S_6573': 'ADNI3_019_S_6573',\n",
       " '003_S_6259': 'ADNI3_003_S_6259',\n",
       " '305_S_6498': 'ADNI3_305_S_6498',\n",
       " '003_S_6014': 'ADNI3_003_S_6014',\n",
       " '100_S_6578': 'ADNI3_100_S_6578',\n",
       " '021_S_6312': 'ADNI3_021_S_6312',\n",
       " '135_S_6544': 'ADNI3_135_S_6544',\n",
       " '014_S_6424': 'ADNI3_014_S_6424',\n",
       " '305_S_6313': 'ADNI3_305_S_6313',\n",
       " '127_S_6549': 'ADNI3_127_S_6549',\n",
       " '131_S_6143': 'ADNI3_131_S_6143',\n",
       " '127_S_6512': 'ADNI3_127_S_6512',\n",
       " '127_S_6232': 'ADNI3_127_S_6232',\n",
       " '033_S_6572': 'ADNI3_033_S_6572',\n",
       " '041_S_6226': 'ADNI3_041_S_6226',\n",
       " '003_S_6264': 'ADNI3_003_S_6264',\n",
       " '032_S_6211': 'ADNI3_032_S_6211',\n",
       " '023_S_6547': 'ADNI3_023_S_6547',\n",
       " '130_S_6111': 'ADNI3_130_S_6111',\n",
       " '141_S_6423': 'ADNI3_141_S_6423',\n",
       " '020_S_6282': 'ADNI3_020_S_6282',\n",
       " '067_S_6529': 'ADNI3_067_S_6529',\n",
       " '011_S_6303': 'ADNI3_011_S_6303',\n",
       " '020_S_6566': 'ADNI3_020_S_6566',\n",
       " '099_S_6175': 'ADNI3_099_S_6175',\n",
       " '037_S_6377': 'ADNI3_037_S_6377',\n",
       " '002_S_6007': 'ADNI3_002_S_6007',\n",
       " '003_S_6307': 'ADNI3_003_S_6307',\n",
       " '037_S_6046': 'ADNI3_037_S_6046',\n",
       " '003_S_6479': 'ADNI3_003_S_6479',\n",
       " '305_S_6157': 'ADNI3_305_S_6157',\n",
       " '007_S_6515': 'ADNI3_007_S_6515',\n",
       " '941_S_6581': 'ADNI3_941_S_6581',\n",
       " '127_S_6173': 'ADNI3_127_S_6173',\n",
       " '094_S_6417': 'ADNI3_094_S_6417',\n",
       " '024_S_6385': 'ADNI3_024_S_6385',\n",
       " '020_S_6227': 'ADNI3_020_S_6227',\n",
       " '168_S_6413': 'ADNI3_168_S_6413',\n",
       " '135_S_6284': 'ADNI3_135_S_6284',\n",
       " '024_S_6472': 'ADNI3_024_S_6472',\n",
       " '020_S_6185': 'ADNI3_020_S_6185',\n",
       " '123_S_6118': 'ADNI3_123_S_6118',\n",
       " '941_S_6514': 'ADNI3_941_S_6514',\n",
       " '019_S_6315': 'ADNI3_019_S_6315',\n",
       " '141_S_6075': 'ADNI3_141_S_6075',\n",
       " '012_S_6503': 'ADNI3_012_S_6503',\n",
       " '100_S_6308': 'ADNI3_100_S_6308',\n",
       " '135_S_6586': 'ADNI3_135_S_6586',\n",
       " '005_S_6084': 'ADNI3_005_S_6084',\n",
       " '027_S_6001': 'ADNI3_027_S_6001',\n",
       " '177_S_6448': 'ADNI3_177_S_6448',\n",
       " '053_S_6598': 'ADNI3_053_S_6598',\n",
       " '027_S_6002': 'ADNI3_027_S_6002',\n",
       " '168_S_6467': 'ADNI3_168_S_6467',\n",
       " '006_S_6234': 'ADNI3_006_S_6234',\n",
       " '003_S_6268': 'ADNI3_003_S_6268',\n",
       " '168_S_6426': 'ADNI3_168_S_6426',\n",
       " '067_S_6442': 'ADNI3_067_S_6442',\n",
       " '127_S_6348': 'ADNI3_127_S_6348',\n",
       " '020_S_6513': 'ADNI3_020_S_6513',\n",
       " '067_S_6138': 'ADNI3_067_S_6138',\n",
       " '135_S_6510': 'ADNI3_135_S_6510',\n",
       " '168_S_6151': 'ADNI3_168_S_6151',\n",
       " '011_S_6465': 'ADNI3_011_S_6465',\n",
       " '019_S_6483': 'ADNI3_019_S_6483',\n",
       " '941_S_6454': 'ADNI3_941_S_6454',\n",
       " '094_S_6485': 'ADNI3_094_S_6485',\n",
       " '168_S_6321': 'ADNI3_168_S_6321',\n",
       " '067_S_6474': 'ADNI3_067_S_6474',\n",
       " '007_S_6421': 'ADNI3_007_S_6421',\n",
       " '114_S_6347': 'ADNI3_114_S_6347',\n",
       " '141_S_6416': 'ADNI3_141_S_6416',\n",
       " '129_S_6457': 'ADNI3_129_S_6457',\n",
       " '027_S_6463': 'ADNI3_027_S_6463',\n",
       " '094_S_6468': 'ADNI3_094_S_6468',\n",
       " '177_S_6409': 'ADNI3_177_S_6409',\n",
       " '032_S_6294': 'ADNI3_032_S_6294',\n",
       " '341_S_6494': 'ADNI3_341_S_6494',\n",
       " '036_S_6316': 'ADNI3_036_S_6316',\n",
       " '035_S_6480': 'ADNI3_035_S_6480',\n",
       " '006_S_6441': 'ADNI3_006_S_6441',\n",
       " '127_S_6357': 'ADNI3_127_S_6357',\n",
       " '027_S_6516': 'ADNI3_027_S_6516',\n",
       " '941_S_6580': 'ADNI3_941_S_6580',\n",
       " '941_S_6546': 'ADNI3_941_S_6546',\n",
       " '127_S_6433': 'ADNI3_127_S_6433',\n",
       " '100_S_6493': 'ADNI3_100_S_6493',\n",
       " '019_S_6533': 'ADNI3_019_S_6533',\n",
       " '168_S_6233': 'ADNI3_168_S_6233',\n",
       " '126_S_6559': 'ADNI3_126_S_6559',\n",
       " '168_S_6492': 'ADNI3_168_S_6492',\n",
       " '131_S_6519': 'ADNI3_131_S_6519',\n",
       " '099_S_6476': 'ADNI3_099_S_6476',\n",
       " '020_S_6504': 'ADNI3_020_S_6504',\n",
       " '098_S_6534': 'ADNI3_098_S_6534',\n",
       " '041_S_6314': 'ADNI3_041_S_6314',\n",
       " '941_S_6499': 'ADNI3_941_S_6499',\n",
       " '023_S_6535': 'ADNI3_023_S_6535',\n",
       " '305_S_6378': 'ADNI3_305_S_6378',\n",
       " '082_S_6415': 'ADNI3_082_S_6415',\n",
       " '024_S_0985': '4_024_S_0985',\n",
       " '131_S_0123': '6_131_S_0123',\n",
       " '098_S_0160': '7_098_S_0160',\n",
       " '027_S_0256': '8_027_S_0256',\n",
       " '116_S_1243': '9_116_S_1243',\n",
       " '011_S_0002': '17_011_S_0002',\n",
       " '003_S_0907': '18_003_S_0907',\n",
       " '052_S_1346': '26_052_S_1346',\n",
       " '012_S_4026': '27_012_S_4026',\n",
       " '037_S_4030': '28_037_S_4030',\n",
       " '073_S_2182': '29_073_S_2182',\n",
       " '116_S_4167': '30_116_S_4167',\n",
       " '073_S_0089': '32_073_S_0089',\n",
       " '082_S_2099': '33_082_S_2099',\n",
       " '021_S_2100': '36_021_S_2100',\n",
       " '127_S_1427': '37_127_S_1427',\n",
       " '023_S_0926': '38_023_S_0926',\n",
       " '137_S_4672': '39_137_S_4672',\n",
       " '033_S_0920': '41_033_S_0920',\n",
       " '137_S_1414': '43_137_S_1414',\n",
       " '128_S_1408': '45_128_S_1408',\n",
       " '072_S_2027': '47_072_S_2027',\n",
       " '128_S_0545': '48_128_S_0545',\n",
       " '021_S_0626': '50_021_S_0626',\n",
       " '016_S_0702': '51_016_S_0702',\n",
       " '136_S_0695': '52_136_S_0695',\n",
       " '051_S_1072': '53_051_S_1072',\n",
       " '014_S_0558': '54_014_S_0558',\n",
       " '136_S_0873': '55_136_S_0873',\n",
       " '002_S_0729': '57_002_S_0729',\n",
       " '131_S_0384': '58_131_S_0384',\n",
       " '014_S_0563': '61_014_S_0563',\n",
       " '029_S_0845': '62_029_S_0845',\n",
       " '007_S_0068': '63_007_S_0068',\n",
       " '027_S_2219': '64_027_S_2219',\n",
       " '021_S_2142': '65_021_S_2142',\n",
       " '011_S_1080': '67_011_S_1080',\n",
       " '127_S_1032': '69_127_S_1032',\n",
       " '014_S_0169': '70_014_S_0169',\n",
       " '027_S_1045': '71_027_S_1045',\n",
       " '082_S_0832': '72_082_S_0832',\n",
       " '082_S_4208': '74_082_S_4208',\n",
       " '068_S_4174': '75_068_S_4174',\n",
       " '051_S_1331': '77_051_S_1331',\n",
       " '029_S_2376': '78_029_S_2376',\n",
       " '031_S_4149': '79_031_S_4149',\n",
       " '153_S_4151': '80_153_S_4151',\n",
       " '098_S_2052': '81_098_S_2052',\n",
       " '007_S_2058': '82_007_S_2058',\n",
       " '007_S_0128': '83_007_S_0128',\n",
       " '100_S_1226': '84_100_S_1226',\n",
       " '127_S_0259': '85_127_S_0259',\n",
       " '100_S_0296': '86_100_S_0296',\n",
       " '031_S_4029': '87_031_S_4029',\n",
       " '041_S_4051': '88_041_S_4051',\n",
       " '098_S_4059': '90_098_S_4059',\n",
       " '016_S_2031': '91_016_S_2031',\n",
       " '941_S_4036': '92_941_S_4036',\n",
       " '068_S_4134': '93_068_S_4134',\n",
       " '003_S_4119': '94_003_S_4119',\n",
       " '141_S_4160': '95_141_S_4160',\n",
       " '041_S_1418': '96_041_S_1418',\n",
       " '033_S_4176': '97_033_S_4176',\n",
       " '941_S_4100': '98_941_S_4100',\n",
       " '153_S_2148': '99_153_S_2148',\n",
       " '014_S_4058': '134_014_S_4058',\n",
       " '099_S_4076': '135_099_S_4076',\n",
       " '027_S_0644': '137_027_S_0644',\n",
       " '002_S_2043': '153_002_S_2043',\n",
       " '037_S_0303': '174_037_S_0303',\n",
       " '041_S_4138': '176_041_S_4138',\n",
       " '023_S_4448': '189_023_S_4448',\n",
       " '128_S_4571': '190_128_S_4571',\n",
       " '012_S_4545': '191_012_S_4545',\n",
       " '035_S_4414': '192_035_S_4414',\n",
       " '109_S_4499': '194_109_S_4499',\n",
       " '126_S_4514': '195_126_S_4514',\n",
       " '014_S_0548': '200_014_S_0548',\n",
       " '153_S_4159': '205_153_S_4159',\n",
       " '051_S_1123': '217_051_S_1123',\n",
       " '098_S_4095': '219_098_S_4095',\n",
       " '141_S_0915': '222_141_S_0915',\n",
       " '126_S_2407': '223_126_S_2407',\n",
       " '037_S_4410': '226_037_S_4410',\n",
       " '006_S_4357': '227_006_S_4357',\n",
       " '018_S_2155': '229_018_S_2155',\n",
       " '013_S_4268': '230_013_S_4268',\n",
       " '021_S_4402': '231_021_S_4402',\n",
       " '141_S_4438': '232_141_S_4438',\n",
       " '019_S_4477': '233_019_S_4477',\n",
       " '068_S_4424': '234_068_S_4424',\n",
       " '141_S_4456': '235_141_S_4456',\n",
       " '130_S_4417': '238_130_S_4417',\n",
       " '153_S_4372': '239_153_S_4372',\n",
       " '130_S_4294': '240_130_S_4294',\n",
       " '021_S_4335': '242_021_S_4335',\n",
       " '073_S_4360': '243_073_S_4360',\n",
       " '021_S_4421': '244_021_S_4421',\n",
       " '053_S_2396': '245_053_S_2396',\n",
       " '032_S_0479': '247_032_S_0479',\n",
       " '018_S_4313': '249_018_S_4313',\n",
       " '018_S_2133': '250_018_S_2133',\n",
       " '006_S_4449': '254_006_S_4449',\n",
       " '072_S_4465': '259_072_S_4465',\n",
       " '011_S_4547': '260_011_S_4547',\n",
       " '053_S_4578': '262_053_S_4578',\n",
       " '037_S_4381': '264_037_S_4381',\n",
       " '041_S_4513': '265_041_S_4513',\n",
       " '109_S_4455': '266_109_S_4455',\n",
       " '007_S_4611': '267_007_S_4611',\n",
       " '100_S_4469': '268_100_S_4469',\n",
       " '022_S_4291': '269_022_S_4291',\n",
       " '036_S_4562': '270_036_S_4562',\n",
       " '130_S_4605': '271_130_S_4605',\n",
       " '153_S_4621': '272_153_S_4621',\n",
       " '130_S_4641': '273_130_S_4641',\n",
       " '023_S_4502': '275_023_S_4502',\n",
       " '067_S_4072': '282_067_S_4072',\n",
       " '005_S_2390': '283_005_S_2390',\n",
       " '023_S_4034': '284_023_S_4034',\n",
       " '022_S_4196': '285_022_S_4196',\n",
       " '099_S_4157': '286_099_S_4157',\n",
       " '002_S_2073': '287_002_S_2073',\n",
       " '128_S_2036': '289_128_S_2036',\n",
       " '014_S_4263': '291_014_S_4263',\n",
       " '009_S_4564': '292_009_S_4564',\n",
       " '127_S_1419': '294_127_S_1419',\n",
       " '073_S_2191': '300_073_S_2191',\n",
       " '127_S_0260': '302_127_S_0260',\n",
       " '136_S_0186': '307_136_S_0186',\n",
       " '023_S_4164': '309_023_S_4164',\n",
       " '068_S_4340': '313_068_S_4340',\n",
       " '011_S_4278': '314_011_S_4278',\n",
       " '129_S_4396': '315_129_S_4396',\n",
       " '116_S_4338': '317_116_S_4338',\n",
       " '130_S_4343': '320_130_S_4343',\n",
       " '129_S_4371': '324_129_S_4371',\n",
       " '127_S_0112': '326_127_S_0112',\n",
       " '099_S_4104': '329_099_S_4104',\n",
       " '014_S_4039': '330_014_S_4039',\n",
       " '016_S_4121': '333_016_S_4121',\n",
       " '003_S_4350': '337_003_S_4350',\n",
       " '013_S_4580': '338_013_S_4580',\n",
       " '126_S_4494': '339_126_S_4494',\n",
       " '141_S_2210': '341_141_S_2210',\n",
       " '032_S_4429': '343_032_S_4429',\n",
       " '009_S_4530': '344_009_S_4530',\n",
       " '002_S_4473': '346_002_S_4473',\n",
       " '007_S_1206': '347_007_S_1206',\n",
       " '073_S_4540': '348_073_S_4540',\n",
       " '053_S_4557': '350_053_S_4557',\n",
       " '036_S_4491': '351_036_S_4491',\n",
       " '007_S_0101': '352_007_S_0101',\n",
       " '019_S_4548': '353_019_S_4548',\n",
       " '137_S_4482': '354_137_S_4482',\n",
       " '082_S_4428': '355_082_S_4428',\n",
       " '006_S_4363': '356_006_S_4363',\n",
       " '135_S_4446': '357_135_S_4446',\n",
       " '009_S_4359': '358_009_S_4359',\n",
       " '018_S_4597': '362_018_S_4597',\n",
       " '130_S_4589': '365_130_S_4589',\n",
       " '009_S_4612': '366_009_S_4612',\n",
       " '003_S_0981': '369_003_S_0981',\n",
       " '007_S_4568': '370_007_S_4568',\n",
       " '135_S_4598': '371_135_S_4598',\n",
       " '137_S_4520': '372_137_S_4520',\n",
       " '072_S_4539': '374_072_S_4539',\n",
       " '073_S_4552': '375_073_S_4552',\n",
       " '128_S_4603': '376_128_S_4603',\n",
       " '135_S_4566': '377_135_S_4566',\n",
       " '014_S_4615': '378_014_S_4615',\n",
       " '037_S_4146': '379_037_S_4146',\n",
       " '016_S_2007': '380_016_S_2007',\n",
       " '035_S_4582': '381_035_S_4582',\n",
       " '135_S_4489': '382_135_S_4489',\n",
       " '007_S_4467': '383_007_S_4467',\n",
       " '130_S_4405': '387_130_S_4405',\n",
       " '126_S_4507': '388_126_S_4507',\n",
       " '941_S_4365': '389_941_S_4365',\n",
       " '130_S_4468': '392_130_S_4468',\n",
       " '036_S_4430': '393_036_S_4430',\n",
       " '005_S_4707': '394_005_S_4707',\n",
       " '022_S_1097': '397_022_S_1097',\n",
       " '041_S_4037': '398_041_S_4037',\n",
       " '141_S_4053': '399_141_S_4053',\n",
       " '023_S_4122': '401_023_S_4122',\n",
       " '052_S_4626': '402_052_S_4626',\n",
       " '023_S_4501': '403_023_S_4501',\n",
       " '037_S_4071': '404_037_S_4071',\n",
       " '094_S_4234': '405_094_S_4234',\n",
       " '137_S_4331': '406_137_S_4331',\n",
       " '032_S_4386': '409_032_S_4386',\n",
       " '022_S_4266': '410_022_S_4266',\n",
       " '094_S_4434': '411_094_S_4434',\n",
       " '068_S_4431': '414_068_S_4431',\n",
       " '007_S_4516': '415_007_S_4516',\n",
       " '016_S_4584': '416_016_S_4584',\n",
       " '006_S_4546': '417_006_S_4546',\n",
       " '114_S_4379': '418_114_S_4379',\n",
       " '116_S_4625': '420_116_S_4625',\n",
       " '022_S_4444': '421_022_S_4444',\n",
       " '041_S_4510': '422_041_S_4510',\n",
       " '099_S_4475': '423_099_S_4475',\n",
       " '037_S_4308': '424_037_S_4308',\n",
       " '029_S_4385': '425_029_S_4385',\n",
       " '072_S_4462': '426_072_S_4462',\n",
       " '007_S_4488': '427_007_S_4488',\n",
       " '002_S_4654': '428_002_S_4654',\n",
       " '037_S_4432': '429_037_S_4432',\n",
       " '073_S_4614': '430_073_S_4614',\n",
       " '073_S_4559': '431_073_S_4559',\n",
       " '136_S_4408': '432_136_S_4408',\n",
       " '014_S_4668': '434_014_S_4668',\n",
       " '013_S_4595': '435_013_S_4595',\n",
       " '041_S_4629': '436_041_S_4629',\n",
       " '128_S_4653': '437_128_S_4653',\n",
       " '020_S_1288': '440_020_S_1288',\n",
       " '116_S_0752': '442_116_S_0752',\n",
       " '012_S_4188': '444_012_S_4188',\n",
       " '021_S_4254': '445_021_S_4254',\n",
       " '137_S_4299': '446_137_S_4299',\n",
       " '031_S_4590': '447_031_S_4590',\n",
       " '006_S_0498': '449_006_S_0498',\n",
       " '072_S_2083': '451_072_S_2083',\n",
       " '068_S_2184': '453_068_S_2184',\n",
       " '094_S_2238': '455_094_S_2238',\n",
       " '127_S_2234': '457_127_S_2234',\n",
       " '031_S_2233': '458_031_S_2233',\n",
       " '022_S_2263': '459_022_S_2263',\n",
       " '022_S_0130': '461_022_S_0130',\n",
       " '098_S_4018': '462_098_S_4018',\n",
       " '072_S_4007': '463_072_S_4007',\n",
       " '037_S_4015': '464_037_S_4015',\n",
       " '037_S_4001': '465_037_S_4001',\n",
       " '130_S_2373': '466_130_S_2373',\n",
       " '002_S_4251': '468_002_S_4251',\n",
       " '023_S_2068': '469_023_S_2068',\n",
       " '072_S_4206': '470_072_S_4206',\n",
       " '099_S_4202': '472_099_S_4202',\n",
       " '129_S_4422': '474_129_S_4422',\n",
       " '029_S_4327': '476_029_S_4327',\n",
       " '082_S_1256': '477_082_S_1256',\n",
       " '099_S_4498': '478_099_S_4498',\n",
       " '006_S_4153': '479_006_S_4153',\n",
       " '098_S_2079': '480_098_S_2079',\n",
       " '137_S_0800': '481_137_S_0800',\n",
       " '098_S_2047': '483_098_S_2047',\n",
       " '941_S_4187': '484_941_S_4187',\n",
       " '002_S_4225': '485_002_S_4225',\n",
       " '002_S_4237': '487_002_S_4237',\n",
       " '070_S_4692': '488_070_S_4692',\n",
       " '018_S_4349': '489_018_S_4349',\n",
       " '137_S_4303': '490_137_S_4303',\n",
       " '035_S_2061': '491_035_S_2061',\n",
       " '041_S_4271': '492_041_S_4271',\n",
       " '135_S_4309': '493_135_S_4309',\n",
       " '009_S_4388': '495_009_S_4388',\n",
       " '024_S_4392': '498_024_S_4392',\n",
       " '035_S_4256': '499_035_S_4256',\n",
       " '098_S_0896': '500_098_S_0896',\n",
       " '016_S_4353': '501_016_S_4353',\n",
       " '130_S_4250': '503_130_S_4250',\n",
       " '130_S_4542': '504_130_S_4542',\n",
       " '003_S_0908': '505_003_S_0908',\n",
       " '127_S_2213': '508_127_S_2213',\n",
       " '018_S_2138': '509_018_S_2138',\n",
       " '027_S_0120': '510_027_S_0120',\n",
       " '128_S_2151': '511_128_S_2151',\n",
       " '032_S_2247': '512_032_S_2247',\n",
       " '027_S_1387': '513_027_S_1387',\n",
       " '098_S_0172': '514_098_S_0172',\n",
       " '014_S_2308': '515_014_S_2308',\n",
       " '023_S_1190': '516_023_S_1190',\n",
       " '005_S_0448': '517_005_S_0448',\n",
       " '068_S_2316': '518_068_S_2316',\n",
       " '007_S_4272': '520_007_S_4272',\n",
       " '098_S_4275': '521_098_S_4275',\n",
       " '068_S_4332': '522_068_S_4332',\n",
       " '018_S_4400': '523_018_S_4400',\n",
       " '072_S_4383': '524_072_S_4383',\n",
       " '153_S_4297': '525_153_S_4297',\n",
       " '006_S_4515': '526_006_S_4515',\n",
       " '023_S_4241': '528_023_S_4241',\n",
       " '016_S_4591': '529_016_S_4591',\n",
       " '128_S_4553': '530_128_S_4553',\n",
       " '009_S_4543': '531_009_S_4543',\n",
       " '127_S_4604': '532_127_S_4604',\n",
       " '127_S_4500': '533_127_S_4500',\n",
       " '941_S_4420': '534_941_S_4420',\n",
       " '099_S_4480': '535_099_S_4480',\n",
       " '094_S_4503': '536_094_S_4503',\n",
       " '098_S_4506': '537_098_S_4506',\n",
       " '072_S_4522': '538_072_S_4522',\n",
       " '128_S_4599': '539_128_S_4599',\n",
       " '116_S_4043': '541_116_S_4043',\n",
       " '073_S_0311': '542_073_S_0311',\n",
       " '019_S_4285': '543_019_S_4285',\n",
       " '032_S_4348': '544_032_S_4348',\n",
       " '021_S_4659': '545_021_S_4659',\n",
       " '027_S_2183': '546_027_S_2183',\n",
       " '014_S_2185': '547_014_S_2185',\n",
       " '022_S_1351': '548_022_S_1351',\n",
       " '068_S_0127': '549_068_S_0127',\n",
       " '068_S_0872': '550_068_S_0872',\n",
       " '014_S_4401': '551_014_S_4401',\n",
       " '006_S_4346': '552_006_S_4346',\n",
       " '114_S_0378': '553_114_S_0378',\n",
       " '141_S_4426': '554_141_S_4426',\n",
       " '099_S_4463': '555_099_S_4463',\n",
       " '073_S_4443': '556_073_S_4443',\n",
       " '127_S_4240': '557_127_S_4240',\n",
       " '094_S_4560': '558_094_S_4560',\n",
       " '007_S_4620': '559_007_S_4620',\n",
       " '019_S_4549': '560_019_S_4549',\n",
       " '067_S_4310': '561_067_S_4310',\n",
       " '141_S_4232': '562_141_S_4232',\n",
       " '006_S_1130': '564_006_S_1130',\n",
       " '057_S_2398': '565_057_S_2398',\n",
       " '136_S_4269': '568_136_S_4269',\n",
       " '126_S_4458': '569_126_S_4458',\n",
       " '072_S_4445': '570_072_S_4445',\n",
       " '116_S_4453': '571_116_S_4453',\n",
       " '114_S_4404': '572_114_S_4404',\n",
       " '072_S_4394': '573_072_S_4394',\n",
       " '031_S_4474': '574_031_S_4474',\n",
       " '072_S_4613': '575_072_S_4613',\n",
       " '116_S_4635': '576_116_S_4635',\n",
       " '127_S_4645': '577_127_S_4645',\n",
       " '136_S_4433': '579_136_S_4433',\n",
       " '128_S_4609': '581_128_S_4609',\n",
       " '137_S_4596': '582_137_S_4596',\n",
       " '141_S_2333': '583_141_S_2333',\n",
       " '007_S_4637': '585_007_S_4637',\n",
       " '032_S_1169': '588_032_S_1169',\n",
       " '099_S_1034': '589_099_S_1034',\n",
       " '116_S_4092': '591_116_S_4092',\n",
       " '136_S_0107': '592_136_S_0107',\n",
       " '002_S_4270': '594_002_S_4270',\n",
       " '035_S_2074': '595_035_S_2074',\n",
       " '127_S_4301': '596_127_S_4301',\n",
       " '099_S_4205': '597_099_S_4205',\n",
       " '082_S_4339': '598_082_S_4339',\n",
       " '032_S_2119': '599_032_S_2119',\n",
       " '009_S_4337': '603_009_S_4337',\n",
       " '012_S_1212': '604_012_S_1212',\n",
       " '027_S_2336': '605_027_S_2336',\n",
       " '068_S_2315': '606_068_S_2315',\n",
       " '022_S_1394': '607_022_S_1394',\n",
       " '057_S_1007': '609_057_S_1007',\n",
       " '082_S_4224': '610_082_S_4224',\n",
       " '135_S_4281': '612_135_S_4281',\n",
       " '130_S_4415': '613_130_S_4415',\n",
       " '137_S_4536': '615_137_S_4536',\n",
       " '135_S_4657': '616_135_S_4657',\n",
       " '023_S_0376': '617_023_S_0376',\n",
       " '012_S_4643': '618_012_S_4643',\n",
       " '099_S_4565': '619_099_S_4565',\n",
       " '018_S_0055': '623_018_S_0055',\n",
       " '023_S_0625': '624_023_S_0625',\n",
       " '021_S_2125': '626_021_S_2125',\n",
       " '007_S_2106': '627_007_S_2106',\n",
       " '022_S_2087': '630_022_S_2087',\n",
       " '036_S_0869': '631_036_S_0869',\n",
       " '033_S_1016': '634_033_S_1016',\n",
       " '005_S_0546': '635_005_S_0546',\n",
       " '033_S_1098': '636_033_S_1098',\n",
       " '033_S_0922': '637_033_S_0922',\n",
       " '072_S_2093': '641_072_S_2093',\n",
       " '072_S_2037': '642_072_S_2037',\n",
       " '033_S_0906': '643_033_S_0906',\n",
       " '094_S_1417': '644_094_S_1417',\n",
       " '005_S_0610': '646_005_S_0610',\n",
       " '127_S_0925': '647_127_S_0925',\n",
       " '137_S_0972': '648_137_S_0972',\n",
       " '036_S_0672': '649_036_S_0672',\n",
       " '128_S_2011': '650_128_S_2011',\n",
       " '033_S_1116': '651_033_S_1116',\n",
       " '005_S_0602': '652_005_S_0602',\n",
       " '052_S_2249': '653_052_S_2249',\n",
       " '035_S_2199': '654_035_S_2199',\n",
       " '021_S_2150': '655_021_S_2150',\n",
       " '072_S_0315': '656_072_S_0315',\n",
       " '082_S_2307': '657_082_S_2307',\n",
       " '002_S_1261': '658_002_S_1261',\n",
       " '123_S_1300': '659_123_S_1300',\n",
       " '037_S_4028': '660_037_S_4028',\n",
       " '072_S_4063': '661_072_S_4063',\n",
       " '036_S_1023': '662_036_S_1023',\n",
       " '011_S_4075': '663_011_S_4075',\n",
       " '027_S_0074': '665_027_S_0074',\n",
       " '128_S_2002': '666_128_S_2002',\n",
       " '072_S_2026': '667_072_S_2026',\n",
       " '016_S_0359': '670_016_S_0359',\n",
       " '031_S_0351': '671_031_S_0351',\n",
       " '127_S_0622': '672_127_S_0622',\n",
       " '014_S_0520': '673_014_S_0520',\n",
       " '135_S_4676': '674_135_S_4676',\n",
       " '014_S_0658': '675_014_S_0658',\n",
       " '012_S_1133': '676_012_S_1133',\n",
       " '128_S_2003': '678_128_S_2003',\n",
       " '003_S_1074': '679_003_S_1074',\n",
       " '016_S_1117': '680_016_S_1117',\n",
       " '099_S_2146': '682_099_S_2146',\n",
       " '037_S_0501': '683_037_S_0501',\n",
       " '031_S_2022': '684_031_S_2022',\n",
       " '073_S_2190': '687_073_S_2190',\n",
       " '068_S_2168': '689_068_S_2168',\n",
       " '037_S_0377': '691_037_S_0377',\n",
       " '067_S_2195': '692_067_S_2195',\n",
       " '057_S_1269': '695_057_S_1269',\n",
       " '129_S_1246': '696_129_S_1246',\n",
       " '031_S_4005': '697_031_S_4005',\n",
       " '067_S_2304': '698_067_S_2304',\n",
       " '129_S_2332': '699_129_S_2332',\n",
       " '022_S_4173': '700_022_S_4173',\n",
       " '006_S_4150': '701_006_S_4150',\n",
       " '002_S_0685': '702_002_S_0685',\n",
       " '031_S_0618': '703_031_S_0618',\n",
       " '031_S_4203': '704_031_S_4203',\n",
       " '003_S_4152': '709_003_S_4152',\n",
       " '002_S_4171': '710_002_S_4171',\n",
       " '009_S_4324': '711_009_S_4324',\n",
       " '128_S_2045': '713_128_S_2045',\n",
       " '009_S_0842': '714_009_S_0842',\n",
       " '128_S_2220': '715_128_S_2220',\n",
       " '068_S_2248': '716_068_S_2248',\n",
       " '022_S_2167': '717_022_S_2167',\n",
       " '094_S_4162': '718_094_S_4162',\n",
       " '023_S_4035': '719_023_S_4035',\n",
       " '031_S_0830': '721_031_S_0830',\n",
       " '031_S_4218': '723_031_S_4218',\n",
       " '127_S_4148': '725_127_S_4148',\n",
       " '072_S_4103': '726_072_S_4103',\n",
       " '033_S_0741': '727_033_S_0741',\n",
       " '037_S_0566': '728_037_S_0566',\n",
       " '024_S_4280': '729_024_S_4280',\n",
       " '082_S_2121': '730_082_S_2121',\n",
       " '013_S_1186': '731_013_S_1186',\n",
       " '011_S_1282': '732_011_S_1282',\n",
       " '036_S_0945': '734_036_S_0945',\n",
       " '100_S_0069': '735_100_S_0069',\n",
       " '123_S_0298': '736_123_S_0298',\n",
       " '032_S_0214': '737_032_S_0214',\n",
       " '041_S_4060': '738_041_S_4060',\n",
       " '126_S_4686': '739_126_S_4686',\n",
       " '137_S_0459': '740_137_S_0459',\n",
       " '041_S_0679': '741_041_S_0679',\n",
       " '072_S_4057': '742_072_S_4057',\n",
       " '116_S_4195': '743_116_S_4195',\n",
       " '019_S_4252': '744_019_S_4252',\n",
       " '073_S_4155': '745_073_S_4155',\n",
       " '002_S_4262': '746_002_S_4262',\n",
       " '041_S_1260': '747_041_S_1260',\n",
       " '053_S_2357': '748_053_S_2357',\n",
       " '123_S_2363': '749_123_S_2363',\n",
       " '099_S_0352': '750_099_S_0352',\n",
       " '009_S_2381': '751_009_S_2381',\n",
       " '098_S_4003': '752_098_S_4003',\n",
       " '016_S_1326': '753_016_S_1326',\n",
       " '126_S_2360': '755_126_S_2360',\n",
       " '018_S_4696': '756_018_S_4696',\n",
       " '130_S_0289': '757_130_S_0289',\n",
       " '051_S_1040': '758_051_S_1040',\n",
       " '031_S_4042': '759_031_S_4042',\n",
       " '007_S_2394': '760_007_S_2394',\n",
       " '137_S_0722': '761_137_S_0722',\n",
       " '116_S_0657': '762_116_S_0657',\n",
       " '100_S_0047': '763_100_S_0047',\n",
       " '018_S_2180': '764_018_S_2180',\n",
       " '137_S_0973': '765_137_S_0973',\n",
       " '098_S_0171': '766_098_S_0171',\n",
       " '131_S_0441': '767_131_S_0441',\n",
       " '129_S_4073': '768_129_S_4073',\n",
       " '068_S_0802': '769_068_S_0802',\n",
       " '023_S_4115': '770_023_S_4115',\n",
       " '037_S_0588': '771_037_S_0588',\n",
       " '037_S_0150': '772_037_S_0150',\n",
       " '051_S_1131': '773_051_S_1131',\n",
       " '011_S_4366': '774_011_S_4366',\n",
       " '072_S_2116': '775_072_S_2116',\n",
       " '035_S_0555': '776_035_S_0555',\n",
       " '126_S_0605': '777_126_S_0605',\n",
       " '068_S_4061': '778_068_S_4061',\n",
       " '033_S_4179': '780_033_S_4179',\n",
       " '024_S_4158': '781_024_S_4158',\n",
       " '029_S_2395': '782_029_S_2395',\n",
       " '153_S_4172': '783_153_S_4172',\n",
       " '005_S_4185': '784_005_S_4185',\n",
       " '067_S_4212': '785_067_S_4212',\n",
       " '006_S_4192': '787_006_S_4192',\n",
       " '041_S_4200': '788_041_S_4200',\n",
       " '128_S_0272': '789_128_S_0272',\n",
       " '100_S_1286': '790_100_S_1286',\n",
       " '041_S_4014': '791_041_S_4014',\n",
       " '031_S_4024': '792_031_S_4024',\n",
       " '052_S_0671': '793_052_S_0671',\n",
       " '073_S_4216': '794_073_S_4216',\n",
       " '082_S_4090': '795_082_S_4090',\n",
       " '114_S_2392': '797_114_S_2392',\n",
       " '041_S_4041': '798_041_S_4041',\n",
       " '037_S_4214': '799_037_S_4214',\n",
       " '035_S_4114': '800_035_S_4114',\n",
       " '123_S_4096': '801_123_S_4096',\n",
       " '005_S_4168': '802_005_S_4168',\n",
       " '072_S_4131': '803_072_S_4131',\n",
       " '032_S_2240': '804_032_S_2240',\n",
       " '002_S_1268': '806_002_S_1268',\n",
       " '021_S_0276': '807_021_S_0276',\n",
       " '098_S_4050': '808_098_S_4050',\n",
       " '123_S_4127': '809_123_S_4127',\n",
       " '123_S_4170': '810_123_S_4170',\n",
       " '099_S_0051': '811_099_S_0051',\n",
       " '099_S_2042': '813_099_S_2042',\n",
       " '073_S_4259': '814_073_S_4259',\n",
       " '037_S_4302': '815_037_S_4302',\n",
       " '082_S_4244': '817_082_S_4244',\n",
       " '135_S_4356': '818_135_S_4356',\n",
       " '018_S_0682': '101_018_S_0682',\n",
       " '021_S_0424': '103_021_S_0424',\n",
       " '006_S_0484': '106_006_S_0484',\n",
       " '133_S_0629': '107_133_S_0629',\n",
       " '128_S_1409': '108_128_S_1409',\n",
       " '099_S_0040': '109_099_S_0040',\n",
       " '005_S_1224': '10_005_S_1224',\n",
       " '068_S_0442': '110_068_S_0442',\n",
       " '073_S_0565': '114_073_S_0565',\n",
       " '131_S_0497': '115_131_S_0497',\n",
       " '033_S_0723': '116_033_S_0723',\n",
       " '130_S_0449': '117_130_S_0449',\n",
       " '033_S_0516': '118_033_S_0516',\n",
       " '137_S_0438': '121_137_S_0438',\n",
       " '018_S_0450': '123_018_S_0450',\n",
       " '041_S_0721': '124_041_S_0721',\n",
       " '012_S_1009': '126_012_S_1009',\n",
       " '022_S_0044': '128_022_S_0044',\n",
       " '010_S_0472': '12_010_S_0472',\n",
       " '941_S_1311': '130_941_S_1311',\n",
       " '136_S_0874': '131_136_S_0874',\n",
       " '053_S_0621': '132_053_S_0621',\n",
       " '029_S_1215': '134_029_S_1215',\n",
       " '067_S_1185': '135_067_S_1185',\n",
       " '067_S_0038': '136_067_S_0038',\n",
       " '067_S_0019': '138_067_S_0019',\n",
       " '007_S_0316': '141_007_S_0316',\n",
       " '141_S_1152': '142_141_S_1152',\n",
       " '141_S_0853': '143_141_S_0853',\n",
       " '126_S_0784': '145_126_S_0784',\n",
       " '100_S_0006': '146_100_S_0006',\n",
       " '013_S_0575': '147_013_S_0575',\n",
       " '137_S_0481': '153_137_S_0481',\n",
       " '128_S_0216': '154_128_S_0216',\n",
       " '128_S_0310': '156_128_S_0310',\n",
       " '100_S_0190': '157_100_S_0190',\n",
       " '130_S_0783': '158_130_S_0783',\n",
       " '098_S_0884': '159_098_S_0884',\n",
       " '099_S_0470': '15_099_S_0470',\n",
       " '041_S_1002': '162_041_S_1002',\n",
       " '027_S_0417': '163_027_S_0417',\n",
       " '023_S_1289': '165_023_S_1289',\n",
       " '033_S_1279': '167_033_S_1279',\n",
       " '067_S_0110': '169_067_S_0110',\n",
       " '128_S_0245': '16_128_S_0245',\n",
       " '073_S_0445': '170_073_S_0445',\n",
       " '072_S_1211': '172_072_S_1211',\n",
       " '022_S_0544': '173_022_S_0544',\n",
       " '035_S_0204': '176_035_S_0204',\n",
       " '941_S_1194': '178_941_S_1194',\n",
       " '007_S_0041': '179_007_S_0041',\n",
       " '137_S_0825': '17_137_S_0825',\n",
       " '011_S_0168': '180_011_S_0168',\n",
       " '006_S_0675': '181_006_S_0675',\n",
       " '016_S_1263': '182_016_S_1263',\n",
       " '041_S_1423': '183_041_S_1423',\n",
       " '027_S_0461': '184_027_S_0461',\n",
       " '052_S_1168': '185_052_S_1168',\n",
       " '126_S_0506': '187_126_S_0506',\n",
       " '023_S_0963': '189_023_S_0963',\n",
       " '128_S_0266': '18_128_S_0266',\n",
       " '067_S_0177': '190_067_S_0177',\n",
       " '029_S_1073': '191_029_S_1073',\n",
       " '067_S_0290': '192_067_S_0290',\n",
       " '033_S_1308': '194_033_S_1308',\n",
       " '037_S_0454': '196_037_S_0454',\n",
       " '126_S_1221': '198_126_S_1221',\n",
       " '012_S_0634': '199_012_S_0634',\n",
       " '067_S_0243': '19_067_S_0243',\n",
       " '068_S_1191': '203_068_S_1191',\n",
       " '136_S_0184': '204_136_S_0184',\n",
       " '141_S_1024': '205_141_S_1024',\n",
       " '136_S_0194': '206_136_S_0194',\n",
       " '013_S_1120': '208_013_S_1120',\n",
       " '137_S_0443': '209_137_S_0443',\n",
       " '036_S_0673': '210_036_S_0673',\n",
       " '053_S_0507': '211_053_S_0507',\n",
       " '023_S_1126': '212_023_S_1126',\n",
       " '116_S_0392': '215_116_S_0392',\n",
       " '082_S_1119': '216_082_S_1119',\n",
       " '029_S_1184': '217_029_S_1184',\n",
       " '130_S_0969': '218_130_S_0969',\n",
       " '016_S_1138': '21_016_S_1138',\n",
       " '062_S_0730': '221_062_S_0730',\n",
       " '098_S_0288': '222_098_S_0288',\n",
       " '133_S_0638': '223_133_S_0638',\n",
       " '027_S_0179': '224_027_S_0179',\n",
       " '123_S_0050': '227_123_S_0050',\n",
       " '130_S_0285': '228_130_S_0285',\n",
       " '099_S_0534': '229_099_S_0534',\n",
       " '002_S_0782': '230_002_S_0782',\n",
       " '067_S_0029': '231_067_S_0029',\n",
       " '007_S_1339': '232_007_S_1339',\n",
       " '006_S_0653': '234_006_S_0653',\n",
       " '023_S_0139': '238_023_S_0139',\n",
       " '029_S_1384': '239_029_S_1384',\n",
       " '027_S_1082': '240_027_S_1082',\n",
       " '128_S_0500': '241_128_S_0500',\n",
       " '057_S_0957': '244_057_S_0957',\n",
       " '082_S_0304': '246_082_S_0304',\n",
       " '141_S_0810': '248_141_S_0810',\n",
       " '041_S_1391': '249_041_S_1391',\n",
       " '007_S_0070': '24_007_S_0070',\n",
       " '016_S_0590': '250_016_S_0590',\n",
       " '007_S_0414': '251_007_S_0414',\n",
       " '007_S_0249': '253_007_S_0249',\n",
       " '031_S_0321': '255_031_S_0321',\n",
       " '082_S_0363': '256_082_S_0363',\n",
       " '062_S_0690': '257_062_S_0690',\n",
       " '007_S_1248': '258_007_S_1248',\n",
       " '011_S_0861': '259_011_S_0861',\n",
       " '133_S_1170': '25_133_S_1170',\n",
       " '052_S_1251': '262_052_S_1251',\n",
       " '072_S_1380': '263_072_S_1380',\n",
       " '141_S_0726': '265_141_S_0726',\n",
       " '130_S_0102': '267_130_S_0102',\n",
       " '141_S_1004': '268_141_S_1004',\n",
       " '130_S_0423': '269_130_S_0423',\n",
       " '128_S_0522': '26_128_S_0522',\n",
       " '082_S_1079': '271_082_S_1079',\n",
       " '141_S_1231': '272_141_S_1231',\n",
       " '062_S_0768': '273_062_S_0768',\n",
       " '136_S_0195': '274_136_S_0195',\n",
       " '018_S_0087': '275_018_S_0087',\n",
       " '018_S_0335': '277_018_S_0335',\n",
       " '016_S_0769': '279_016_S_0769',\n",
       " '141_S_1245': '27_141_S_1245',\n",
       " '141_S_1051': '281_141_S_1051',\n",
       " '022_S_0066': '282_022_S_0066',\n",
       " '062_S_1294': '285_062_S_1294',\n",
       " '100_S_0747': '286_100_S_0747',\n",
       " '136_S_0429': '287_136_S_0429',\n",
       " '023_S_0126': '289_023_S_0126',\n",
       " '941_S_1363': '290_941_S_1363',\n",
       " '031_S_1209': '291_031_S_1209',\n",
       " '037_S_0627': '292_037_S_0627',\n",
       " '036_S_0976': '294_036_S_0976',\n",
       " '029_S_0914': '296_029_S_0914',\n",
       " '073_S_0312': '297_073_S_0312',\n",
       " '021_S_0178': '298_021_S_0178',\n",
       " '021_S_0647': '299_021_S_0647',\n",
       " '007_S_1304': '29_007_S_1304',\n",
       " '005_S_1341': '2_005_S_1341',\n",
       " '021_S_0332': '300_021_S_0332',\n",
       " '027_S_0850': '301_027_S_0850',\n",
       " '131_S_0319': '302_131_S_0319',\n",
       " '032_S_1101': '303_032_S_1101',\n",
       " '002_S_0559': '304_002_S_0559',\n",
       " '032_S_0677': '305_032_S_0677',\n",
       " '041_S_1411': '309_041_S_1411',\n",
       " '137_S_0841': '310_137_S_0841',\n",
       " '013_S_1276': '311_013_S_1276',\n",
       " '029_S_0999': '312_029_S_0999',\n",
       " '022_S_0543': '313_022_S_0543',\n",
       " '082_S_0469': '314_082_S_0469',\n",
       " '012_S_1292': '315_012_S_1292',\n",
       " '082_S_1377': '316_082_S_1377',\n",
       " '002_S_0413': '319_002_S_0413',\n",
       " '006_S_0547': '31_006_S_0547',\n",
       " '032_S_0718': '320_032_S_0718',\n",
       " '141_S_1244': '321_141_S_1244',\n",
       " '126_S_0891': '323_126_S_0891',\n",
       " '013_S_1205': '324_013_S_1205',\n",
       " '005_S_0222': '325_005_S_0222',\n",
       " '009_S_0751': '32_009_S_0751',\n",
       " '099_S_0551': '330_099_S_0551',\n",
       " '002_S_0295': '333_002_S_0295',\n",
       " '100_S_1154': '334_100_S_1154',\n",
       " '128_S_0188': '336_128_S_0188',\n",
       " '027_S_1213': '337_027_S_1213',\n",
       " '029_S_1318': '339_029_S_1318',\n",
       " '123_S_0390': '33_123_S_0390',\n",
       " '037_S_0327': '341_037_S_0327',\n",
       " '033_S_1284': '342_033_S_1284',\n",
       " '068_S_0476': '343_068_S_0476',\n",
       " '029_S_1056': '344_029_S_1056',\n",
       " '067_S_0045': '345_067_S_0045',\n",
       " '023_S_0078': '348_023_S_0078',\n",
       " '100_S_0015': '349_100_S_0015',\n",
       " '012_S_0689': '350_012_S_0689',\n",
       " '114_S_0979': '352_114_S_0979',\n",
       " '128_S_1406': '353_128_S_1406',\n",
       " '137_S_1041': '354_137_S_1041',\n",
       " ...}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "GWAS_ID = 'ukb-b-13806'\n",
    "usable_samples_ADNI_unsplitted = pd.read_csv(f'./PRSice_output/{GWAS_ID}/{GWAS_ID}.best', ' ')['IID'].to_numpy().tolist()\n",
    "usable_samples_ADNI = {'_'.join(sample.split('_')[1:]):sample for sample in (usable_samples_ADNI_unsplitted)}\n",
    "# above line may need to be commented out\n",
    "# json.dump(usable_samples_ADNI, open('./usable_samples_ADNI.json', 'w'))\n",
    "# print(type(usable_samples_ADNI), len(usable_samples_ADNI))\n",
    "usable_samples_ADNI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'25_7_22_thyroid traits.zip'   ukb-a-257     ukb-b-17006   ukb-b-5779\r\n",
      " bbj-a-46\t\t       ukb-b-11495   ukb-b-17243   ukb-b-6134\r\n",
      " bbj-a-78\t\t       ukb-b-12064   ukb-b-17627   ukb-b-6324\r\n",
      " ieu-b-109\t\t       ukb-b-12417   ukb-b-18275   ukb-b-6358\r\n",
      " ieu-b-110\t\t       ukb-b-12493   ukb-b-19732   ukb-b-7663\r\n",
      " ieu-b-111\t\t       ukb-b-12963   ukb-b-19953   ukb-b-770\r\n",
      " ieu-b-25\t\t       ukb-b-13806   ukb-b-20289   ukb-b-8476\r\n",
      " ieu-b-38\t\t       ukb-b-14057   ukb-b-2209    ukb-d-20405_0\r\n",
      " ieu-b-39\t\t       ukb-b-14180   ukb-b-323\t   ukb-d-20405_1\r\n",
      " lib\t\t\t       ukb-b-14699   ukb-b-3957    ukb-d-20405_2\r\n",
      " met-d-Total_C\t\t       ukb-b-15541   ukb-b-4424\r\n"
     ]
    }
   ],
   "source": [
    "!ls PRSice_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1816, 39) 1816\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "# PRS_feature_matrix = np.load('./PRS_feature_matrix.npy')\n",
    "PRS_feature_matrix = np.load(inputFolder+'PRS_feature_matrix.npy')\n",
    "# usable_samples_ADNI = json.load(open('./usable_samples_ADNI.json'))\n",
    "print(PRS_feature_matrix.shape, usable_samples_ADNI.__len__())\n",
    "\n",
    "# usable_samples_ADNI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prsice result used in our model\n",
    "usable_samples_adni-> from .best of prsice corresponding to larger dataset we get the IIDs ( ie the individuals that we considered for our studies )\n",
    "now , larger data set is actually a part of ADNIMERGE dataset . So, here we have all the considered patients, but some of the data that are in ADNIMERGE are not present in larger dataset. That leads to the check of \"sample in usable_samples_adni\". \n",
    "The reason behind this is related to the generation of \"larger dataset\" generation from \"ADNI\" dataset.\n",
    "Here our main task is to find out those samples that have corresponding .best file entry, ie included in larger dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12328/2187409031.py:3: DtypeWarning: Columns (18,19,20,103,104) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ADNIMERGE = pd.read_csv('ADNIMERGE.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RID        PTID VISCODE  SITE COLPROT ORIGPROT  EXAMDATE DX_bl   AGE  \\\n",
      "0    2  011_S_0002      bl    11   ADNI1    ADNI1  08-09-05    CN  74.3   \n",
      "1    3  011_S_0003      bl    11   ADNI1    ADNI1  12-09-05    AD  81.3   \n",
      "2    3  011_S_0003     m06    11   ADNI1    ADNI1  13-03-06    AD  81.3   \n",
      "3    3  011_S_0003     m12    11   ADNI1    ADNI1  12-09-06    AD  81.3   \n",
      "4    3  011_S_0003     m24    11   ADNI1    ADNI1  12-09-07    AD  81.3   \n",
      "\n",
      "  PTGENDER  ...  TAU_bl PTAU_bl   FDG_bl PIB_bl  AV45_bl  Years_bl  Month_bl  \\\n",
      "0     Male  ...     NaN     NaN  1.36665    NaN      NaN  0.000000   0.00000   \n",
      "1     Male  ...   239.7   22.83  1.08355    NaN      NaN  0.000000   0.00000   \n",
      "2     Male  ...   239.7   22.83  1.08355    NaN      NaN  0.498289   5.96721   \n",
      "3     Male  ...   239.7   22.83  1.08355    NaN      NaN  0.999316  11.96720   \n",
      "4     Male  ...   239.7   22.83  1.08355    NaN      NaN  1.998630  23.93440   \n",
      "\n",
      "   Month     M update_stamp  \n",
      "0      0   0.0      55:41.0  \n",
      "1      0   0.0      55:41.0  \n",
      "2      6   6.0      55:41.0  \n",
      "3     12  12.0      55:41.0  \n",
      "4     24  24.0      55:41.0  \n",
      "\n",
      "[5 rows x 113 columns]\n",
      "(15122, 113)\n",
      "Dementia shape :  (2338, 4)\n",
      "        RID        PTID        DX  Month\n",
      "1333    619  002_S_0619  Dementia      0\n",
      "6467    619  002_S_0619  Dementia      6\n",
      "6469    619  002_S_0619  Dementia     12\n",
      "6470    619  002_S_0619  Dementia     24\n",
      "1549    729  002_S_0729  Dementia     12\n",
      "...     ...         ...       ...    ...\n",
      "7928   1311  941_S_1311  Dementia     24\n",
      "8004   1363  941_S_1363  Dementia      6\n",
      "14030  6345  941_S_6345  Dementia     12\n",
      "14947  6345  941_S_6345  Dementia     30\n",
      "14672  6854  941_S_6854  Dementia      0\n",
      "\n",
      "[2338 rows x 4 columns]\n",
      "Samples Dementia length :  787\n",
      "Samples NonDementia length :  1481\n",
      "Final Samples Dementia length :  654\n",
      "Final Samples Non-Dementia length :  1144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(654, 1144, 1798)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# samples with no restriction\n",
    "THRESHOLD_MONTH = 12*0\n",
    "ADNIMERGE = pd.read_csv('ADNIMERGE.csv')\n",
    "print(ADNIMERGE.head())\n",
    "print(ADNIMERGE.shape)\n",
    "ADNI_TEMP = ADNIMERGE[['RID', 'PTID', 'DX', 'Month']].dropna().sort_values(by=['PTID', 'Month'])\n",
    "Dementia = ADNI_TEMP[ADNI_TEMP['DX']=='Dementia']\n",
    "print(\"Dementia shape : \", Dementia.shape)\n",
    "print(Dementia)\n",
    "Samples_Dementia = set(Dementia['PTID'].unique())\n",
    "print(\"Samples Dementia length : \", len(Samples_Dementia) )\n",
    "Samples_NonDementia = set(ADNI_TEMP['PTID'].unique()) - Samples_Dementia\n",
    "print(\"Samples NonDementia length : \", len( Samples_NonDementia ) )\n",
    "\n",
    "# Samples_NonDementia\n",
    "Final_Samples_Dementia = set()\n",
    "for sample in Samples_Dementia:\n",
    "    last_dx = ADNI_TEMP[ADNI_TEMP['PTID']==sample]['DX'].iloc[-1]\n",
    "    last_month_of_dx = ADNI_TEMP[ADNI_TEMP['PTID']==sample]['Month'].iloc[-1]\n",
    "    \n",
    "    if True:\n",
    "#     if last_month_of_dx >= THRESHOLD_MONTH :\n",
    "#         if last_dx != 'Dementia':\n",
    "#             print(last_dx)\n",
    "        \n",
    "        if last_dx == 'Dementia' and sample in usable_samples_ADNI:\n",
    "            \n",
    "            \n",
    "            Final_Samples_Dementia = Final_Samples_Dementia.union({usable_samples_ADNI[sample]})\n",
    "            \n",
    "        \n",
    "#             why check for dementia again?\n",
    "                \n",
    "\n",
    "Final_Samples_NonDementia = set()\n",
    "for sample in Samples_NonDementia:\n",
    "    last_month_of_dx = ADNI_TEMP[ADNI_TEMP['PTID']==sample]['Month'].iloc[-1]\n",
    "    if last_month_of_dx >= THRESHOLD_MONTH and sample in usable_samples_ADNI:\n",
    "#     if sample in usable_samples_ADNI:\n",
    "        Final_Samples_NonDementia = Final_Samples_NonDementia | {usable_samples_ADNI[sample]} # union symbol in python sets\n",
    "    \n",
    "# sum(ADNI_TEMP['Month'] == 6), ADNI_TEMP.shape\n",
    "# Dementia\n",
    "Final_Samples_Dementia = [[x, 1] for x in Final_Samples_Dementia]\n",
    "Final_Samples_NonDementia = [[x, 0] for x in Final_Samples_NonDementia]\n",
    "print(\"Final Samples Dementia length : \", len(Final_Samples_Dementia) )\n",
    "print(\"Final Samples Non-Dementia length : \", len(Final_Samples_NonDementia) )\n",
    "\n",
    "Final_Samples = Final_Samples_Dementia + Final_Samples_NonDementia\n",
    "# json.dump(Final_Samples, open(inputFolder+'Final_Samples.json', 'w'))\n",
    "json.dump(Final_Samples, open('Final_Samples_nores.json', 'w'))\n",
    "json.dump(Final_Samples_Dementia, open('Final_Samples_Dementia.json', 'w'))\n",
    "json.dump(Final_Samples_NonDementia, open('Final_Samples_NonDementia.json', 'w'))\n",
    "\n",
    "\n",
    "Final_Samples_Dementia.__len__(), Final_Samples_NonDementia.__len__(), Final_Samples.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12328/634977319.py:3: DtypeWarning: Columns (18,19,20,103,104) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ADNIMERGE = pd.read_csv('ADNIMERGE.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RID        PTID VISCODE  SITE COLPROT ORIGPROT  EXAMDATE DX_bl   AGE  \\\n",
      "0    2  011_S_0002      bl    11   ADNI1    ADNI1  08-09-05    CN  74.3   \n",
      "1    3  011_S_0003      bl    11   ADNI1    ADNI1  12-09-05    AD  81.3   \n",
      "2    3  011_S_0003     m06    11   ADNI1    ADNI1  13-03-06    AD  81.3   \n",
      "3    3  011_S_0003     m12    11   ADNI1    ADNI1  12-09-06    AD  81.3   \n",
      "4    3  011_S_0003     m24    11   ADNI1    ADNI1  12-09-07    AD  81.3   \n",
      "\n",
      "  PTGENDER  ...  TAU_bl PTAU_bl   FDG_bl PIB_bl  AV45_bl  Years_bl  Month_bl  \\\n",
      "0     Male  ...     NaN     NaN  1.36665    NaN      NaN  0.000000   0.00000   \n",
      "1     Male  ...   239.7   22.83  1.08355    NaN      NaN  0.000000   0.00000   \n",
      "2     Male  ...   239.7   22.83  1.08355    NaN      NaN  0.498289   5.96721   \n",
      "3     Male  ...   239.7   22.83  1.08355    NaN      NaN  0.999316  11.96720   \n",
      "4     Male  ...   239.7   22.83  1.08355    NaN      NaN  1.998630  23.93440   \n",
      "\n",
      "   Month     M update_stamp  \n",
      "0      0   0.0      55:41.0  \n",
      "1      0   0.0      55:41.0  \n",
      "2      6   6.0      55:41.0  \n",
      "3     12  12.0      55:41.0  \n",
      "4     24  24.0      55:41.0  \n",
      "\n",
      "[5 rows x 113 columns]\n",
      "(15122, 113)\n",
      "Dementia shape :  (2338, 4)\n",
      "        RID        PTID        DX  Month\n",
      "1333    619  002_S_0619  Dementia      0\n",
      "6467    619  002_S_0619  Dementia      6\n",
      "6469    619  002_S_0619  Dementia     12\n",
      "6470    619  002_S_0619  Dementia     24\n",
      "1549    729  002_S_0729  Dementia     12\n",
      "...     ...         ...       ...    ...\n",
      "7928   1311  941_S_1311  Dementia     24\n",
      "8004   1363  941_S_1363  Dementia      6\n",
      "14030  6345  941_S_6345  Dementia     12\n",
      "14947  6345  941_S_6345  Dementia     30\n",
      "14672  6854  941_S_6854  Dementia      0\n",
      "\n",
      "[2338 rows x 4 columns]\n",
      "Samples Dementia length :  787\n",
      "Samples NonDementia length :  1481\n",
      "Final Samples Dementia length :  654\n",
      "Final Samples Non-Dementia length :  867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(654, 867, 1521)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 years samples\n",
    "THRESHOLD_MONTH = 12*2\n",
    "ADNIMERGE = pd.read_csv('ADNIMERGE.csv')\n",
    "print(ADNIMERGE.head())\n",
    "print(ADNIMERGE.shape)\n",
    "ADNI_TEMP = ADNIMERGE[['RID', 'PTID', 'DX', 'Month']].dropna().sort_values(by=['PTID', 'Month'])\n",
    "Dementia = ADNI_TEMP[ADNI_TEMP['DX']=='Dementia']\n",
    "print(\"Dementia shape : \", Dementia.shape)\n",
    "print(Dementia)\n",
    "Samples_Dementia = set(Dementia['PTID'].unique())\n",
    "print(\"Samples Dementia length : \", len(Samples_Dementia) )\n",
    "Samples_NonDementia = set(ADNI_TEMP['PTID'].unique()) - Samples_Dementia\n",
    "print(\"Samples NonDementia length : \", len( Samples_NonDementia ) )\n",
    "\n",
    "# Samples_NonDementia\n",
    "Final_Samples_Dementia = set()\n",
    "for sample in Samples_Dementia:\n",
    "    last_dx = ADNI_TEMP[ADNI_TEMP['PTID']==sample]['DX'].iloc[-1]\n",
    "    last_month_of_dx = ADNI_TEMP[ADNI_TEMP['PTID']==sample]['Month'].iloc[-1]\n",
    "    \n",
    "    if True:\n",
    "#     if last_month_of_dx >= THRESHOLD_MONTH :\n",
    "#         if last_dx != 'Dementia':\n",
    "#             print(last_dx)\n",
    "        \n",
    "        if last_dx == 'Dementia' and sample in usable_samples_ADNI:\n",
    "            \n",
    "            \n",
    "            Final_Samples_Dementia = Final_Samples_Dementia.union({usable_samples_ADNI[sample]})\n",
    "            \n",
    "        \n",
    "#             why check for dementia again?\n",
    "                \n",
    "\n",
    "Final_Samples_NonDementia = set()\n",
    "for sample in Samples_NonDementia:\n",
    "    last_month_of_dx = ADNI_TEMP[ADNI_TEMP['PTID']==sample]['Month'].iloc[-1]\n",
    "    if last_month_of_dx >= THRESHOLD_MONTH and sample in usable_samples_ADNI:\n",
    "#     if sample in usable_samples_ADNI:\n",
    "        Final_Samples_NonDementia = Final_Samples_NonDementia | {usable_samples_ADNI[sample]} # union symbol in python sets\n",
    "    \n",
    "# sum(ADNI_TEMP['Month'] == 6), ADNI_TEMP.shape\n",
    "# Dementia\n",
    "Final_Samples_Dementia = [[x, 1] for x in Final_Samples_Dementia]\n",
    "Final_Samples_NonDementia = [[x, 0] for x in Final_Samples_NonDementia]\n",
    "print(\"Final Samples Dementia length : \", len(Final_Samples_Dementia) )\n",
    "print(\"Final Samples Non-Dementia length : \", len(Final_Samples_NonDementia) )\n",
    "\n",
    "Final_Samples = Final_Samples_Dementia + Final_Samples_NonDementia\n",
    "# json.dump(Final_Samples, open(inputFolder+'Final_Samples.json', 'w'))\n",
    "json.dump(Final_Samples, open('Final_Samples_2yrs.json', 'w'))\n",
    "json.dump(Final_Samples_Dementia, open('Final_Samples_Dementia.json', 'w'))\n",
    "json.dump(Final_Samples_NonDementia, open('Final_Samples_NonDementia.json', 'w'))\n",
    "\n",
    "\n",
    "Final_Samples_Dementia.__len__(), Final_Samples_NonDementia.__len__(), Final_Samples.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12328/2450854249.py:3: DtypeWarning: Columns (18,19,20,103,104) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ADNIMERGE = pd.read_csv('ADNIMERGE.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RID        PTID VISCODE  SITE COLPROT ORIGPROT  EXAMDATE DX_bl   AGE  \\\n",
      "0    2  011_S_0002      bl    11   ADNI1    ADNI1  08-09-05    CN  74.3   \n",
      "1    3  011_S_0003      bl    11   ADNI1    ADNI1  12-09-05    AD  81.3   \n",
      "2    3  011_S_0003     m06    11   ADNI1    ADNI1  13-03-06    AD  81.3   \n",
      "3    3  011_S_0003     m12    11   ADNI1    ADNI1  12-09-06    AD  81.3   \n",
      "4    3  011_S_0003     m24    11   ADNI1    ADNI1  12-09-07    AD  81.3   \n",
      "\n",
      "  PTGENDER  ...  TAU_bl PTAU_bl   FDG_bl PIB_bl  AV45_bl  Years_bl  Month_bl  \\\n",
      "0     Male  ...     NaN     NaN  1.36665    NaN      NaN  0.000000   0.00000   \n",
      "1     Male  ...   239.7   22.83  1.08355    NaN      NaN  0.000000   0.00000   \n",
      "2     Male  ...   239.7   22.83  1.08355    NaN      NaN  0.498289   5.96721   \n",
      "3     Male  ...   239.7   22.83  1.08355    NaN      NaN  0.999316  11.96720   \n",
      "4     Male  ...   239.7   22.83  1.08355    NaN      NaN  1.998630  23.93440   \n",
      "\n",
      "   Month     M update_stamp  \n",
      "0      0   0.0      55:41.0  \n",
      "1      0   0.0      55:41.0  \n",
      "2      6   6.0      55:41.0  \n",
      "3     12  12.0      55:41.0  \n",
      "4     24  24.0      55:41.0  \n",
      "\n",
      "[5 rows x 113 columns]\n",
      "(15122, 113)\n",
      "Dementia shape :  (2338, 4)\n",
      "        RID        PTID        DX  Month\n",
      "1333    619  002_S_0619  Dementia      0\n",
      "6467    619  002_S_0619  Dementia      6\n",
      "6469    619  002_S_0619  Dementia     12\n",
      "6470    619  002_S_0619  Dementia     24\n",
      "1549    729  002_S_0729  Dementia     12\n",
      "...     ...         ...       ...    ...\n",
      "7928   1311  941_S_1311  Dementia     24\n",
      "8004   1363  941_S_1363  Dementia      6\n",
      "14030  6345  941_S_6345  Dementia     12\n",
      "14947  6345  941_S_6345  Dementia     30\n",
      "14672  6854  941_S_6854  Dementia      0\n",
      "\n",
      "[2338 rows x 4 columns]\n",
      "Samples Dementia length :  787\n",
      "Samples NonDementia length :  1481\n",
      "Final Samples Dementia length :  654\n",
      "Final Samples Non-Dementia length :  504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(654, 504, 1158)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 years samples\n",
    "THRESHOLD_MONTH = 12*4\n",
    "ADNIMERGE = pd.read_csv('ADNIMERGE.csv')\n",
    "print(ADNIMERGE.head())\n",
    "print(ADNIMERGE.shape)\n",
    "ADNI_TEMP = ADNIMERGE[['RID', 'PTID', 'DX', 'Month']].dropna().sort_values(by=['PTID', 'Month'])\n",
    "Dementia = ADNI_TEMP[ADNI_TEMP['DX']=='Dementia']\n",
    "print(\"Dementia shape : \", Dementia.shape)\n",
    "print(Dementia)\n",
    "Samples_Dementia = set(Dementia['PTID'].unique())\n",
    "print(\"Samples Dementia length : \", len(Samples_Dementia) )\n",
    "Samples_NonDementia = set(ADNI_TEMP['PTID'].unique()) - Samples_Dementia\n",
    "print(\"Samples NonDementia length : \", len( Samples_NonDementia ) )\n",
    "\n",
    "# Samples_NonDementia\n",
    "Final_Samples_Dementia = set()\n",
    "for sample in Samples_Dementia:\n",
    "    last_dx = ADNI_TEMP[ADNI_TEMP['PTID']==sample]['DX'].iloc[-1]\n",
    "    last_month_of_dx = ADNI_TEMP[ADNI_TEMP['PTID']==sample]['Month'].iloc[-1]\n",
    "    \n",
    "    if True:\n",
    "#     if last_month_of_dx >= THRESHOLD_MONTH :\n",
    "#         if last_dx != 'Dementia':\n",
    "#             print(last_dx)\n",
    "        \n",
    "        if last_dx == 'Dementia' and sample in usable_samples_ADNI:\n",
    "            \n",
    "            \n",
    "            Final_Samples_Dementia = Final_Samples_Dementia.union({usable_samples_ADNI[sample]})\n",
    "            \n",
    "        \n",
    "#             why check for dementia again?\n",
    "                \n",
    "\n",
    "Final_Samples_NonDementia = set()\n",
    "for sample in Samples_NonDementia:\n",
    "    last_month_of_dx = ADNI_TEMP[ADNI_TEMP['PTID']==sample]['Month'].iloc[-1]\n",
    "    if last_month_of_dx >= THRESHOLD_MONTH and sample in usable_samples_ADNI:\n",
    "#     if sample in usable_samples_ADNI:\n",
    "        Final_Samples_NonDementia = Final_Samples_NonDementia | {usable_samples_ADNI[sample]} # union symbol in python sets\n",
    "    \n",
    "# sum(ADNI_TEMP['Month'] == 6), ADNI_TEMP.shape\n",
    "# Dementia\n",
    "Final_Samples_Dementia = [[x, 1] for x in Final_Samples_Dementia]\n",
    "Final_Samples_NonDementia = [[x, 0] for x in Final_Samples_NonDementia]\n",
    "print(\"Final Samples Dementia length : \", len(Final_Samples_Dementia) )\n",
    "print(\"Final Samples Non-Dementia length : \", len(Final_Samples_NonDementia) )\n",
    "\n",
    "Final_Samples = Final_Samples_Dementia + Final_Samples_NonDementia\n",
    "# json.dump(Final_Samples, open(inputFolder+'Final_Samples.json', 'w'))\n",
    "json.dump(Final_Samples, open('Final_Samples_4yrs.json', 'w'))\n",
    "json.dump(Final_Samples_Dementia, open('Final_Samples_Dementia.json', 'w'))\n",
    "json.dump(Final_Samples_NonDementia, open('Final_Samples_NonDementia.json', 'w'))\n",
    "\n",
    "\n",
    "Final_Samples_Dementia.__len__(), Final_Samples_NonDementia.__len__(), Final_Samples.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12328/1020319883.py:3: DtypeWarning: Columns (18,19,20,103,104) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ADNIMERGE = pd.read_csv('ADNIMERGE.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RID        PTID VISCODE  SITE COLPROT ORIGPROT  EXAMDATE DX_bl   AGE  \\\n",
      "0    2  011_S_0002      bl    11   ADNI1    ADNI1  08-09-05    CN  74.3   \n",
      "1    3  011_S_0003      bl    11   ADNI1    ADNI1  12-09-05    AD  81.3   \n",
      "2    3  011_S_0003     m06    11   ADNI1    ADNI1  13-03-06    AD  81.3   \n",
      "3    3  011_S_0003     m12    11   ADNI1    ADNI1  12-09-06    AD  81.3   \n",
      "4    3  011_S_0003     m24    11   ADNI1    ADNI1  12-09-07    AD  81.3   \n",
      "\n",
      "  PTGENDER  ...  TAU_bl PTAU_bl   FDG_bl PIB_bl  AV45_bl  Years_bl  Month_bl  \\\n",
      "0     Male  ...     NaN     NaN  1.36665    NaN      NaN  0.000000   0.00000   \n",
      "1     Male  ...   239.7   22.83  1.08355    NaN      NaN  0.000000   0.00000   \n",
      "2     Male  ...   239.7   22.83  1.08355    NaN      NaN  0.498289   5.96721   \n",
      "3     Male  ...   239.7   22.83  1.08355    NaN      NaN  0.999316  11.96720   \n",
      "4     Male  ...   239.7   22.83  1.08355    NaN      NaN  1.998630  23.93440   \n",
      "\n",
      "   Month     M update_stamp  \n",
      "0      0   0.0      55:41.0  \n",
      "1      0   0.0      55:41.0  \n",
      "2      6   6.0      55:41.0  \n",
      "3     12  12.0      55:41.0  \n",
      "4     24  24.0      55:41.0  \n",
      "\n",
      "[5 rows x 113 columns]\n",
      "(15122, 113)\n",
      "Dementia shape :  (2338, 4)\n",
      "        RID        PTID        DX  Month\n",
      "1333    619  002_S_0619  Dementia      0\n",
      "6467    619  002_S_0619  Dementia      6\n",
      "6469    619  002_S_0619  Dementia     12\n",
      "6470    619  002_S_0619  Dementia     24\n",
      "1549    729  002_S_0729  Dementia     12\n",
      "...     ...         ...       ...    ...\n",
      "7928   1311  941_S_1311  Dementia     24\n",
      "8004   1363  941_S_1363  Dementia      6\n",
      "14030  6345  941_S_6345  Dementia     12\n",
      "14947  6345  941_S_6345  Dementia     30\n",
      "14672  6854  941_S_6854  Dementia      0\n",
      "\n",
      "[2338 rows x 4 columns]\n",
      "Samples Dementia length :  787\n",
      "Samples NonDementia length :  1481\n",
      "Final Samples Dementia length :  654\n",
      "Final Samples Non-Dementia length :  320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(654, 320, 974)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This struggles in our ADNI dataset\n",
    "THRESHOLD_MONTH = 12*6\n",
    "ADNIMERGE = pd.read_csv('ADNIMERGE.csv')\n",
    "print(ADNIMERGE.head())\n",
    "print(ADNIMERGE.shape)\n",
    "ADNI_TEMP = ADNIMERGE[['RID', 'PTID', 'DX', 'Month']].dropna().sort_values(by=['PTID', 'Month'])\n",
    "Dementia = ADNI_TEMP[ADNI_TEMP['DX']=='Dementia']\n",
    "print(\"Dementia shape : \", Dementia.shape)\n",
    "print(Dementia)\n",
    "Samples_Dementia = set(Dementia['PTID'].unique())\n",
    "print(\"Samples Dementia length : \", len(Samples_Dementia) )\n",
    "Samples_NonDementia = set(ADNI_TEMP['PTID'].unique()) - Samples_Dementia\n",
    "print(\"Samples NonDementia length : \", len( Samples_NonDementia ) )\n",
    "\n",
    "# Samples_NonDementia\n",
    "Final_Samples_Dementia = set()\n",
    "for sample in Samples_Dementia:\n",
    "    last_dx = ADNI_TEMP[ADNI_TEMP['PTID']==sample]['DX'].iloc[-1]\n",
    "    last_month_of_dx = ADNI_TEMP[ADNI_TEMP['PTID']==sample]['Month'].iloc[-1]\n",
    "    \n",
    "    if True:\n",
    "#     if last_month_of_dx >= THRESHOLD_MONTH :\n",
    "#         if last_dx != 'Dementia':\n",
    "#             print(last_dx)\n",
    "        \n",
    "        if last_dx == 'Dementia' and sample in usable_samples_ADNI:\n",
    "            \n",
    "            \n",
    "            Final_Samples_Dementia = Final_Samples_Dementia.union({usable_samples_ADNI[sample]})\n",
    "            \n",
    "        \n",
    "#             why check for dementia again?\n",
    "                \n",
    "\n",
    "Final_Samples_NonDementia = set()\n",
    "for sample in Samples_NonDementia:\n",
    "    last_month_of_dx = ADNI_TEMP[ADNI_TEMP['PTID']==sample]['Month'].iloc[-1]\n",
    "    if last_month_of_dx >= THRESHOLD_MONTH and sample in usable_samples_ADNI:\n",
    "#     if sample in usable_samples_ADNI:\n",
    "        Final_Samples_NonDementia = Final_Samples_NonDementia | {usable_samples_ADNI[sample]} # union symbol in python sets\n",
    "    \n",
    "# sum(ADNI_TEMP['Month'] == 6), ADNI_TEMP.shape\n",
    "# Dementia\n",
    "Final_Samples_Dementia = [[x, 1] for x in Final_Samples_Dementia]\n",
    "Final_Samples_NonDementia = [[x, 0] for x in Final_Samples_NonDementia]\n",
    "print(\"Final Samples Dementia length : \", len(Final_Samples_Dementia) )\n",
    "print(\"Final Samples Non-Dementia length : \", len(Final_Samples_NonDementia) )\n",
    "\n",
    "Final_Samples = Final_Samples_Dementia + Final_Samples_NonDementia\n",
    "# json.dump(Final_Samples, open(inputFolder+'Final_Samples.json', 'w'))\n",
    "json.dump(Final_Samples, open('Final_Samples_6yrs.json', 'w'))\n",
    "json.dump(Final_Samples_Dementia, open('Final_Samples_Dementia.json', 'w'))\n",
    "json.dump(Final_Samples_NonDementia, open('Final_Samples_NonDementia.json', 'w'))\n",
    "\n",
    "\n",
    "Final_Samples_Dementia.__len__(), Final_Samples_NonDementia.__len__(), Final_Samples.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12328/3847962530.py:4: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  usable_samples_ADNI = pd.read_csv(f'./PRSice_output/{GWAS_ID}/{GWAS_ID}.best', ' ')['IID'].to_numpy().tolist()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ADNI3_036_S_6231': 0,\n",
       " 'ADNI3_006_S_6277': 1,\n",
       " 'ADNI3_129_S_6146': 2,\n",
       " 'ADNI3_033_S_6352': 3,\n",
       " 'ADNI3_027_S_6183': 4,\n",
       " 'ADNI3_005_S_6427': 5,\n",
       " 'ADNI3_127_S_6147': 6,\n",
       " 'ADNI3_114_S_6251': 7,\n",
       " 'ADNI3_129_S_6228': 8,\n",
       " 'ADNI3_114_S_6309': 9,\n",
       " 'ADNI3_135_S_6110': 10,\n",
       " 'ADNI3_020_S_6358': 11,\n",
       " 'ADNI3_135_S_6411': 12,\n",
       " 'ADNI3_024_S_6202': 13,\n",
       " 'ADNI3_018_S_6414': 14,\n",
       " 'ADNI3_002_S_6103': 15,\n",
       " 'ADNI3_177_S_6408': 16,\n",
       " 'ADNI3_014_S_6148': 17,\n",
       " 'ADNI3_036_S_6466': 18,\n",
       " 'ADNI3_036_S_6134': 19,\n",
       " 'ADNI3_007_S_6455': 20,\n",
       " 'ADNI3_037_S_6271': 21,\n",
       " 'ADNI3_116_S_6100': 22,\n",
       " 'ADNI3_027_S_6327': 23,\n",
       " 'ADNI3_099_S_6097': 24,\n",
       " 'ADNI3_127_S_6330': 25,\n",
       " 'ADNI3_127_S_6168': 26,\n",
       " 'ADNI3_018_S_6351': 27,\n",
       " 'ADNI3_009_S_6212': 28,\n",
       " 'ADNI3_168_S_6180': 29,\n",
       " 'ADNI3_116_S_6119': 30,\n",
       " 'ADNI3_023_S_6346': 31,\n",
       " 'ADNI3_168_S_6065': 32,\n",
       " 'ADNI3_035_S_6200': 33,\n",
       " 'ADNI3_023_S_6399': 34,\n",
       " 'ADNI3_037_S_6125': 35,\n",
       " 'ADNI3_116_S_6428': 36,\n",
       " 'ADNI3_041_S_6192': 37,\n",
       " 'ADNI3_941_S_6333': 38,\n",
       " 'ADNI3_006_S_6209': 39,\n",
       " 'ADNI3_033_S_6497': 40,\n",
       " 'ADNI3_127_S_6436': 41,\n",
       " 'ADNI3_141_S_6178': 42,\n",
       " 'ADNI3_002_S_6456': 43,\n",
       " 'ADNI3_168_S_6062': 44,\n",
       " 'ADNI3_033_S_6298': 45,\n",
       " 'ADNI3_002_S_6053': 46,\n",
       " 'ADNI3_135_S_6359': 47,\n",
       " 'ADNI3_141_S_6015': 48,\n",
       " 'ADNI3_027_S_6317': 49,\n",
       " 'ADNI3_002_S_6009': 50,\n",
       " 'ADNI3_098_S_6343': 51,\n",
       " 'ADNI3_024_S_6033': 52,\n",
       " 'ADNI3_941_S_6384': 53,\n",
       " 'ADNI3_141_S_6008': 54,\n",
       " 'ADNI3_023_S_6400': 55,\n",
       " 'ADNI3_027_S_6034': 56,\n",
       " 'ADNI3_002_S_6404': 57,\n",
       " 'ADNI3_037_S_6031': 58,\n",
       " 'ADNI3_941_S_6017': 59,\n",
       " 'ADNI3_130_S_6329': 60,\n",
       " 'ADNI3_941_S_6044': 61,\n",
       " 'ADNI3_020_S_6470': 62,\n",
       " 'ADNI3_941_S_6052': 63,\n",
       " 'ADNI3_082_S_6197': 64,\n",
       " 'ADNI3_130_S_6019': 65,\n",
       " 'ADNI3_023_S_6356': 66,\n",
       " 'ADNI3_002_S_6030': 67,\n",
       " 'ADNI3_094_S_6419': 68,\n",
       " 'ADNI3_130_S_6037': 69,\n",
       " 'ADNI3_007_S_6310': 70,\n",
       " 'ADNI3_941_S_6054': 71,\n",
       " 'ADNI3_041_S_6354': 72,\n",
       " 'ADNI3_141_S_6041': 73,\n",
       " 'ADNI3_135_S_6360': 74,\n",
       " 'ADNI3_067_S_6045': 75,\n",
       " 'ADNI3_011_S_6367': 76,\n",
       " 'ADNI3_099_S_6016': 77,\n",
       " 'ADNI3_035_S_6306': 78,\n",
       " 'ADNI3_024_S_6005': 79,\n",
       " 'ADNI3_168_S_6318': 80,\n",
       " 'ADNI3_130_S_6047': 81,\n",
       " 'ADNI3_082_S_6287': 82,\n",
       " 'ADNI3_941_S_6068': 83,\n",
       " 'ADNI3_037_S_6222': 84,\n",
       " 'ADNI3_022_S_6013': 85,\n",
       " 'ADNI3_941_S_6422': 86,\n",
       " 'ADNI3_114_S_6039': 87,\n",
       " 'ADNI3_006_S_6375': 88,\n",
       " 'ADNI3_002_S_6066': 89,\n",
       " 'ADNI3_094_S_6250': 90,\n",
       " 'ADNI3_305_S_6188': 91,\n",
       " 'ADNI3_941_S_6471': 92,\n",
       " 'ADNI3_003_S_6258': 93,\n",
       " 'ADNI3_041_S_6159': 94,\n",
       " 'ADNI3_100_S_6349': 95,\n",
       " 'ADNI3_141_S_6240': 96,\n",
       " 'ADNI3_131_S_6170': 97,\n",
       " 'ADNI3_018_S_6207': 98,\n",
       " 'ADNI3_003_S_6256': 99,\n",
       " 'ADNI3_301_S_6224': 100,\n",
       " 'ADNI3_023_S_6334': 101,\n",
       " 'ADNI3_007_S_6255': 102,\n",
       " 'ADNI3_003_S_6260': 103,\n",
       " 'ADNI3_100_S_6164': 104,\n",
       " 'ADNI3_070_S_6394': 105,\n",
       " 'ADNI3_014_S_6145': 106,\n",
       " 'ADNI3_099_S_6396': 107,\n",
       " 'ADNI3_109_S_6213': 108,\n",
       " 'ADNI3_129_S_6452': 109,\n",
       " 'ADNI3_009_S_6163': 110,\n",
       " 'ADNI3_116_S_6543': 111,\n",
       " 'ADNI3_003_S_6158': 112,\n",
       " 'ADNI3_130_S_6161': 113,\n",
       " 'ADNI3_006_S_6252': 114,\n",
       " 'ADNI3_135_S_6446': 115,\n",
       " 'ADNI3_014_S_6199': 116,\n",
       " 'ADNI3_130_S_6319': 117,\n",
       " 'ADNI3_129_S_6244': 118,\n",
       " 'ADNI3_032_S_6279': 119,\n",
       " 'ADNI3_006_S_6243': 120,\n",
       " 'ADNI3_301_S_6326': 121,\n",
       " 'ADNI3_114_S_6113': 122,\n",
       " 'ADNI3_007_S_6323': 123,\n",
       " 'ADNI3_153_S_6274': 124,\n",
       " 'ADNI3_094_S_6269': 125,\n",
       " 'ADNI3_037_S_6141': 126,\n",
       " 'ADNI3_037_S_6187': 127,\n",
       " 'ADNI3_168_S_6049': 128,\n",
       " 'ADNI3_177_S_6335': 129,\n",
       " 'ADNI3_033_S_6266': 130,\n",
       " 'ADNI3_129_S_6459': 131,\n",
       " 'ADNI3_130_S_6372': 132,\n",
       " 'ADNI3_141_S_6253': 133,\n",
       " 'ADNI3_006_S_6500': 134,\n",
       " 'ADNI3_130_S_6072': 135,\n",
       " 'ADNI3_082_S_6283': 136,\n",
       " 'ADNI3_141_S_6061': 137,\n",
       " 'ADNI3_007_S_6341': 138,\n",
       " 'ADNI3_007_S_6120': 139,\n",
       " 'ADNI3_094_S_6275': 140,\n",
       " 'ADNI3_941_S_6080': 141,\n",
       " 'ADNI3_016_S_6381': 142,\n",
       " 'ADNI3_941_S_6094': 143,\n",
       " 'ADNI3_941_S_6345': 144,\n",
       " 'ADNI3_003_S_6067': 145,\n",
       " 'ADNI3_023_S_6374': 146,\n",
       " 'ADNI3_012_S_6073': 147,\n",
       " 'ADNI3_037_S_6216': 148,\n",
       " 'ADNI3_135_S_6104': 149,\n",
       " 'ADNI3_168_S_6320': 150,\n",
       " 'ADNI3_067_S_6117': 151,\n",
       " 'ADNI3_041_S_6401': 152,\n",
       " 'ADNI3_014_S_6076': 153,\n",
       " 'ADNI3_011_S_6418': 154,\n",
       " 'ADNI3_036_S_6088': 155,\n",
       " 'ADNI3_003_S_6432': 156,\n",
       " 'ADNI3_037_S_6083': 157,\n",
       " 'ADNI3_116_S_6550': 158,\n",
       " 'ADNI3_130_S_6043': 159,\n",
       " 'ADNI3_070_S_6386': 160,\n",
       " 'ADNI3_127_S_6024': 161,\n",
       " 'ADNI3_027_S_6370': 162,\n",
       " 'ADNI3_023_S_6369': 163,\n",
       " 'ADNI3_130_S_6035': 164,\n",
       " 'ADNI3_168_S_6371': 165,\n",
       " 'ADNI3_099_S_6038': 166,\n",
       " 'ADNI3_168_S_6350': 167,\n",
       " 'ADNI3_301_S_6056': 168,\n",
       " 'ADNI3_099_S_6025': 169,\n",
       " 'ADNI3_135_S_6389': 170,\n",
       " 'ADNI3_130_S_6105': 171,\n",
       " 'ADNI3_127_S_6241': 172,\n",
       " 'ADNI3_022_S_6069': 173,\n",
       " 'ADNI3_009_S_6402': 174,\n",
       " 'ADNI3_941_S_6058': 175,\n",
       " 'ADNI3_035_S_6488': 176,\n",
       " 'ADNI3_141_S_6116': 177,\n",
       " 'ADNI3_116_S_6439': 178,\n",
       " 'ADNI3_116_S_6133': 179,\n",
       " 'ADNI3_037_S_6204': 180,\n",
       " 'ADNI3_114_S_6429': 181,\n",
       " 'ADNI3_041_S_6292': 182,\n",
       " 'ADNI3_013_S_6206': 183,\n",
       " 'ADNI3_153_S_6336': 184,\n",
       " 'ADNI3_014_S_6437': 185,\n",
       " 'ADNI3_100_S_6273': 186,\n",
       " 'ADNI3_027_S_6577': 187,\n",
       " 'ADNI3_941_S_6575': 188,\n",
       " 'ADNI3_036_S_6189': 189,\n",
       " 'ADNI3_135_S_6545': 190,\n",
       " 'ADNI3_036_S_6179': 191,\n",
       " 'ADNI3_135_S_6473': 192,\n",
       " 'ADNI3_029_S_6289': 193,\n",
       " 'ADNI3_014_S_6522': 194,\n",
       " 'ADNI3_019_S_6186': 195,\n",
       " 'ADNI3_014_S_6502': 196,\n",
       " 'ADNI3_070_S_6236': 197,\n",
       " 'ADNI3_027_S_6582': 198,\n",
       " 'ADNI3_168_S_6085': 199,\n",
       " 'ADNI3_019_S_6573': 200,\n",
       " 'ADNI3_003_S_6259': 201,\n",
       " 'ADNI3_305_S_6498': 202,\n",
       " 'ADNI3_003_S_6014': 203,\n",
       " 'ADNI3_100_S_6578': 204,\n",
       " 'ADNI3_021_S_6312': 205,\n",
       " 'ADNI3_135_S_6544': 206,\n",
       " 'ADNI3_014_S_6424': 207,\n",
       " 'ADNI3_305_S_6313': 208,\n",
       " 'ADNI3_127_S_6549': 209,\n",
       " 'ADNI3_131_S_6143': 210,\n",
       " 'ADNI3_127_S_6512': 211,\n",
       " 'ADNI3_127_S_6232': 212,\n",
       " 'ADNI3_033_S_6572': 213,\n",
       " 'ADNI3_041_S_6226': 214,\n",
       " 'ADNI3_003_S_6264': 215,\n",
       " 'ADNI3_032_S_6211': 216,\n",
       " 'ADNI3_023_S_6547': 217,\n",
       " 'ADNI3_130_S_6111': 218,\n",
       " 'ADNI3_141_S_6423': 219,\n",
       " 'ADNI3_020_S_6282': 220,\n",
       " 'ADNI3_067_S_6529': 221,\n",
       " 'ADNI3_011_S_6303': 222,\n",
       " 'ADNI3_020_S_6566': 223,\n",
       " 'ADNI3_099_S_6175': 224,\n",
       " 'ADNI3_037_S_6377': 225,\n",
       " 'ADNI3_002_S_6007': 226,\n",
       " 'ADNI3_003_S_6307': 227,\n",
       " 'ADNI3_037_S_6046': 228,\n",
       " 'ADNI3_003_S_6479': 229,\n",
       " 'ADNI3_305_S_6157': 230,\n",
       " 'ADNI3_007_S_6515': 231,\n",
       " 'ADNI3_941_S_6581': 232,\n",
       " 'ADNI3_127_S_6173': 233,\n",
       " 'ADNI3_094_S_6417': 234,\n",
       " 'ADNI3_024_S_6385': 235,\n",
       " 'ADNI3_020_S_6227': 236,\n",
       " 'ADNI3_168_S_6413': 237,\n",
       " 'ADNI3_135_S_6284': 238,\n",
       " 'ADNI3_024_S_6472': 239,\n",
       " 'ADNI3_020_S_6185': 240,\n",
       " 'ADNI3_123_S_6118': 241,\n",
       " 'ADNI3_941_S_6514': 242,\n",
       " 'ADNI3_019_S_6315': 243,\n",
       " 'ADNI3_141_S_6075': 244,\n",
       " 'ADNI3_012_S_6503': 245,\n",
       " 'ADNI3_100_S_6308': 246,\n",
       " 'ADNI3_135_S_6586': 247,\n",
       " 'ADNI3_005_S_6084': 248,\n",
       " 'ADNI3_027_S_6001': 249,\n",
       " 'ADNI3_177_S_6448': 250,\n",
       " 'ADNI3_053_S_6598': 251,\n",
       " 'ADNI3_027_S_6002': 252,\n",
       " 'ADNI3_168_S_6467': 253,\n",
       " 'ADNI3_006_S_6234': 254,\n",
       " 'ADNI3_003_S_6268': 255,\n",
       " 'ADNI3_168_S_6426': 256,\n",
       " 'ADNI3_067_S_6442': 257,\n",
       " 'ADNI3_127_S_6348': 258,\n",
       " 'ADNI3_020_S_6513': 259,\n",
       " 'ADNI3_067_S_6138': 260,\n",
       " 'ADNI3_135_S_6510': 261,\n",
       " 'ADNI3_168_S_6151': 262,\n",
       " 'ADNI3_011_S_6465': 263,\n",
       " 'ADNI3_019_S_6483': 264,\n",
       " 'ADNI3_941_S_6454': 265,\n",
       " 'ADNI3_094_S_6485': 266,\n",
       " 'ADNI3_168_S_6321': 267,\n",
       " 'ADNI3_067_S_6474': 268,\n",
       " 'ADNI3_007_S_6421': 269,\n",
       " 'ADNI3_114_S_6347': 270,\n",
       " 'ADNI3_141_S_6416': 271,\n",
       " 'ADNI3_129_S_6457': 272,\n",
       " 'ADNI3_027_S_6463': 273,\n",
       " 'ADNI3_094_S_6468': 274,\n",
       " 'ADNI3_177_S_6409': 275,\n",
       " 'ADNI3_032_S_6294': 276,\n",
       " 'ADNI3_341_S_6494': 277,\n",
       " 'ADNI3_036_S_6316': 278,\n",
       " 'ADNI3_035_S_6480': 279,\n",
       " 'ADNI3_006_S_6441': 280,\n",
       " 'ADNI3_127_S_6357': 281,\n",
       " 'ADNI3_027_S_6516': 282,\n",
       " 'ADNI3_941_S_6580': 283,\n",
       " 'ADNI3_941_S_6546': 284,\n",
       " 'ADNI3_127_S_6433': 285,\n",
       " 'ADNI3_100_S_6493': 286,\n",
       " 'ADNI3_019_S_6533': 287,\n",
       " 'ADNI3_168_S_6233': 288,\n",
       " 'ADNI3_126_S_6559': 289,\n",
       " 'ADNI3_168_S_6492': 290,\n",
       " 'ADNI3_131_S_6519': 291,\n",
       " 'ADNI3_099_S_6476': 292,\n",
       " 'ADNI3_020_S_6504': 293,\n",
       " 'ADNI3_098_S_6534': 294,\n",
       " 'ADNI3_041_S_6314': 295,\n",
       " 'ADNI3_941_S_6499': 296,\n",
       " 'ADNI3_023_S_6535': 297,\n",
       " 'ADNI3_305_S_6378': 298,\n",
       " 'ADNI3_082_S_6415': 299,\n",
       " '4_024_S_0985': 300,\n",
       " '6_131_S_0123': 301,\n",
       " '7_098_S_0160': 302,\n",
       " '8_027_S_0256': 303,\n",
       " '9_116_S_1243': 304,\n",
       " '17_011_S_0002': 305,\n",
       " '18_003_S_0907': 306,\n",
       " '26_052_S_1346': 307,\n",
       " '27_012_S_4026': 308,\n",
       " '28_037_S_4030': 309,\n",
       " '29_073_S_2182': 310,\n",
       " '30_116_S_4167': 311,\n",
       " '32_073_S_0089': 312,\n",
       " '33_082_S_2099': 313,\n",
       " '36_021_S_2100': 314,\n",
       " '37_127_S_1427': 315,\n",
       " '38_023_S_0926': 316,\n",
       " '39_137_S_4672': 317,\n",
       " '41_033_S_0920': 318,\n",
       " '43_137_S_1414': 319,\n",
       " '45_128_S_1408': 320,\n",
       " '47_072_S_2027': 321,\n",
       " '48_128_S_0545': 322,\n",
       " '50_021_S_0626': 323,\n",
       " '51_016_S_0702': 324,\n",
       " '52_136_S_0695': 325,\n",
       " '53_051_S_1072': 326,\n",
       " '54_014_S_0558': 327,\n",
       " '55_136_S_0873': 328,\n",
       " '57_002_S_0729': 329,\n",
       " '58_131_S_0384': 330,\n",
       " '61_014_S_0563': 331,\n",
       " '62_029_S_0845': 332,\n",
       " '63_007_S_0068': 333,\n",
       " '64_027_S_2219': 334,\n",
       " '65_021_S_2142': 335,\n",
       " '67_011_S_1080': 336,\n",
       " '69_127_S_1032': 337,\n",
       " '70_014_S_0169': 338,\n",
       " '71_027_S_1045': 339,\n",
       " '72_082_S_0832': 340,\n",
       " '74_082_S_4208': 341,\n",
       " '75_068_S_4174': 342,\n",
       " '77_051_S_1331': 343,\n",
       " '78_029_S_2376': 344,\n",
       " '79_031_S_4149': 345,\n",
       " '80_153_S_4151': 346,\n",
       " '81_098_S_2052': 347,\n",
       " '82_007_S_2058': 348,\n",
       " '83_007_S_0128': 349,\n",
       " '84_100_S_1226': 350,\n",
       " '85_127_S_0259': 351,\n",
       " '86_100_S_0296': 352,\n",
       " '87_031_S_4029': 353,\n",
       " '88_041_S_4051': 354,\n",
       " '90_098_S_4059': 355,\n",
       " '91_016_S_2031': 356,\n",
       " '92_941_S_4036': 357,\n",
       " '93_068_S_4134': 358,\n",
       " '94_003_S_4119': 359,\n",
       " '95_141_S_4160': 360,\n",
       " '96_041_S_1418': 361,\n",
       " '97_033_S_4176': 362,\n",
       " '98_941_S_4100': 363,\n",
       " '99_153_S_2148': 364,\n",
       " '134_014_S_4058': 365,\n",
       " '135_099_S_4076': 366,\n",
       " '137_027_S_0644': 367,\n",
       " '153_002_S_2043': 368,\n",
       " '174_037_S_0303': 369,\n",
       " '176_041_S_4138': 370,\n",
       " '189_023_S_4448': 371,\n",
       " '190_128_S_4571': 372,\n",
       " '191_012_S_4545': 373,\n",
       " '192_035_S_4414': 374,\n",
       " '194_109_S_4499': 375,\n",
       " '195_126_S_4514': 376,\n",
       " '200_014_S_0548': 377,\n",
       " '205_153_S_4159': 378,\n",
       " '217_051_S_1123': 379,\n",
       " '219_098_S_4095': 380,\n",
       " '222_141_S_0915': 381,\n",
       " '223_126_S_2407': 382,\n",
       " '226_037_S_4410': 383,\n",
       " '227_006_S_4357': 384,\n",
       " '229_018_S_2155': 385,\n",
       " '230_013_S_4268': 386,\n",
       " '231_021_S_4402': 387,\n",
       " '232_141_S_4438': 388,\n",
       " '233_019_S_4477': 389,\n",
       " '234_068_S_4424': 390,\n",
       " '235_141_S_4456': 391,\n",
       " '238_130_S_4417': 392,\n",
       " '239_153_S_4372': 393,\n",
       " '240_130_S_4294': 394,\n",
       " '242_021_S_4335': 395,\n",
       " '243_073_S_4360': 396,\n",
       " '244_021_S_4421': 397,\n",
       " '245_053_S_2396': 398,\n",
       " '247_032_S_0479': 399,\n",
       " '249_018_S_4313': 400,\n",
       " '250_018_S_2133': 401,\n",
       " '254_006_S_4449': 402,\n",
       " '259_072_S_4465': 403,\n",
       " '260_011_S_4547': 404,\n",
       " '262_053_S_4578': 405,\n",
       " '264_037_S_4381': 406,\n",
       " '265_041_S_4513': 407,\n",
       " '266_109_S_4455': 408,\n",
       " '267_007_S_4611': 409,\n",
       " '268_100_S_4469': 410,\n",
       " '269_022_S_4291': 411,\n",
       " '270_036_S_4562': 412,\n",
       " '271_130_S_4605': 413,\n",
       " '272_153_S_4621': 414,\n",
       " '273_130_S_4641': 415,\n",
       " '275_023_S_4502': 416,\n",
       " '282_067_S_4072': 417,\n",
       " '283_005_S_2390': 418,\n",
       " '284_023_S_4034': 419,\n",
       " '285_022_S_4196': 420,\n",
       " '286_099_S_4157': 421,\n",
       " '287_002_S_2073': 422,\n",
       " '289_128_S_2036': 423,\n",
       " '291_014_S_4263': 424,\n",
       " '292_009_S_4564': 425,\n",
       " '294_127_S_1419': 426,\n",
       " '300_073_S_2191': 427,\n",
       " '302_127_S_0260': 428,\n",
       " '307_136_S_0186': 429,\n",
       " '309_023_S_4164': 430,\n",
       " '313_068_S_4340': 431,\n",
       " '314_011_S_4278': 432,\n",
       " '315_129_S_4396': 433,\n",
       " '317_116_S_4338': 434,\n",
       " '320_130_S_4343': 435,\n",
       " '324_129_S_4371': 436,\n",
       " '326_127_S_0112': 437,\n",
       " '329_099_S_4104': 438,\n",
       " '330_014_S_4039': 439,\n",
       " '333_016_S_4121': 440,\n",
       " '337_003_S_4350': 441,\n",
       " '338_013_S_4580': 442,\n",
       " '339_126_S_4494': 443,\n",
       " '341_141_S_2210': 444,\n",
       " '343_032_S_4429': 445,\n",
       " '344_009_S_4530': 446,\n",
       " '346_002_S_4473': 447,\n",
       " '347_007_S_1206': 448,\n",
       " '348_073_S_4540': 449,\n",
       " '350_053_S_4557': 450,\n",
       " '351_036_S_4491': 451,\n",
       " '352_007_S_0101': 452,\n",
       " '353_019_S_4548': 453,\n",
       " '354_137_S_4482': 454,\n",
       " '355_082_S_4428': 455,\n",
       " '356_006_S_4363': 456,\n",
       " '357_135_S_4446': 457,\n",
       " '358_009_S_4359': 458,\n",
       " '362_018_S_4597': 459,\n",
       " '365_130_S_4589': 460,\n",
       " '366_009_S_4612': 461,\n",
       " '369_003_S_0981': 462,\n",
       " '370_007_S_4568': 463,\n",
       " '371_135_S_4598': 464,\n",
       " '372_137_S_4520': 465,\n",
       " '374_072_S_4539': 466,\n",
       " '375_073_S_4552': 467,\n",
       " '376_128_S_4603': 468,\n",
       " '377_135_S_4566': 469,\n",
       " '378_014_S_4615': 470,\n",
       " '379_037_S_4146': 471,\n",
       " '380_016_S_2007': 472,\n",
       " '381_035_S_4582': 473,\n",
       " '382_135_S_4489': 474,\n",
       " '383_007_S_4467': 475,\n",
       " '387_130_S_4405': 476,\n",
       " '388_126_S_4507': 477,\n",
       " '389_941_S_4365': 478,\n",
       " '392_130_S_4468': 479,\n",
       " '393_036_S_4430': 480,\n",
       " '394_005_S_4707': 481,\n",
       " '397_022_S_1097': 482,\n",
       " '398_041_S_4037': 483,\n",
       " '399_141_S_4053': 484,\n",
       " '401_023_S_4122': 485,\n",
       " '402_052_S_4626': 486,\n",
       " '403_023_S_4501': 487,\n",
       " '404_037_S_4071': 488,\n",
       " '405_094_S_4234': 489,\n",
       " '406_137_S_4331': 490,\n",
       " '409_032_S_4386': 491,\n",
       " '410_022_S_4266': 492,\n",
       " '411_094_S_4434': 493,\n",
       " '414_068_S_4431': 494,\n",
       " '415_007_S_4516': 495,\n",
       " '416_016_S_4584': 496,\n",
       " '417_006_S_4546': 497,\n",
       " '418_114_S_4379': 498,\n",
       " '420_116_S_4625': 499,\n",
       " '421_022_S_4444': 500,\n",
       " '422_041_S_4510': 501,\n",
       " '423_099_S_4475': 502,\n",
       " '424_037_S_4308': 503,\n",
       " '425_029_S_4385': 504,\n",
       " '426_072_S_4462': 505,\n",
       " '427_007_S_4488': 506,\n",
       " '428_002_S_4654': 507,\n",
       " '429_037_S_4432': 508,\n",
       " '430_073_S_4614': 509,\n",
       " '431_073_S_4559': 510,\n",
       " '432_136_S_4408': 511,\n",
       " '434_014_S_4668': 512,\n",
       " '435_013_S_4595': 513,\n",
       " '436_041_S_4629': 514,\n",
       " '437_128_S_4653': 515,\n",
       " '440_020_S_1288': 516,\n",
       " '442_116_S_0752': 517,\n",
       " '444_012_S_4188': 518,\n",
       " '445_021_S_4254': 519,\n",
       " '446_137_S_4299': 520,\n",
       " '447_031_S_4590': 521,\n",
       " '449_006_S_0498': 522,\n",
       " '451_072_S_2083': 523,\n",
       " '453_068_S_2184': 524,\n",
       " '455_094_S_2238': 525,\n",
       " '457_127_S_2234': 526,\n",
       " '458_031_S_2233': 527,\n",
       " '459_022_S_2263': 528,\n",
       " '461_022_S_0130': 529,\n",
       " '462_098_S_4018': 530,\n",
       " '463_072_S_4007': 531,\n",
       " '464_037_S_4015': 532,\n",
       " '465_037_S_4001': 533,\n",
       " '466_130_S_2373': 534,\n",
       " '468_002_S_4251': 535,\n",
       " '469_023_S_2068': 536,\n",
       " '470_072_S_4206': 537,\n",
       " '472_099_S_4202': 538,\n",
       " '474_129_S_4422': 539,\n",
       " '476_029_S_4327': 540,\n",
       " '477_082_S_1256': 541,\n",
       " '478_099_S_4498': 542,\n",
       " '479_006_S_4153': 543,\n",
       " '480_098_S_2079': 544,\n",
       " '481_137_S_0800': 545,\n",
       " '483_098_S_2047': 546,\n",
       " '484_941_S_4187': 547,\n",
       " '485_002_S_4225': 548,\n",
       " '487_002_S_4237': 549,\n",
       " '488_070_S_4692': 550,\n",
       " '489_018_S_4349': 551,\n",
       " '490_137_S_4303': 552,\n",
       " '491_035_S_2061': 553,\n",
       " '492_041_S_4271': 554,\n",
       " '493_135_S_4309': 555,\n",
       " '495_009_S_4388': 556,\n",
       " '498_024_S_4392': 557,\n",
       " '499_035_S_4256': 558,\n",
       " '500_098_S_0896': 559,\n",
       " '501_016_S_4353': 560,\n",
       " '503_130_S_4250': 561,\n",
       " '504_130_S_4542': 562,\n",
       " '505_003_S_0908': 563,\n",
       " '508_127_S_2213': 564,\n",
       " '509_018_S_2138': 565,\n",
       " '510_027_S_0120': 566,\n",
       " '511_128_S_2151': 567,\n",
       " '512_032_S_2247': 568,\n",
       " '513_027_S_1387': 569,\n",
       " '514_098_S_0172': 570,\n",
       " '515_014_S_2308': 571,\n",
       " '516_023_S_1190': 572,\n",
       " '517_005_S_0448': 573,\n",
       " '518_068_S_2316': 574,\n",
       " '520_007_S_4272': 575,\n",
       " '521_098_S_4275': 576,\n",
       " '522_068_S_4332': 577,\n",
       " '523_018_S_4400': 578,\n",
       " '524_072_S_4383': 579,\n",
       " '525_153_S_4297': 580,\n",
       " '526_006_S_4515': 581,\n",
       " '528_023_S_4241': 582,\n",
       " '529_016_S_4591': 583,\n",
       " '530_128_S_4553': 584,\n",
       " '531_009_S_4543': 585,\n",
       " '532_127_S_4604': 586,\n",
       " '533_127_S_4500': 587,\n",
       " '534_941_S_4420': 588,\n",
       " '535_099_S_4480': 589,\n",
       " '536_094_S_4503': 590,\n",
       " '537_098_S_4506': 591,\n",
       " '538_072_S_4522': 592,\n",
       " '539_128_S_4599': 593,\n",
       " '541_116_S_4043': 594,\n",
       " '542_073_S_0311': 595,\n",
       " '543_019_S_4285': 596,\n",
       " '544_032_S_4348': 597,\n",
       " '545_021_S_4659': 598,\n",
       " '546_027_S_2183': 599,\n",
       " '547_014_S_2185': 600,\n",
       " '548_022_S_1351': 601,\n",
       " '549_068_S_0127': 602,\n",
       " '550_068_S_0872': 603,\n",
       " '551_014_S_4401': 604,\n",
       " '552_006_S_4346': 605,\n",
       " '553_114_S_0378': 606,\n",
       " '554_141_S_4426': 607,\n",
       " '555_099_S_4463': 608,\n",
       " '556_073_S_4443': 609,\n",
       " '557_127_S_4240': 610,\n",
       " '558_094_S_4560': 611,\n",
       " '559_007_S_4620': 612,\n",
       " '560_019_S_4549': 613,\n",
       " '561_067_S_4310': 614,\n",
       " '562_141_S_4232': 615,\n",
       " '564_006_S_1130': 616,\n",
       " '565_057_S_2398': 617,\n",
       " '568_136_S_4269': 618,\n",
       " '569_126_S_4458': 619,\n",
       " '570_072_S_4445': 620,\n",
       " '571_116_S_4453': 621,\n",
       " '572_114_S_4404': 622,\n",
       " '573_072_S_4394': 623,\n",
       " '574_031_S_4474': 624,\n",
       " '575_072_S_4613': 625,\n",
       " '576_116_S_4635': 626,\n",
       " '577_127_S_4645': 627,\n",
       " '579_136_S_4433': 628,\n",
       " '581_128_S_4609': 629,\n",
       " '582_137_S_4596': 630,\n",
       " '583_141_S_2333': 631,\n",
       " '585_007_S_4637': 632,\n",
       " '588_032_S_1169': 633,\n",
       " '589_099_S_1034': 634,\n",
       " '591_116_S_4092': 635,\n",
       " '592_136_S_0107': 636,\n",
       " '594_002_S_4270': 637,\n",
       " '595_035_S_2074': 638,\n",
       " '596_127_S_4301': 639,\n",
       " '597_099_S_4205': 640,\n",
       " '598_082_S_4339': 641,\n",
       " '599_032_S_2119': 642,\n",
       " '603_009_S_4337': 643,\n",
       " '604_012_S_1212': 644,\n",
       " '605_027_S_2336': 645,\n",
       " '606_068_S_2315': 646,\n",
       " '607_022_S_1394': 647,\n",
       " '609_057_S_1007': 648,\n",
       " '610_082_S_4224': 649,\n",
       " '612_135_S_4281': 650,\n",
       " '613_130_S_4415': 651,\n",
       " '615_137_S_4536': 652,\n",
       " '616_135_S_4657': 653,\n",
       " '617_023_S_0376': 654,\n",
       " '618_012_S_4643': 655,\n",
       " '619_099_S_4565': 656,\n",
       " '623_018_S_0055': 657,\n",
       " '624_023_S_0625': 658,\n",
       " '626_021_S_2125': 659,\n",
       " '627_007_S_2106': 660,\n",
       " '630_022_S_2087': 661,\n",
       " '631_036_S_0869': 662,\n",
       " '634_033_S_1016': 663,\n",
       " '635_005_S_0546': 664,\n",
       " '636_033_S_1098': 665,\n",
       " '637_033_S_0922': 666,\n",
       " '641_072_S_2093': 667,\n",
       " '642_072_S_2037': 668,\n",
       " '643_033_S_0906': 669,\n",
       " '644_094_S_1417': 670,\n",
       " '646_005_S_0610': 671,\n",
       " '647_127_S_0925': 672,\n",
       " '648_137_S_0972': 673,\n",
       " '649_036_S_0672': 674,\n",
       " '650_128_S_2011': 675,\n",
       " '651_033_S_1116': 676,\n",
       " '652_005_S_0602': 677,\n",
       " '653_052_S_2249': 678,\n",
       " '654_035_S_2199': 679,\n",
       " '655_021_S_2150': 680,\n",
       " '656_072_S_0315': 681,\n",
       " '657_082_S_2307': 682,\n",
       " '658_002_S_1261': 683,\n",
       " '659_123_S_1300': 684,\n",
       " '660_037_S_4028': 685,\n",
       " '661_072_S_4063': 686,\n",
       " '662_036_S_1023': 687,\n",
       " '663_011_S_4075': 688,\n",
       " '665_027_S_0074': 689,\n",
       " '666_128_S_2002': 690,\n",
       " '667_072_S_2026': 691,\n",
       " '670_016_S_0359': 692,\n",
       " '671_031_S_0351': 693,\n",
       " '672_127_S_0622': 694,\n",
       " '673_014_S_0520': 695,\n",
       " '674_135_S_4676': 696,\n",
       " '675_014_S_0658': 697,\n",
       " '676_012_S_1133': 698,\n",
       " '678_128_S_2003': 699,\n",
       " '679_003_S_1074': 700,\n",
       " '680_016_S_1117': 701,\n",
       " '682_099_S_2146': 702,\n",
       " '683_037_S_0501': 703,\n",
       " '684_031_S_2022': 704,\n",
       " '687_073_S_2190': 705,\n",
       " '689_068_S_2168': 706,\n",
       " '691_037_S_0377': 707,\n",
       " '692_067_S_2195': 708,\n",
       " '695_057_S_1269': 709,\n",
       " '696_129_S_1246': 710,\n",
       " '697_031_S_4005': 711,\n",
       " '698_067_S_2304': 712,\n",
       " '699_129_S_2332': 713,\n",
       " '700_022_S_4173': 714,\n",
       " '701_006_S_4150': 715,\n",
       " '702_002_S_0685': 716,\n",
       " '703_031_S_0618': 717,\n",
       " '704_031_S_4203': 718,\n",
       " '709_003_S_4152': 719,\n",
       " '710_002_S_4171': 720,\n",
       " '711_009_S_4324': 721,\n",
       " '713_128_S_2045': 722,\n",
       " '714_009_S_0842': 723,\n",
       " '715_128_S_2220': 724,\n",
       " '716_068_S_2248': 725,\n",
       " '717_022_S_2167': 726,\n",
       " '718_094_S_4162': 727,\n",
       " '719_023_S_4035': 728,\n",
       " '721_031_S_0830': 729,\n",
       " '723_031_S_4218': 730,\n",
       " '725_127_S_4148': 731,\n",
       " '726_072_S_4103': 732,\n",
       " '727_033_S_0741': 733,\n",
       " '728_037_S_0566': 734,\n",
       " '729_024_S_4280': 735,\n",
       " '730_082_S_2121': 736,\n",
       " '731_013_S_1186': 737,\n",
       " '732_011_S_1282': 738,\n",
       " '734_036_S_0945': 739,\n",
       " '735_100_S_0069': 740,\n",
       " '736_123_S_0298': 741,\n",
       " '737_032_S_0214': 742,\n",
       " '738_041_S_4060': 743,\n",
       " '739_126_S_4686': 744,\n",
       " '740_137_S_0459': 745,\n",
       " '741_041_S_0679': 746,\n",
       " '742_072_S_4057': 747,\n",
       " '743_116_S_4195': 748,\n",
       " '744_019_S_4252': 749,\n",
       " '745_073_S_4155': 750,\n",
       " '746_002_S_4262': 751,\n",
       " '747_041_S_1260': 752,\n",
       " '748_053_S_2357': 753,\n",
       " '749_123_S_2363': 754,\n",
       " '750_099_S_0352': 755,\n",
       " '751_009_S_2381': 756,\n",
       " '752_098_S_4003': 757,\n",
       " '753_016_S_1326': 758,\n",
       " '755_126_S_2360': 759,\n",
       " '756_018_S_4696': 760,\n",
       " '757_130_S_0289': 761,\n",
       " '758_051_S_1040': 762,\n",
       " '759_031_S_4042': 763,\n",
       " '760_007_S_2394': 764,\n",
       " '761_137_S_0722': 765,\n",
       " '762_116_S_0657': 766,\n",
       " '763_100_S_0047': 767,\n",
       " '764_018_S_2180': 768,\n",
       " '765_137_S_0973': 769,\n",
       " '766_098_S_0171': 770,\n",
       " '767_131_S_0441': 771,\n",
       " '768_129_S_4073': 772,\n",
       " '769_068_S_0802': 773,\n",
       " '770_023_S_4115': 774,\n",
       " '771_037_S_0588': 775,\n",
       " '772_037_S_0150': 776,\n",
       " '773_051_S_1131': 777,\n",
       " '774_011_S_4366': 778,\n",
       " '775_072_S_2116': 779,\n",
       " '776_035_S_0555': 780,\n",
       " '777_126_S_0605': 781,\n",
       " '778_068_S_4061': 782,\n",
       " '780_033_S_4179': 783,\n",
       " '781_024_S_4158': 784,\n",
       " '782_029_S_2395': 785,\n",
       " '783_153_S_4172': 786,\n",
       " '784_005_S_4185': 787,\n",
       " '785_067_S_4212': 788,\n",
       " '787_006_S_4192': 789,\n",
       " '788_041_S_4200': 790,\n",
       " '789_128_S_0272': 791,\n",
       " '790_100_S_1286': 792,\n",
       " '791_041_S_4014': 793,\n",
       " '792_031_S_4024': 794,\n",
       " '793_052_S_0671': 795,\n",
       " '794_073_S_4216': 796,\n",
       " '795_082_S_4090': 797,\n",
       " '797_114_S_2392': 798,\n",
       " '798_041_S_4041': 799,\n",
       " '799_037_S_4214': 800,\n",
       " '800_035_S_4114': 801,\n",
       " '801_123_S_4096': 802,\n",
       " '802_005_S_4168': 803,\n",
       " '803_072_S_4131': 804,\n",
       " '804_032_S_2240': 805,\n",
       " '806_002_S_1268': 806,\n",
       " '807_021_S_0276': 807,\n",
       " '808_098_S_4050': 808,\n",
       " '809_123_S_4127': 809,\n",
       " '810_123_S_4170': 810,\n",
       " '811_099_S_0051': 811,\n",
       " '813_099_S_2042': 812,\n",
       " '814_073_S_4259': 813,\n",
       " '815_037_S_4302': 814,\n",
       " '817_082_S_4244': 815,\n",
       " '818_135_S_4356': 816,\n",
       " '101_018_S_0682': 817,\n",
       " '103_021_S_0424': 818,\n",
       " '106_006_S_0484': 819,\n",
       " '107_133_S_0629': 820,\n",
       " '108_128_S_1409': 821,\n",
       " '109_099_S_0040': 822,\n",
       " '10_005_S_1224': 823,\n",
       " '110_068_S_0442': 824,\n",
       " '114_073_S_0565': 825,\n",
       " '115_131_S_0497': 826,\n",
       " '116_033_S_0723': 827,\n",
       " '117_130_S_0449': 828,\n",
       " '118_033_S_0516': 829,\n",
       " '121_137_S_0438': 830,\n",
       " '123_018_S_0450': 831,\n",
       " '124_041_S_0721': 832,\n",
       " '126_012_S_1009': 833,\n",
       " '128_022_S_0044': 834,\n",
       " '12_010_S_0472': 835,\n",
       " '130_941_S_1311': 836,\n",
       " '131_136_S_0874': 837,\n",
       " '132_053_S_0621': 838,\n",
       " '134_029_S_1215': 839,\n",
       " '135_067_S_1185': 840,\n",
       " '136_067_S_0038': 841,\n",
       " '138_067_S_0019': 842,\n",
       " '141_007_S_0316': 843,\n",
       " '142_141_S_1152': 844,\n",
       " '143_141_S_0853': 845,\n",
       " '145_126_S_0784': 846,\n",
       " '146_100_S_0006': 847,\n",
       " '147_013_S_0575': 848,\n",
       " '153_137_S_0481': 849,\n",
       " '154_128_S_0216': 850,\n",
       " '156_128_S_0310': 851,\n",
       " '157_100_S_0190': 852,\n",
       " '158_130_S_0783': 853,\n",
       " '159_098_S_0884': 854,\n",
       " '15_099_S_0470': 855,\n",
       " '162_041_S_1002': 856,\n",
       " '163_027_S_0417': 857,\n",
       " '165_023_S_1289': 858,\n",
       " '167_033_S_1279': 859,\n",
       " '169_067_S_0110': 860,\n",
       " '16_128_S_0245': 861,\n",
       " '170_073_S_0445': 862,\n",
       " '172_072_S_1211': 863,\n",
       " '173_022_S_0544': 864,\n",
       " '176_035_S_0204': 865,\n",
       " '178_941_S_1194': 866,\n",
       " '179_007_S_0041': 867,\n",
       " '17_137_S_0825': 868,\n",
       " '180_011_S_0168': 869,\n",
       " '181_006_S_0675': 870,\n",
       " '182_016_S_1263': 871,\n",
       " '183_041_S_1423': 872,\n",
       " '184_027_S_0461': 873,\n",
       " '185_052_S_1168': 874,\n",
       " '187_126_S_0506': 875,\n",
       " '189_023_S_0963': 876,\n",
       " '18_128_S_0266': 877,\n",
       " '190_067_S_0177': 878,\n",
       " '191_029_S_1073': 879,\n",
       " '192_067_S_0290': 880,\n",
       " '194_033_S_1308': 881,\n",
       " '196_037_S_0454': 882,\n",
       " '198_126_S_1221': 883,\n",
       " '199_012_S_0634': 884,\n",
       " '19_067_S_0243': 885,\n",
       " '203_068_S_1191': 886,\n",
       " '204_136_S_0184': 887,\n",
       " '205_141_S_1024': 888,\n",
       " '206_136_S_0194': 889,\n",
       " '208_013_S_1120': 890,\n",
       " '209_137_S_0443': 891,\n",
       " '210_036_S_0673': 892,\n",
       " '211_053_S_0507': 893,\n",
       " '212_023_S_1126': 894,\n",
       " '215_116_S_0392': 895,\n",
       " '216_082_S_1119': 896,\n",
       " '217_029_S_1184': 897,\n",
       " '218_130_S_0969': 898,\n",
       " '21_016_S_1138': 899,\n",
       " '221_062_S_0730': 900,\n",
       " '222_098_S_0288': 901,\n",
       " '223_133_S_0638': 902,\n",
       " '224_027_S_0179': 903,\n",
       " '227_123_S_0050': 904,\n",
       " '228_130_S_0285': 905,\n",
       " '229_099_S_0534': 906,\n",
       " '230_002_S_0782': 907,\n",
       " '231_067_S_0029': 908,\n",
       " '232_007_S_1339': 909,\n",
       " '234_006_S_0653': 910,\n",
       " '238_023_S_0139': 911,\n",
       " '239_029_S_1384': 912,\n",
       " '240_027_S_1082': 913,\n",
       " '241_128_S_0500': 914,\n",
       " '244_057_S_0957': 915,\n",
       " '246_082_S_0304': 916,\n",
       " '248_141_S_0810': 917,\n",
       " '249_041_S_1391': 918,\n",
       " '24_007_S_0070': 919,\n",
       " '250_016_S_0590': 920,\n",
       " '251_007_S_0414': 921,\n",
       " '253_007_S_0249': 922,\n",
       " '255_031_S_0321': 923,\n",
       " '256_082_S_0363': 924,\n",
       " '257_062_S_0690': 925,\n",
       " '258_007_S_1248': 926,\n",
       " '259_011_S_0861': 927,\n",
       " '25_133_S_1170': 928,\n",
       " '262_052_S_1251': 929,\n",
       " '263_072_S_1380': 930,\n",
       " '265_141_S_0726': 931,\n",
       " '267_130_S_0102': 932,\n",
       " '268_141_S_1004': 933,\n",
       " '269_130_S_0423': 934,\n",
       " '26_128_S_0522': 935,\n",
       " '271_082_S_1079': 936,\n",
       " '272_141_S_1231': 937,\n",
       " '273_062_S_0768': 938,\n",
       " '274_136_S_0195': 939,\n",
       " '275_018_S_0087': 940,\n",
       " '277_018_S_0335': 941,\n",
       " '279_016_S_0769': 942,\n",
       " '27_141_S_1245': 943,\n",
       " '281_141_S_1051': 944,\n",
       " '282_022_S_0066': 945,\n",
       " '285_062_S_1294': 946,\n",
       " '286_100_S_0747': 947,\n",
       " '287_136_S_0429': 948,\n",
       " '289_023_S_0126': 949,\n",
       " '290_941_S_1363': 950,\n",
       " '291_031_S_1209': 951,\n",
       " '292_037_S_0627': 952,\n",
       " '294_036_S_0976': 953,\n",
       " '296_029_S_0914': 954,\n",
       " '297_073_S_0312': 955,\n",
       " '298_021_S_0178': 956,\n",
       " '299_021_S_0647': 957,\n",
       " '29_007_S_1304': 958,\n",
       " '2_005_S_1341': 959,\n",
       " '300_021_S_0332': 960,\n",
       " '301_027_S_0850': 961,\n",
       " '302_131_S_0319': 962,\n",
       " '303_032_S_1101': 963,\n",
       " '304_002_S_0559': 964,\n",
       " '305_032_S_0677': 965,\n",
       " '309_041_S_1411': 966,\n",
       " '310_137_S_0841': 967,\n",
       " '311_013_S_1276': 968,\n",
       " '312_029_S_0999': 969,\n",
       " '313_022_S_0543': 970,\n",
       " '314_082_S_0469': 971,\n",
       " '315_012_S_1292': 972,\n",
       " '316_082_S_1377': 973,\n",
       " '319_002_S_0413': 974,\n",
       " '31_006_S_0547': 975,\n",
       " '320_032_S_0718': 976,\n",
       " '321_141_S_1244': 977,\n",
       " '323_126_S_0891': 978,\n",
       " '324_013_S_1205': 979,\n",
       " '325_005_S_0222': 980,\n",
       " '32_009_S_0751': 981,\n",
       " '330_099_S_0551': 982,\n",
       " '333_002_S_0295': 983,\n",
       " '334_100_S_1154': 984,\n",
       " '336_128_S_0188': 985,\n",
       " '337_027_S_1213': 986,\n",
       " '339_029_S_1318': 987,\n",
       " '33_123_S_0390': 988,\n",
       " '341_037_S_0327': 989,\n",
       " '342_033_S_1284': 990,\n",
       " '343_068_S_0476': 991,\n",
       " '344_029_S_1056': 992,\n",
       " '345_067_S_0045': 993,\n",
       " '348_023_S_0078': 994,\n",
       " '349_100_S_0015': 995,\n",
       " '350_012_S_0689': 996,\n",
       " '352_114_S_0979': 997,\n",
       " '353_128_S_1406': 998,\n",
       " '354_137_S_1041': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "GWAS_ID = 'ukb-b-14057'\n",
    "usable_samples_ADNI = pd.read_csv(f'./PRSice_output/{GWAS_ID}/{GWAS_ID}.best', ' ')['IID'].to_numpy().tolist()\n",
    "usable_samples_ADNI = {sample:idx for idx,sample in enumerate(usable_samples_ADNI)}\n",
    "json.dump(usable_samples_ADNI, open('./usable_samples_ADNI.json', 'w'))\n",
    "# json.dump(usable_samples_ADNI, open(inputFolder+'usable_samples_ADNI.json', 'w'))\n",
    "\n",
    "usable_samples_ADNI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ukb-b-13806', 'ukb-d-20405_0', 'ukb-d-20405_1', 'ukb-d-20405_2', 'met-d-Total_C', 'ieu-b-109', 'ieu-b-110', 'ieu-b-111', 'ieu-b-25', 'ieu-b-38', 'ieu-b-39', 'ukb-a-257', 'ukb-b-12064', 'ukb-b-17627', 'ukb-b-18275', 'ukb-b-19953', 'ukb-b-2209', 'ukb-b-3957', 'ukb-b-4424', 'ukb-b-6134', 'ukb-b-6324', 'ukb-b-7663', 'ukb-b-770', 'ukb-b-8476', 'ukb-b-323', 'ukb-b-14699', 'ukb-b-14180', 'ukb-b-17243', 'ukb-b-6358', 'ukb-b-17006', 'ukb-b-5779', 'ukb-b-15541', 'ukb-b-19732', 'ukb-b-20289', 'ukb-b-14057', 'ukb-b-12963', 'ukb-b-12417', 'ukb-b-11495', 'ukb-b-12493']\n"
     ]
    }
   ],
   "source": [
    "ALL_GWAS_IDS = [key for key in base_files]\n",
    "print(ALL_GWAS_IDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ukb-b-13806 : Non-cancer illness code, self-reported: type 2 diabetes\n",
      "ukb-d-20405_0 : Ever had known person concerned about, or recommend reduction of, alcohol consumption: No\n",
      "ukb-d-20405_1 : Ever had known person concerned about, or recommend reduction of, alcohol consumption: Yes, but not in the last year\n",
      "ukb-d-20405_2 : Ever had known person concerned about, or recommend reduction of, alcohol consumption: Yes, during the last year\n",
      "met-d-Total_C : Total cholesterol\n",
      "ieu-b-109 : HDL cholesterol\n",
      "ieu-b-110 : LDL cholesterol\n",
      "ieu-b-111 : triglycerides\n",
      "ieu-b-25 : Cigarettes per Day\n",
      "ieu-b-38 : systolic blood pressure\n",
      "ieu-b-39 : diastolic blood pressure\n",
      "ukb-a-257 : Hearing difficulty/problems: Yes\n",
      "ukb-b-12064 : Non-cancer illness code, self-reported: depression\n",
      "ukb-b-17627 : Non-oily fish intake\n",
      "ukb-b-18275 : Hearing difficulty/problems with background noise\n",
      "ukb-b-19953 : Body mass index (BMI)\n",
      "ukb-b-2209 : Oily fish intake\n",
      "ukb-b-3957 : Sleeplessness / insomnia\n",
      "ukb-b-4424 : Sleep duration\n",
      "ukb-b-6134 : Age completed full time education\n",
      "ukb-b-6324 : Processed meat intake\n",
      "ukb-b-7663 : Types of physical activity in last 4 weeks: Strenuous sports\n",
      "ukb-b-770 : Other meat intake\n",
      "ukb-b-8476 : Loneliness, isolation\n",
      "ukb-b-323 : Illnesses of father: Alzheimer's disease/dementia\n",
      "ukb-b-14699 : Illnesses of mother: Alzheimer's disease/dementia\n",
      "ukb-b-14180 : Mood swings\n",
      "ukb-b-17243 : Non-cancer illness code, self-reported: anxiety/panic attacks\n",
      "ukb-b-6358 : Non-cancer illness code, self-reported: stroke\n",
      "ukb-b-17006 : Non-cancer illness code, self-reported: head injury\n",
      "ukb-b-5779 : Alcohol intake frequency\n",
      "ukb-b-15541 : Diagnoses - secondary ICD10: E66.9 Obesity, unspecified\n",
      "ukb-b-19732 : Non-cancer illness code, self-reported: hypothyroidism/myxoedema\n",
      "ukb-b-20289 : Non-cancer illness code, self-reported: hyperthyroidism/thyrotoxicosis\n",
      "ukb-b-14057 : Non-cancer illness code, self-reported: hypertension\n",
      "ukb-b-12963 : Particulate matter air pollution 2.5-10um; 2010\n",
      "ukb-b-12417 : Nitrogen oxides air pollution; 2010\n",
      "ukb-b-11495 : Types of physical activity in last 4 weeks: Light DIY (eg: pruning, watering the lawn)\n",
      "ukb-b-12493 : Diagnoses - secondary ICD10: I10 Essential (primary) hypertension\n",
      "['Non-cancer illness code, self-reported: type 2 diabetes', 'Ever had known person concerned about, or recommend reduction of, alcohol consumption: No', 'Ever had known person concerned about, or recommend reduction of, alcohol consumption: Yes, but not in the last year', 'Ever had known person concerned about, or recommend reduction of, alcohol consumption: Yes, during the last year', 'Total cholesterol', 'HDL cholesterol', 'LDL cholesterol', 'triglycerides', 'Cigarettes per Day', 'systolic blood pressure', 'diastolic blood pressure', 'Hearing difficulty/problems: Yes', 'Non-cancer illness code, self-reported: depression', 'Non-oily fish intake', 'Hearing difficulty/problems with background noise', 'Body mass index (BMI)', 'Oily fish intake', 'Sleeplessness / insomnia', 'Sleep duration', 'Age completed full time education', 'Processed meat intake', 'Types of physical activity in last 4 weeks: Strenuous sports', 'Other meat intake', 'Loneliness, isolation', \"Illnesses of father: Alzheimer's disease/dementia\", \"Illnesses of mother: Alzheimer's disease/dementia\", 'Mood swings', 'Non-cancer illness code, self-reported: anxiety/panic attacks', 'Non-cancer illness code, self-reported: stroke', 'Non-cancer illness code, self-reported: head injury', 'Alcohol intake frequency', 'Diagnoses - secondary ICD10: E66.9 Obesity, unspecified', 'Non-cancer illness code, self-reported: hypothyroidism/myxoedema', 'Non-cancer illness code, self-reported: hyperthyroidism/thyrotoxicosis', 'Non-cancer illness code, self-reported: hypertension', 'Particulate matter air pollution 2.5-10um; 2010', 'Nitrogen oxides air pollution; 2010', 'Types of physical activity in last 4 weeks: Light DIY (eg: pruning, watering the lawn)', 'Diagnoses - secondary ICD10: I10 Essential (primary) hypertension']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('GWAS_datasets_to_consider.xlsx', engine='openpyxl')[['GWAS_ID', 'Trait', 'Category']]\n",
    "all_traits = []\n",
    "for GWAS_ID in ALL_GWAS_IDS:\n",
    "    trait = str(df[df['GWAS_ID'] == GWAS_ID]['Trait'].to_numpy()[0])\n",
    "    print(GWAS_ID, ':', trait)\n",
    "    all_traits += [trait]\n",
    "print(all_traits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this is for demo purpose\n",
    "# prsice_command = f'Rscript ./PRSice_linux/PRSice.R --dir ./PRSice_linux\t\\\n",
    "# --prsice ./PRSice_linux/PRSice_linux     \\\n",
    "# --base ./PRSice_linux/simple_table_with_pval.txt     \\\n",
    "# --target ./PRSice_linux/ADNI_plink     \\\n",
    "# --thread 1     \\\n",
    "# --beta     \\\n",
    "# --binary-target F\t\\\n",
    "# --out ./PRSice_output/PRSice\t\\\n",
    "# --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat UKB-b-6134:ES --pvalue PVAL_generated_from_LP\t\\\n",
    "# --extract ./PRSice_output/PRSice.valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     # this is for demo purpose\n",
    "#     import os\n",
    "#     return_status = os.system(prsice_command) # generate the file named {GWAS_ID}.valid\n",
    "#     print('1a:', return_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ad_venv_2",
   "language": "python",
   "name": "ad_venv_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
