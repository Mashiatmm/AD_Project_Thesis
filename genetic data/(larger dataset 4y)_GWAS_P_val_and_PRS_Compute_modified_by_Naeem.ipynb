{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFolder=\"\"\n",
    "folderCounter=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '_io.TextIOWrapper'>\n",
      "0 :\t CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tUKB-b-6134:ES\tUKB-b-6134:SE\tUKB-b-6134:LP\tUKB-b-6134:AF\tUKB-b-6134:SS\tUKB-b-6134:EZ\tUKB-b-6134:SI\tUKB-b-6134:NC\tUKB-b-6134:ID\n",
      "\n",
      "1 :\t 1\t49298\trs10399793\tT\tC\t.\tPASS\t0.623238\t0.0017795\t0.00366743\t0.200659\t0.623238\t.\t.\t.\t.\trs10399793\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# debug cell\n",
    "with open('simple_table.txt', 'r') as f:\n",
    "    print(type(f))\n",
    "    cnt = 2\n",
    "    for i,line in enumerate(f):\n",
    "        print(i, ':\\t', line)\n",
    "        cnt -= 1\n",
    "        if cnt == 0:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './ukb-b-6134.vcf.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# debug cell\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgzip\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mgzip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./ukb-b-6134.vcf.gz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(f)\n",
      "File \u001b[0;32m~/anaconda3/envs/ad_venv/lib/python3.9/gzip.py:58\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(filename, mode, compresslevel, encoding, errors, newline)\u001b[0m\n\u001b[1;32m     56\u001b[0m gz_mode \u001b[38;5;241m=\u001b[39m mode\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filename, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike)):\n\u001b[0;32m---> 58\u001b[0m     binary_file \u001b[38;5;241m=\u001b[39m \u001b[43mGzipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgz_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompresslevel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwrite\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     60\u001b[0m     binary_file \u001b[38;5;241m=\u001b[39m GzipFile(\u001b[38;5;28;01mNone\u001b[39;00m, gz_mode, compresslevel, filename)\n",
      "File \u001b[0;32m~/anaconda3/envs/ad_venv/lib/python3.9/gzip.py:173\u001b[0m, in \u001b[0;36mGzipFile.__init__\u001b[0;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[1;32m    171\u001b[0m     mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fileobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     fileobj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmyfileobj \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    175\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fileobj, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './ukb-b-6134.vcf.gz'"
     ]
    }
   ],
   "source": [
    "# debug cell\n",
    "import gzip\n",
    "with gzip.open('./ukb-b-6134.vcf.gz') as f:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import time\n",
    "import gzip\n",
    "import shutil\n",
    "\n",
    "def generate_gwas_output_as_tsv_file(inVCF_File, writeFile=None):\n",
    "    root = './tabular_format_gwas_data/'\n",
    "    t0 = time.time()\n",
    "    if writeFile is None:\n",
    "        writeFile = root + inVCF_File.split('/')[-1].split('.')[0] + '.tsv'\n",
    "    \n",
    "    print(\"Processing:\", inVCF_File)\n",
    "    if \".gz\" == inVCF_File[-3:]:\n",
    "        with gzip.open(inVCF_File, 'rb') as f_in:\n",
    "            with open(root+'temp_vcf.vcf', 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "        inVCF_File = root+'temp_vcf.vcf'\n",
    "    print(\"gzip open done :\", inVCF_File)\n",
    "    \"\"\"\n",
    "    Convert all the VCF into simplified tsv format\n",
    "    Source: https://github.com/everestial/VCF-simplify#table-of-contents\n",
    "    python3 ./VCF-Simplify/VCF-Simplify/VcfSimplify.py SimplifyVCF -toType table -inVCF ./ukb-b-6134.vcf -outFile ./simple_table.txt\n",
    "    \"\"\"\n",
    "    vcf_simplify_path = \"./VCF-Simplify/VCF-Simplify/VcfSimplify.py\"\n",
    "    out_File = root+'temp_table.tsv'\n",
    "    os.system(f\"python3 {vcf_simplify_path} SimplifyVCF -toType table -inVCF {inVCF_File} -outFile {out_File}\")\n",
    "    print(writeFile)\n",
    "        \n",
    "    f_read = open(out_File, 'r')\n",
    "    f_write = open(writeFile, 'w')\n",
    "    cnt = 0\n",
    "    for line in f_read:\n",
    "#         print(line)\n",
    "        newliner = ''\n",
    "        if '\\n' == line[-1]:\n",
    "            newliner = '\\n'\n",
    "            line = line.strip()\n",
    "        if 'CHROM' in line:\n",
    "            line = line.upper() + '\\tPVAL_generated_from_LP'\n",
    "        else:\n",
    "            LP = float(line.split('\\t')[10])\n",
    "#             LP = float(line.split('\\t')[14])\n",
    "            #find out LP column from the tsv file\n",
    "            \n",
    "            p_val = str(10**(-1 * LP))\n",
    "            line = line + '\\t' + p_val\n",
    "        line = line + newliner\n",
    "    #     print(line)\n",
    "        f_write.write(line)\n",
    "        cnt += 1\n",
    "    #     if cnt == 20: break\n",
    "\n",
    "    f_read.close()\n",
    "    f_write.close()\n",
    "    print(f'Total SNPs: {cnt} | Total exec time: {time.time() - t0} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: ./tabular_format_gwas_data/ukb-b-12963.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'UKB-b-12963:ES', 'UKB-b-12963:SE', 'UKB-b-12963:LP', 'UKB-b-12963:AF', 'UKB-b-12963:SS', 'UKB-b-12963:EZ', 'UKB-b-12963:SI', 'UKB-b-12963:NC', 'UKB-b-12963:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "elapsed time:  144.3343071937561\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 11,564, after: 11,820, consumed: 256; exec time: 144.36314964294434 seconds\n",
      "./tabular_format_gwas_data/ukb-b-12963.tsv\n",
      "Total SNPs: 9851867 | Total exec time: 215.63963747024536 seconds\n",
      "Processing: ./tabular_format_gwas_data/ukb-b-12417.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'UKB-b-12417:ES', 'UKB-b-12417:SE', 'UKB-b-12417:LP', 'UKB-b-12417:AF', 'UKB-b-12417:SS', 'UKB-b-12417:EZ', 'UKB-b-12417:SI', 'UKB-b-12417:NC', 'UKB-b-12417:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "elapsed time:  153.066552400589\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 11,532, after: 11,788, consumed: 256; exec time: 153.07559728622437 seconds\n",
      "./tabular_format_gwas_data/ukb-b-12417.tsv\n",
      "Total SNPs: 9851867 | Total exec time: 235.14553308486938 seconds\n",
      "Processing: ./tabular_format_gwas_data/ukb-b-11495.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'UKB-b-11495:ES', 'UKB-b-11495:SE', 'UKB-b-11495:LP', 'UKB-b-11495:AF', 'UKB-b-11495:SS', 'UKB-b-11495:EZ', 'UKB-b-11495:SI', 'UKB-b-11495:NC', 'UKB-b-11495:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "elapsed time:  160.59958386421204\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 11,512, after: 11,512, consumed: 0; exec time: 160.64053750038147 seconds\n",
      "./tabular_format_gwas_data/ukb-b-11495.tsv\n",
      "Total SNPs: 9606173 | Total exec time: 236.42789435386658 seconds\n",
      "Processing: ./tabular_format_gwas_data/ukb-b-12493.vcf.gz\n",
      "gzip open done : ./tabular_format_gwas_data/temp_vcf.vcf\n",
      "    ## VCF Simplify ## : Python application for parsing VCF files.\n",
      "    Author: Bishwa K. Giri\n",
      "    Contributors: Bhuwan Aryal\n",
      "    Contact: bkgiri@uncg.edu, kirannbishwa01@gmail.com, bhuwanaryal19@gmail.com\n",
      "\n",
      "Using the following arguments: \n",
      "Namespace(toType=['table'], inVCF='./tabular_format_gwas_data/temp_vcf.vcf', outFile='./tabular_format_gwas_data/temp_table.tsv', outHeaderName=None, GTbase=['GT:numeric'], PG='PG', PI='PI', includeUnphased='0', samples='all', preHeader=['all'], infos=['all'], formats=['all'], mode='0')\n",
      "\n",
      "Using option \"SimplifyVCF\"\n",
      "  Simplifying the VCF records ...\n",
      "1 samples found\n",
      "\n",
      "Skipping the header.\n",
      "\n",
      "Writing table in a wide format.\n",
      "\n",
      "sample genotypes tag 'GT' are written as 'numeric' bases\n",
      "\n",
      "- Output header of the simplified VCF file:\n",
      "['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO:AF', 'UKB-b-12493:ES', 'UKB-b-12493:SE', 'UKB-b-12493:LP', 'UKB-b-12493:AF', 'UKB-b-12493:SS', 'UKB-b-12493:EZ', 'UKB-b-12493:SI', 'UKB-b-12493:NC', 'UKB-b-12493:ID']\n",
      "\n",
      "Reading the input vcf file ... \n",
      "\n",
      "Contig 1 is being processed ... \n",
      "\n",
      "Contig 2 is being processed ... \n",
      "\n",
      "Contig 3 is being processed ... \n",
      "\n",
      "Contig 4 is being processed ... \n",
      "\n",
      "Contig 5 is being processed ... \n",
      "\n",
      "Contig 6 is being processed ... \n",
      "\n",
      "Contig 7 is being processed ... \n",
      "\n",
      "Contig 8 is being processed ... \n",
      "\n",
      "Contig 9 is being processed ... \n",
      "\n",
      "Contig 10 is being processed ... \n",
      "\n",
      "Contig 11 is being processed ... \n",
      "\n",
      "Contig 12 is being processed ... \n",
      "\n",
      "Contig 13 is being processed ... \n",
      "\n",
      "Contig 14 is being processed ... \n",
      "\n",
      "Contig 15 is being processed ... \n",
      "\n",
      "Contig 16 is being processed ... \n",
      "\n",
      "Contig 17 is being processed ... \n",
      "\n",
      "Contig 18 is being processed ... \n",
      "\n",
      "Contig 19 is being processed ... \n",
      "\n",
      "Contig 20 is being processed ... \n",
      "\n",
      "Contig 21 is being processed ... \n",
      "\n",
      "Contig 22 is being processed ... \n",
      "\n",
      "elapsed time:  126.28700041770935\n",
      "Completed converting the VCF file to table output.\n",
      "fnc_vcf_to_table: memory before: 11,620, after: 11,872, consumed: 252; exec time: 126.29191613197327 seconds\n",
      "./tabular_format_gwas_data/ukb-b-12493.tsv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total SNPs: 8361395 | Total exec time: 192.67844223976135 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "generate_gwas_output_as_tsv_file(inVCF_File='./tabular_format_gwas_data/ukb-b-12963.vcf.gz', writeFile=None)\n",
    "generate_gwas_output_as_tsv_file(inVCF_File='./tabular_format_gwas_data/ukb-b-12417.vcf.gz', writeFile=None)\n",
    "generate_gwas_output_as_tsv_file(inVCF_File='./tabular_format_gwas_data/ukb-b-11495.vcf.gz', writeFile=None)\n",
    "generate_gwas_output_as_tsv_file(inVCF_File='./tabular_format_gwas_data/ukb-b-12493.vcf.gz', writeFile=None)\n",
    "# generate_gwas_output_as_tsv_file(inVCF_File='./tabular_format_gwas_data/ukb-b-19732.vcf.gz', writeFile=None)\n",
    "# generate_gwas_output_as_tsv_file(inVCF_File='./tabular_format_gwas_data/ukb-b-17006.vcf.gz', writeFile=None)\n",
    "# generate_gwas_output_as_tsv_file(inVCF_File='./tabular_format_gwas_data/ukb-b-5779.vcf.gz', writeFile=None)\n",
    "# generate_gwas_output_as_tsv_file(inVCF_File='./tabular_format_gwas_data/ukb-b-15541.vcf.gz', writeFile=None)\n",
    "# need to just specify the file path here\n",
    "# ebi-a-GCST005920.vcf.gz\n",
    "# ebi-a-GCST005923.vcf.gz\n",
    "# ukb-b-14699.vcf.gz\n",
    "# ukb-b-323.vcf.gz\n",
    "# ukb-b-6358\n",
    "# next update in the 'GWAS_datasets_to_consider.xlsx'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ' abc def\\n'.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10**(-1*0.200659) #0.6300007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %pip install openpyxl\n",
    "import pandas as pd\n",
    "\n",
    "category_map = {\n",
    "    'Continuous' : 'beta', \n",
    "    'Categorical Ordered (assumed continuous)': 'beta',\n",
    "    'Binary': 'or',\n",
    "    'NA (Possibly binary)': 'or'\n",
    "}\n",
    "\n",
    "\n",
    "df = pd.read_excel('GWAS_datasets_to_consider.xlsx', engine='openpyxl')[['GWAS_ID', 'Trait', 'Category']]\n",
    "# print(df)\n",
    "# print(df['Category'].unique())\n",
    "# GWAS_ID = 'ieu-b-111'\n",
    "# category = category_map[df[df['GWAS_ID'] == GWAS_ID].to_numpy()[0, 2]] \n",
    "# category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "['ukb-b-13806', 'ukb-d-20405_0', 'ukb-d-20405_1', 'ukb-d-20405_2', 'met-d-Total_C', 'ieu-b-109', 'ieu-b-110', 'ieu-b-111', 'ieu-b-25', 'ieu-b-38', 'ieu-b-39', 'ukb-a-257', 'ukb-b-12064', 'ukb-b-17627', 'ukb-b-18275', 'ukb-b-19953', 'ukb-b-2209', 'ukb-b-3957', 'ukb-b-4424', 'ukb-b-6134', 'ukb-b-6324', 'ukb-b-7663', 'ukb-b-770', 'ukb-b-8476', 'ukb-b-323', 'ukb-b-14699', 'ukb-b-14180', 'ukb-b-17243', 'ukb-b-6358', 'ukb-b-17006', 'ukb-b-5779', 'ukb-b-15541', 'ukb-b-19732', 'ukb-b-20289', 'ukb-b-14057', 'ukb-b-12963', 'ukb-b-12417', 'ukb-b-11495', 'ukb-b-12493']\n",
      "{'ukb-b-13806': 'or', 'ukb-d-20405_0': 'or', 'ukb-d-20405_1': 'or', 'ukb-d-20405_2': 'or', 'met-d-Total_C': 'beta', 'ieu-b-109': 'beta', 'ieu-b-110': 'beta', 'ieu-b-111': 'beta', 'ieu-b-25': 'beta', 'ieu-b-38': 'beta', 'ieu-b-39': 'beta', 'ukb-a-257': 'or', 'ukb-b-12064': 'or', 'ukb-b-17627': 'beta', 'ukb-b-18275': 'or', 'ukb-b-19953': 'beta', 'ukb-b-2209': 'beta', 'ukb-b-3957': 'beta', 'ukb-b-4424': 'beta', 'ukb-b-6134': 'beta', 'ukb-b-6324': 'beta', 'ukb-b-7663': 'or', 'ukb-b-770': 'beta', 'ukb-b-8476': 'or', 'ukb-b-323': 'or', 'ukb-b-14699': 'or', 'ukb-b-14180': 'or', 'ukb-b-17243': 'or', 'ukb-b-6358': 'or', 'ukb-b-17006': 'or', 'ukb-b-5779': 'beta', 'ukb-b-15541': 'or', 'ukb-b-19732': 'or', 'ukb-b-20289': 'or', 'ukb-b-14057': 'or', 'ukb-b-12963': 'beta', 'ukb-b-12417': 'beta', 'ukb-b-11495': 'or', 'ukb-b-12493': 'or'}\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "# df = pd.read_excel('GWAS_datasets_to_consider.xlsx', engine='openpyxl')[['GWAS_ID', 'Trait', 'Category']]\n",
    "# all_gwas_vcf_files = glob('/mnt/c/Users/HP/Downloads/Compressed/GWAS/*')\n",
    "# ROOT = '/mnt/c/Users/HP/Downloads/Compressed/GWAS/'\n",
    "# ALL_GWAS_IDS = list(set(df['GWAS_ID'].to_numpy().tolist()) - {'bbj-a-46', 'bbj-a-78', 'ieu-a-1283', 'ukb-a-257','ukb-b-2209','ukb-b-17627','ieub-109','ieu-b-110','ieu-b-111','met-d-Total_C'})\n",
    "# bbj-a-78,ukb-a-257,bbj-a-46\n",
    "# ALL_GWAS_IDS = list(set(df['GWAS_ID'].to_numpy().tolist()) - { 'ieu-a-1283','bbj-a-46', 'bbj-a-78'})\n",
    "# ALL_GWAS_IDS = list(set(df['GWAS_ID'].to_numpy().tolist()) - {  'ieu-b-109','ieu-b-110','ieu-b-111','met-d-Total_C','ukb-b-2209','ukb-b-17627','ukb-a-257','ieu-a-1283','bbj-a-46', 'bbj-a-78','ukb-b-14180','ukb-b-13806','ukb-b-12064','ukb-b-323','ukb-b-14699','ukb-b-14699','ukb-b-5779'})\n",
    "ALL_GWAS_IDS = list(df['GWAS_ID'].to_numpy().tolist()) \n",
    "\n",
    "print(len(ALL_GWAS_IDS))\n",
    "print(ALL_GWAS_IDS)\n",
    "\n",
    "# ALL_GWAS_IDS = list(set(df['GWAS_ID'].to_numpy().tolist()) - {})\n",
    "\n",
    "# ukb-b-323\n",
    "# ukb-b-14699\n",
    "\n",
    "# ukb-b-17243\n",
    "# ukb-b-6358\n",
    "# ukb-b-17006\n",
    "# ukb-b-5779\n",
    "# ukb-b-15541\n",
    "# ukb-b-20289\n",
    "# ukb-b-19732\n",
    "\n",
    "base_files = {}\n",
    "\n",
    "# base_files=[] #naeem mod\n",
    "for GWAS_ID in ALL_GWAS_IDS:\n",
    "    \n",
    "#     file = ROOT + GWAS_ID + '.vcf.gz'\n",
    "#     base_files[GWAS_ID] = category_map[df[df['GWAS_ID'] == GWAS_ID].to_numpy()[0, 2]]\n",
    "    base_files[GWAS_ID] = df[df['GWAS_ID'] == GWAS_ID].to_numpy()[0, 2]\n",
    "#     base_files[GWAS_ID]=category_map[base_files[GWAS_ID]]\n",
    "    \n",
    "print(base_files)\n",
    "#     generate_gwas_output_as_tsv_file(inVCF_File=file, writeFile=None)\n",
    "# print(name_mapping)\n",
    "# print(name_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ukb-b-13806': 'or', 'ukb-d-20405_0': 'or', 'ukb-d-20405_1': 'or', 'ukb-d-20405_2': 'or', 'met-d-Total_C': 'beta', 'ieu-b-109': 'beta', 'ieu-b-110': 'beta', 'ieu-b-111': 'beta', 'ieu-b-25': 'beta', 'ieu-b-38': 'beta', 'ieu-b-39': 'beta', 'ukb-a-257': 'or', 'ukb-b-12064': 'or', 'ukb-b-17627': 'beta', 'ukb-b-18275': 'or', 'ukb-b-19953': 'beta', 'ukb-b-2209': 'beta', 'ukb-b-3957': 'beta', 'ukb-b-4424': 'beta', 'ukb-b-6134': 'beta', 'ukb-b-6324': 'beta', 'ukb-b-7663': 'or', 'ukb-b-770': 'beta', 'ukb-b-8476': 'or', 'ukb-b-323': 'or', 'ukb-b-14699': 'or', 'ukb-b-14180': 'or', 'ukb-b-17243': 'or', 'ukb-b-6358': 'or', 'ukb-b-17006': 'or', 'ukb-b-5779': 'beta', 'ukb-b-15541': 'or', 'ukb-b-19732': 'or', 'ukb-b-20289': 'or', 'ukb-b-14057': 'or', 'ukb-b-12963': 'beta', 'ukb-b-12417': 'beta', 'ukb-b-11495': 'or', 'ukb-b-12493': 'or'}\n",
      "ukb-b-13806\n",
      "ukb-d-20405_0\n",
      "ukb-d-20405_1\n",
      "ukb-d-20405_2\n",
      "met-d-Total_C\n",
      "ieu-b-109\n",
      "ieu-b-110\n",
      "ieu-b-111\n",
      "ieu-b-25\n",
      "ieu-b-38\n",
      "ieu-b-39\n",
      "ukb-a-257\n",
      "ukb-b-12064\n",
      "ukb-b-17627\n",
      "ukb-b-18275\n",
      "ukb-b-19953\n",
      "ukb-b-2209\n",
      "ukb-b-3957\n",
      "ukb-b-4424\n",
      "ukb-b-6134\n",
      "ukb-b-6324\n",
      "ukb-b-7663\n",
      "ukb-b-770\n",
      "ukb-b-8476\n",
      "ukb-b-323\n",
      "ukb-b-14699\n",
      "ukb-b-14180\n",
      "ukb-b-17243\n",
      "ukb-b-6358\n",
      "ukb-b-17006\n",
      "ukb-b-5779\n",
      "ukb-b-15541\n",
      "ukb-b-19732\n",
      "ukb-b-20289\n",
      "ukb-b-14057\n",
      "ukb-b-12963\n",
      "ukb-b-12417\n",
      "ukb-b-11495\n",
      "ukb-b-12493\n"
     ]
    }
   ],
   "source": [
    "# base_files\n",
    "print(base_files)\n",
    "for GWAS_ID in base_files:\n",
    "    print(GWAS_ID)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5175/1785225935.py:2: DtypeWarning: Columns (18,19,20,103,104) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ADNIMERGE = pd.read_csv('ADNIMERGE.csv')\n"
     ]
    }
   ],
   "source": [
    "gender_map = {'Female': 0,'Male': 1}\n",
    "ADNIMERGE = pd.read_csv('ADNIMERGE.csv')\n",
    "def get_gender_and_age(PTID):\n",
    "    gender = ADNIMERGE[ADNIMERGE['PTID'] == PTID]['PTGENDER'].dropna().unique()[0]\n",
    "    age = ADNIMERGE[ADNIMERGE['PTID'] == PTID]['AGE'].dropna().unique()[0]\n",
    "    return str(gender_map[gender]) + ' ' + str(age)\n",
    "\n",
    "# NUM_TRAINING_SAMPLES = int(830 * .7)\n",
    "# print('NUM_TRAINING_SAMPLES:', NUM_TRAINING_SAMPLES)\n",
    "# f_writable = open('./COVAR_FILE.txt', 'w')\n",
    "# f_TRAINING_SAMPLES = open('./TRAINING_SAMPLES.txt', 'w')\n",
    "# with open('/mnt/c/Users/HP/Documents/GWA_tutorial/2_Population_stratification/covar_mds.txt') as f:\n",
    "#     for i, line in enumerate(f):\n",
    "#         if 'FID IID' in line:\n",
    "#             line = line[:-1] + ' GENDER AGE\\n'\n",
    "#         else:\n",
    "#             line = line[:-1] + ' ' + get_gender_and_age(PTID=line.split(' ')[1]) + '\\n'\n",
    "#         if i < NUM_TRAINING_SAMPLES:\n",
    "#             f_TRAINING_SAMPLES.write(' '.join(line.split(' ')[:2])+'\\n')\n",
    "#         f_writable.write(line)\n",
    "# #         print(line)\n",
    "# f_writable.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_prsice(GWAS_ID, redo=False):\n",
    "#     TARGET_DATA = '/mnt/c/Users/HP/Documents/GWA_tutorial/2_Population_stratification/ADNI' # old and smaller dataset\n",
    "    #jei data diye ultimate train kora hocche model e\n",
    "    #larger dataset er protita data er jnno protita trait er prscore ber kora hocche\n",
    "    TARGET_DATA = '../larger_dataset/larger_dataset' # new and larger dataset\n",
    "    '''\n",
    "    return_status --> 0: success | 256: Error. Execusion Halted | 2: \n",
    "    '''\n",
    "#     need to alter between these two if needed\n",
    "    if os.path.isfile(f'./PRSice_output/{GWAS_ID}/'):\n",
    "#     if True:\n",
    "        return_status = os.system(f'mkdir ./PRSice_output/{GWAS_ID}/')\n",
    "        print('0:', return_status)\n",
    "        if return_status == 256 and not redo:\n",
    "            return return_status\n",
    "    print('stat',{base_files[GWAS_ID]})\n",
    "#     prsice_command = f'Rscript ./PRSice_linux/PRSice.R \\\n",
    "#         --dir ./PRSice_output \\\n",
    "#         --prsice ./PRSice_linux/PRSice_linux \\\n",
    "#         --base ./tabular_format_gwas_data/{GWAS_ID}.tsv \\\n",
    "#         --target {TARGET_DATA} \\\n",
    "#         --thread 2 \\\n",
    "#         --stat {base_files[GWAS_ID].upper()} \\\n",
    "#         --{base_files[GWAS_ID]} \\\n",
    "#         --binary-target F \\\n",
    "#         --quantile 10 \\\n",
    "#         --out ./PRSice_output/{GWAS_ID}/{GWAS_ID} \\\n",
    "#         --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat {GWAS_ID.upper()}:ES --pvalue PVAL_generated_from_LP \\\n",
    "#         --score std \\\n",
    "#         --cov ../larger_dataset/COVAR_FILE_bigger_dataset.txt \\\n",
    "#         --extract ./PRSice_output/{GWAS_ID}/{GWAS_ID}.valid'\n",
    "    if os.path.isfile(f'./PRSice_output/{GWAS_ID}/{GWAS_ID}.valid'):\n",
    "        prsice_command = f'Rscript ./PRSice_linux/PRSice.R \\\n",
    "            --dir ./PRSice_output \\\n",
    "            --prsice ./PRSice_linux/PRSice_linux \\\n",
    "            --base ./tabular_format_gwas_data/{GWAS_ID}.tsv \\\n",
    "            --target {TARGET_DATA} \\\n",
    "            --thread 2 \\\n",
    "            --stat {base_files[GWAS_ID].upper()} \\\n",
    "            --{base_files[GWAS_ID]} \\\n",
    "            --binary-target F \\\n",
    "            --quantile 10 \\\n",
    "            --out ./PRSice_output/{GWAS_ID}/{GWAS_ID} \\\n",
    "            --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat {GWAS_ID.upper()}:ES --pvalue PVAL_generated_from_LP \\\n",
    "            --score std \\\n",
    "            --cov ../larger_dataset/COVAR_FILE_bigger_dataset.txt \\\n",
    "            --extract ./PRSice_output/{GWAS_ID}/{GWAS_ID}.valid'\n",
    "    else :\n",
    "        prsice_command = f'Rscript ./PRSice_linux/PRSice.R \\\n",
    "            --dir ./PRSice_output \\\n",
    "            --prsice ./PRSice_linux/PRSice_linux \\\n",
    "            --base ./tabular_format_gwas_data/{GWAS_ID}.tsv \\\n",
    "            --target {TARGET_DATA} \\\n",
    "            --thread 2 \\\n",
    "            --stat {base_files[GWAS_ID].upper()} \\\n",
    "            --{base_files[GWAS_ID]} \\\n",
    "            --binary-target F \\\n",
    "            --quantile 10 \\\n",
    "            --out ./PRSice_output/{GWAS_ID}/{GWAS_ID} \\\n",
    "            --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat {GWAS_ID.upper()}:ES --pvalue PVAL_generated_from_LP \\\n",
    "            --score std \\\n",
    "            --cov ../larger_dataset/COVAR_FILE_bigger_dataset.txt '\n",
    "#         print(prsice_command)\n",
    "#         print('stat',{base_files[GWAS_ID]})\n",
    "#         return_status = os.system(prsice_command) # generate the file named {GWAS_ID}.valid\n",
    "#         print('1:', return_status)\n",
    "#         return_status = os.system('echo \"===== Done =====\"')\n",
    "#         print('2:', return_status) \n",
    "\n",
    "    #             running second time with .valid extraction\n",
    "#         prsice_command = f'Rscript ./PRSice_linux/PRSice.R \\\n",
    "#             --dir ./PRSice_output \\\n",
    "#             --prsice ./PRSice_linux/PRSice_linux \\\n",
    "#             --base ./tabular_format_gwas_data/{GWAS_ID}.tsv \\\n",
    "#             --target {TARGET_DATA} \\\n",
    "#             --thread 2 \\\n",
    "#             --stat {base_files[GWAS_ID].upper()} \\\n",
    "#             --{base_files[GWAS_ID]} \\\n",
    "#             --binary-target F \\\n",
    "#             --quantile 10 \\\n",
    "#             --out ./PRSice_output/{GWAS_ID}/{GWAS_ID} \\\n",
    "#             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat {GWAS_ID.upper()}:ES --pvalue PVAL_generated_from_LP \\\n",
    "#             --score std \\\n",
    "#             --cov ../larger_dataset/COVAR_FILE_bigger_dataset.txt \\\n",
    "#             --extract ./PRSice_output/{GWAS_ID}/{GWAS_ID}.valid'\n",
    "        \n",
    "\n",
    "# #     return_status = os.system(prsice_command + '  --keep ./TRAINING_SAMPLES.txt') # generate the file named {GWAS_ID}.valid\n",
    "# #     return_status = os.system(prsice_command) # generate the file named {GWAS_ID}.validukb-b-12963\n",
    "# #     print('1a:', return_status)\n",
    "# #     return\n",
    "# #     if os.path.isfile(f'./PRSice_output/{GWAS_ID}/{GWAS_ID}.valid'): \n",
    "# #         prsice_command += f' --extract ./PRSice_output/{GWAS_ID}/{GWAS_ID}.valid' \n",
    "# #         return_status = os.system(prsice_command + '  --keep ./TRAINING_SAMPLES.txt') # perform the regression analysis on the training samples only and choose the best p-value-threshold\n",
    "# #         return_status = os.system(prsice_command) # perform the regression analysis on the training samples only and choose the best p-value-threshold\n",
    "# #         print('1b:', return_status)\n",
    "# #         if return_status != 0:\n",
    "# # #             return_status = os.system(prsice_command) # perform the regression analysis on the training samples only and choose the best p-value-threshold\n",
    "# #             print('1c:', return_status)\n",
    "# #     return_status = os.system(prsice_command + '  --all-score --no-regress') # Do not perform the regression analysis and simply output all PRS.\n",
    "# #     return_status = os.system(prsice_command + '  --all-score') # Do not perform the regression analysis and simply output all PRS.\n",
    "# #     print('2:', return_status)\n",
    "#     # in later steps, select the PRS values for the selected p-value-threshold for all the samples (both training and testing)\n",
    "    print(prsice_command)\n",
    "    print('stat',{base_files[GWAS_ID]})\n",
    "    return_status = os.system(prsice_command) # generate the file named {GWAS_ID}.valid\n",
    "    print('1:', return_status)\n",
    "    return_status = os.system('echo \"===== Done =====\"')\n",
    "    print('2:', return_status) \n",
    "#     os.system(f'mv ./prsice_output/{GWAS_ID}.* ./prsice_output/{GWAS_ID}/')\n",
    "# https://github.com/adiamb/Remove-duplicate-snps-plink"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes on run_prsice\n",
    "\n",
    "for each of the data ( individual ) that we have in target dataset, we use our built psrice framework to find out the prs value. so we now know the PRS for target dataset IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****GWAS ID IS***** ukb-b-12963\n",
      "stat {'beta'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ukb-b-12963.tsv             --target ../larger_dataset/larger_dataset             --thread 2             --stat BETA             --beta             --binary-target F             --quantile 10             --out ./PRSice_output/ukb-b-12963/ukb-b-12963             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat UKB-B-12963:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ukb-b-12963/ukb-b-12963.valid\n",
      "stat {'beta'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.5 (2021-09-20) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-09-05 14:55:31\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ukb-b-12963.tsv \\\n",
      "    --beta  \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ukb-b-12963/ukb-b-12963.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --out ./PRSice_output/ukb-b-12963/ukb-b-12963 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 338876137 \\\n",
      "    --snp ID \\\n",
      "    --stat UKB-B-12963:ES \\\n",
      "    --target ../larger_dataset/larger_dataset \\\n",
      "    --thread 2 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset/larger_dataset (bed) \n",
      "\n",
      "Start processing ukb-b-12963 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ukb-b-12963.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tUKB-B-12963:ES\tUKB-B-12963:SE\tUKB-B-12963:LP\tUKB-B-12963:AF\tUKB-B-12963:SS\tUKB-B-12963:EZ\tUKB-B-12963:SI\tUKB-B-12963:NC\tUKB-B-12963:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "9851866 variant(s) observed in base file, with: \n",
      "3268847 variant(s) excluded based on user input \n",
      "6583019 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "1245185 variant(s) not found in previous data \n",
      "29 variant(s) with mismatch information \n",
      "6583019 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 388490 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s)/phenotype(s) with p-value > 0.1 (\u001b[1;31mnot \n",
      "significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n",
      "*****GWAS ID IS***** ukb-b-12417\n",
      "stat {'beta'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ukb-b-12417.tsv             --target ../larger_dataset/larger_dataset             --thread 2             --stat BETA             --beta             --binary-target F             --quantile 10             --out ./PRSice_output/ukb-b-12417/ukb-b-12417             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat UKB-B-12417:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ukb-b-12417/ukb-b-12417.valid\n",
      "stat {'beta'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.5 (2021-09-20) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-09-05 15:22:45\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ukb-b-12417.tsv \\\n",
      "    --beta  \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ukb-b-12417/ukb-b-12417.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --out ./PRSice_output/ukb-b-12417/ukb-b-12417 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 1544405511 \\\n",
      "    --snp ID \\\n",
      "    --stat UKB-B-12417:ES \\\n",
      "    --target ../larger_dataset/larger_dataset \\\n",
      "    --thread 2 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset/larger_dataset (bed) \n",
      "\n",
      "Start processing ukb-b-12417 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ukb-b-12417.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tUKB-B-12417:ES\tUKB-B-12417:SE\tUKB-B-12417:LP\tUKB-B-12417:AF\tUKB-B-12417:SS\tUKB-B-12417:EZ\tUKB-B-12417:SI\tUKB-B-12417:NC\tUKB-B-12417:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "9851866 variant(s) observed in base file, with: \n",
      "3268847 variant(s) excluded based on user input \n",
      "6583019 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "1245185 variant(s) not found in previous data \n",
      "29 variant(s) with mismatch information \n",
      "6583019 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 388543 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s)/phenotype(s) with p-value > 0.1 (\u001b[1;31mnot \n",
      "significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n",
      "*****GWAS ID IS***** ukb-b-11495\n",
      "stat {'or'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ukb-b-11495.tsv             --target ../larger_dataset/larger_dataset             --thread 2             --stat OR             --or             --binary-target F             --quantile 10             --out ./PRSice_output/ukb-b-11495/ukb-b-11495             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat UKB-B-11495:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ukb-b-11495/ukb-b-11495.valid\n",
      "stat {'or'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.5 (2021-09-20) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-09-05 15:50:36\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ukb-b-11495.tsv \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ukb-b-11495/ukb-b-11495.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --or  \\\n",
      "    --out ./PRSice_output/ukb-b-11495/ukb-b-11495 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 3106741041 \\\n",
      "    --snp ID \\\n",
      "    --stat UKB-B-11495:ES \\\n",
      "    --target ../larger_dataset/larger_dataset \\\n",
      "    --thread 2 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset/larger_dataset (bed) \n",
      "\n",
      "Start processing ukb-b-11495 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ukb-b-11495.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tUKB-B-11495:ES\tUKB-B-11495:SE\tUKB-B-11495:LP\tUKB-B-11495:AF\tUKB-B-11495:SS\tUKB-B-11495:EZ\tUKB-B-11495:SI\tUKB-B-11495:NC\tUKB-B-11495:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "9606172 variant(s) observed in base file, with: \n",
      "6370208 variant(s) excluded based on user input \n",
      "3235964 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "4592254 variant(s) not found in previous data \n",
      "15 variant(s) with mismatch information \n",
      "3235964 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 255065 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s) with p-value between 0.1 and 1e-5 \n",
      "(\u001b[1;31mmay not be significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n",
      "*****GWAS ID IS***** ukb-b-12493\n",
      "stat {'or'}\n",
      "Rscript ./PRSice_linux/PRSice.R             --dir ./PRSice_output             --prsice ./PRSice_linux/PRSice_linux             --base ./tabular_format_gwas_data/ukb-b-12493.tsv             --target ../larger_dataset/larger_dataset             --thread 2             --stat OR             --or             --binary-target F             --quantile 10             --out ./PRSice_output/ukb-b-12493/ukb-b-12493             --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat UKB-B-12493:ES --pvalue PVAL_generated_from_LP             --score std             --cov ../larger_dataset/COVAR_FILE_bigger_dataset.txt             --extract ./PRSice_output/ukb-b-12493/ukb-b-12493.valid\n",
      "stat {'or'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PRSice 2.3.5 (2021-09-20) \n",
      "https://github.com/choishingwan/PRSice\n",
      "(C) 2016-2020 Shing Wan (Sam) Choi and Paul F. O'Reilly\n",
      "GNU General Public License v3\n",
      "If you use PRSice in any published work, please cite:\n",
      "Choi SW, O'Reilly PF.\n",
      "PRSice-2: Polygenic Risk Score Software for Biobank-Scale Data.\n",
      "GigaScience 8, no. 7 (July 1, 2019)\n",
      "2022-09-05 15:59:45\n",
      "./PRSice_linux/PRSice_linux \\\n",
      "    --a1 ALT \\\n",
      "    --a2 REF \\\n",
      "    --bar-levels 0.001,0.05,0.1,0.2,0.3,0.4,0.5,1 \\\n",
      "    --base ./tabular_format_gwas_data/ukb-b-12493.tsv \\\n",
      "    --binary-target F \\\n",
      "    --bp POS \\\n",
      "    --chr CHROM \\\n",
      "    --clump-kb 250kb \\\n",
      "    --clump-p 1.000000 \\\n",
      "    --clump-r2 0.100000 \\\n",
      "    --cov ../larger_dataset/COVAR_FILE_bigger_dataset.txt \\\n",
      "    --extract ./PRSice_output/ukb-b-12493/ukb-b-12493.valid \\\n",
      "    --interval 5e-05 \\\n",
      "    --lower 5e-08 \\\n",
      "    --num-auto 22 \\\n",
      "    --or  \\\n",
      "    --out ./PRSice_output/ukb-b-12493/ukb-b-12493 \\\n",
      "    --pvalue PVAL_generated_from_LP \\\n",
      "    --score std \\\n",
      "    --seed 127435988 \\\n",
      "    --snp ID \\\n",
      "    --stat UKB-B-12493:ES \\\n",
      "    --target ../larger_dataset/larger_dataset \\\n",
      "    --thread 2 \\\n",
      "    --upper 0.5\n",
      "\n",
      "Initializing Genotype file: \n",
      "../larger_dataset/larger_dataset (bed) \n",
      "\n",
      "Start processing ukb-b-12493 \n",
      "================================================== \n",
      "\n",
      "SNP extraction/exclusion list contains 5 columns, will \n",
      "assume first column contains the SNP ID \n",
      "\n",
      "Base file: ./tabular_format_gwas_data/ukb-b-12493.tsv \n",
      "Header of file is: \n",
      "\n",
      "CHROM\tPOS\tID\tREF\tALT\tQUAL\tFILTER\tINFO:AF\tUKB-B-12493:ES\tUKB-B-12493:SE\tUKB-B-12493:LP\tUKB-B-12493:AF\tUKB-B-12493:SS\tUKB-B-12493:EZ\tUKB-B-12493:SI\tUKB-B-12493:NC\tUKB-B-12493:ID\tPVAL_generated_from_LP \n",
      "\n",
      "Reading 100.00%\n",
      "8361394 variant(s) observed in base file, with: \n",
      "5141254 variant(s) excluded based on user input \n",
      "3220140 total variant(s) included from base file \n",
      "\n",
      "Loading Genotype info from target \n",
      "================================================== \n",
      "\n",
      "1816 people (1000 male(s), 816 female(s)) observed \n",
      "1816 founder(s) included \n",
      "\n",
      "4608077 variant(s) not found in previous data \n",
      "16 variant(s) with mismatch information \n",
      "3220140 variant(s) included \n",
      "\n",
      "There are a total of 1 phenotype to process \n",
      "\n",
      "Start performing clumping \n",
      "\n",
      "Clumping Progress: 100.00%\n",
      "Number of variant(s) after clumping : 249405 \n",
      "\n",
      "Processing the 1 th phenotype \n",
      "\n",
      "Phenotype is a continuous phenotype \n",
      "1816 sample(s) with valid phenotype \n",
      "\n",
      "Processing the covariate file: \n",
      "../larger_dataset/COVAR_FILE_bigger_dataset.txt \n",
      "============================== \n",
      "\n",
      "Include Covariates: \n",
      "Name\tMissing\tNumber of levels \n",
      "PC1\t0\t- \n",
      "PC2\t0\t- \n",
      "PC3\t0\t- \n",
      "PC4\t0\t- \n",
      "PC5\t0\t- \n",
      "PC6\t0\t- \n",
      "PC7\t0\t- \n",
      "PC8\t0\t- \n",
      "PC9\t0\t- \n",
      "PC10\t0\t- \n",
      "PTGENDER\t0\t- \n",
      "AGE\t0\t- \n",
      "\u001b[1;33mWarning: More than 12.885463% of your samples were removed! \n",
      "         You should check if your covariate file is correct \u001b[0m\n",
      "\n",
      "After reading the covariate file, 1582 sample(s) included \n",
      "in the analysis \n",
      "\n",
      "\n",
      "Start Processing\n",
      "Processing 100.00%\n",
      "There are 1 region(s) with p-value between 0.1 and 1e-5 \n",
      "(\u001b[1;31mmay not be significant\u001b[0m). \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin plotting\n",
      "Current Rscript version = 2.3.3\n",
      "Plotting the quantile plot\n",
      "Plotting Bar Plot\n",
      "Plotting the high resolution plot\n",
      "1: 0\n",
      "===== Done =====\n",
      "2: 0\n"
     ]
    }
   ],
   "source": [
    "# here for some files a weird error occurs: \"reporter not initialized\"\n",
    "# bbj-a-78\n",
    "# ukb-a-257\n",
    "# bbj-a-46\n",
    "for GWAS_ID in base_files:\n",
    "    if GWAS_ID == 'ukb-b-12963' or GWAS_ID == 'ukb-b-12417' or GWAS_ID == 'ukb-b-11495' or GWAS_ID == 'ukb-b-12493':\n",
    "        print('*****GWAS ID IS*****',GWAS_ID)\n",
    "        run_prsice(GWAS_ID=GWAS_ID)\n",
    "\n",
    "#         problem -> they do not have corresponding entries in prsice_output folder->create those folders manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_prsice(GWAS_ID='ukb-b-17627')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls 'tabular_format_gwas_data/{GWAS_ID}.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# base_files=[] #naeem mod\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m GWAS_ID \u001b[38;5;129;01min\u001b[39;00m ALL_GWAS_IDS:\n\u001b[1;32m     26\u001b[0m \n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#     file = ROOT + GWAS_ID + '.vcf.gz'\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m     base_files[GWAS_ID] \u001b[38;5;241m=\u001b[39m category_map[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGWAS_ID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mGWAS_ID\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m]\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#     generate_gwas_output_as_tsv_file(inVCF_File=file, writeFile=None)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# print(name_mapping)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# print(name_mapping)\u001b[39;00m\n\u001b[1;32m     34\u001b[0m gender_map \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFemale\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMale\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m}\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "# # need to remove this\n",
    "# from glob import glob\n",
    "# import pandas as pd\n",
    "# category_map = {\n",
    "#     'Continuous' : 'beta', \n",
    "#     'Categorical Ordered (assumed continuous)': 'beta',\n",
    "#     'Binary': 'or',\n",
    "#     'NA (Possibly binary)': 'or'\n",
    "# }\n",
    "\n",
    "# df = pd.read_excel('GWAS_datasets_to_consider.xlsx', engine='openpyxl')[['GWAS_ID', 'Trait', 'Category']]\n",
    "# # all_gwas_vcf_files = glob('/mnt/c/Users/HP/Downloads/Compressed/GWAS/*')\n",
    "# # ROOT = '/mnt/c/Users/HP/Downloads/Compressed/GWAS/'\n",
    "# # ALL_GWAS_IDS = list(set(df['GWAS_ID'].to_numpy().tolist()) - {'bbj-a-46', 'bbj-a-78', 'ieu-a-1283', 'ukb-a-257','ukb-b-2209','ukb-b-17627','ieub-109','ieu-b-110','ieu-b-111','met-d-Total_C'})\n",
    "# # bbj-a-78,ukb-a-257,bbj-a-46\n",
    "# # ALL_GWAS_IDS = list(set(df['GWAS_ID'].to_numpy().tolist()) - { 'ieu-a-1283','bbj-a-46', 'bbj-a-78'})\n",
    "# ALL_GWAS_IDS = list(set(df['GWAS_ID'].to_numpy().tolist()) - { 'ieu-a-1283','bbj-a-46', 'bbj-a-78','ukb-b-13806','ukb-b-12064','ukb-b-323','ukb-b-14699','ukb-b-14699','ukb-b-5779'})\n",
    "# print(len(ALL_GWAS_IDS))\n",
    "\n",
    "# ALL_GWAS_IDS= {'ukb-b-17006','ukb-b-5779','ukb-b-15541','ukb-b-20289','ukb-b-19732','ukb-b-6324','ukb-b-7663','ukb-b-770','ukb-b-323','ukb-b-14699','ukb-b-14180','ukb-b-17243','ukb-b-6358','','ukb-b-8476','','ukb-b-6134','ukb-b-4424','ukb-b-3957','ukb-b-2209','ukb-b-19953','ukb-b-18275','ukb-b-17627','ukb-b-12064','ukb-a-257','ieu-b-39','ieu-b-38','ieu-b-25','ieu-b-111','ieu-b-110','ieu-b-109','met-d-Total_C','ukb-d-20405_2','ukb-d-20405_1','ukb-d-20405_0','ukb-b-13806','ukb-b-13806','ukb-b-12064','ukb-b-323','ukb-b-14699','ukb-b-14699','ukb-b-5779'}\n",
    "\n",
    "# base_files = {}\n",
    "\n",
    "# # base_files=[] #naeem mod\n",
    "# for GWAS_ID in ALL_GWAS_IDS:\n",
    "\n",
    "# #     file = ROOT + GWAS_ID + '.vcf.gz'\n",
    "#     base_files[GWAS_ID] = category_map[df[df['GWAS_ID'] == GWAS_ID].to_numpy()[0, 2]]\n",
    "\n",
    "# #     generate_gwas_output_as_tsv_file(inVCF_File=file, writeFile=None)\n",
    "# # print(name_mapping)\n",
    "# # print(name_mapping)\n",
    "\n",
    "# gender_map = {'Female': 0,'Male': 1}\n",
    "# ADNIMERGE = pd.read_csv('ADNIMERGE.csv')\n",
    "# def get_gender_and_age(PTID):\n",
    "#     gender = ADNIMERGE[ADNIMERGE['PTID'] == PTID]['PTGENDER'].dropna().unique()[0]\n",
    "#     age = ADNIMERGE[ADNIMERGE['PTID'] == PTID]['AGE'].dropna().unique()[0]\n",
    "#     return str(gender_map[gender]) + ' ' + str(age)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_files\n",
    "GWAS_ID = 'ukb-b-14057'\n",
    "\n",
    "#====\n",
    "\n",
    "def get_prs_values(GWAS_ID):\n",
    "    prsice_output = f'./PRSice_output/{GWAS_ID}/'\n",
    "\n",
    "    if False:\n",
    "        with open(prsice_output+f'{GWAS_ID}.all_score', 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            lines = ['\\t'.join(x.split()) for x in lines]\n",
    "            lines = '\\n'.join(lines)\n",
    "\n",
    "        with open(prsice_output+f'{GWAS_ID}.all_score.tsv', 'w') as f:\n",
    "            f.write(lines)\n",
    "\n",
    "        # best_p_val_threshold = '0.00025005'\n",
    "        best_p_val_threshold = str(open(prsice_output+f'{GWAS_ID}.summary').readlines()[1].split('\\t')[2]) \n",
    "    #     print(best_p_val_threshold) \n",
    "    prs_array = pd.read_csv(prsice_output+f'{GWAS_ID}.best', ' ')['PRS'].to_numpy() \n",
    "    return prs_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4364/1595037025.py:1: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  get_prs_values(GWAS_ID=GWAS_ID).shape[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1816"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prs_values(GWAS_ID=GWAS_ID).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "# folderCounter=9\n",
    "folderCounter=folderCounter+1\n",
    "inputFolder=\"input/\"+str(folderCounter)+\"/\"\n",
    "os.mkdir(inputFolder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base files {'ukb-b-13806': 'or', 'ukb-d-20405_0': 'or', 'ukb-d-20405_1': 'or', 'ukb-d-20405_2': 'or', 'met-d-Total_C': 'beta', 'ieu-b-109': 'beta', 'ieu-b-110': 'beta', 'ieu-b-111': 'beta', 'ieu-b-25': 'beta', 'ieu-b-38': 'beta', 'ieu-b-39': 'beta', 'ukb-a-257': 'or', 'ukb-b-12064': 'or', 'ukb-b-17627': 'beta', 'ukb-b-18275': 'or', 'ukb-b-19953': 'beta', 'ukb-b-2209': 'beta', 'ukb-b-3957': 'beta', 'ukb-b-4424': 'beta', 'ukb-b-6134': 'beta', 'ukb-b-6324': 'beta', 'ukb-b-7663': 'or', 'ukb-b-770': 'beta', 'ukb-b-8476': 'or', 'ukb-b-323': 'or', 'ukb-b-14699': 'or', 'ukb-b-14180': 'or', 'ukb-b-17243': 'or', 'ukb-b-6358': 'or', 'ukb-b-17006': 'or', 'ukb-b-5779': 'beta', 'ukb-b-15541': 'or', 'ukb-b-19732': 'or', 'ukb-b-20289': 'or', 'ukb-b-14057': 'or', 'ukb-b-12963': 'beta', 'ukb-b-12417': 'beta', 'ukb-b-11495': 'or', 'ukb-b-12493': 'or'}\n",
      "new base files ['ukb-b-13806', 'ukb-d-20405_0', 'ukb-d-20405_1', 'ukb-d-20405_2', 'met-d-Total_C', 'ieu-b-109', 'ieu-b-110', 'ieu-b-111', 'ieu-b-25', 'ieu-b-38', 'ieu-b-39', 'ukb-a-257', 'ukb-b-12064', 'ukb-b-17627', 'ukb-b-18275', 'ukb-b-19953', 'ukb-b-2209', 'ukb-b-3957', 'ukb-b-4424', 'ukb-b-6134', 'ukb-b-6324', 'ukb-b-7663', 'ukb-b-770', 'ukb-b-8476', 'ukb-b-323', 'ukb-b-14699', 'ukb-b-14180', 'ukb-b-17243', 'ukb-b-6358', 'ukb-b-17006', 'ukb-b-5779', 'ukb-b-15541', 'ukb-b-19732', 'ukb-b-20289', 'ukb-b-14057', 'ukb-b-12963', 'ukb-b-12417', 'ukb-b-11495', 'ukb-b-12493']\n",
      "ukb-b-13806\n",
      "ukb-d-20405_0\n",
      "ukb-d-20405_1\n",
      "ukb-d-20405_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4364/247646291.py:25: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_4364/247646291.py:25: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_4364/247646291.py:25: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_4364/247646291.py:25: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "met-d-Total_C\n",
      "ieu-b-109\n",
      "ieu-b-110\n",
      "ieu-b-111\n",
      "ieu-b-25\n",
      "ieu-b-38\n",
      "ieu-b-39\n",
      "ukb-a-257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4364/247646291.py:25: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_4364/247646291.py:25: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_4364/247646291.py:25: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_4364/247646291.py:25: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_4364/247646291.py:25: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_4364/247646291.py:25: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_4364/247646291.py:25: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_4364/247646291.py:25: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ukb-b-12064\n",
      "ukb-b-17627\n",
      "ukb-b-18275\n",
      "ukb-b-19953\n",
      "ukb-b-2209\n",
      "ukb-b-3957\n",
      "ukb-b-4424\n",
      "ukb-b-6134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4364/247646291.py:25: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_4364/247646291.py:25: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_4364/247646291.py:25: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_4364/247646291.py:25: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_4364/247646291.py:25: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_4364/247646291.py:25: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_4364/247646291.py:25: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_4364/247646291.py:25: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ukb-b-6324\n",
      "ukb-b-7663\n",
      "ukb-b-770\n",
      "ukb-b-8476\n",
      "ukb-b-323\n",
      "ukb-b-14699\n",
      "ukb-b-14180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4364/247646291.py:25: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_4364/247646291.py:25: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_4364/247646291.py:25: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_4364/247646291.py:25: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_4364/247646291.py:25: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_4364/247646291.py:25: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_4364/247646291.py:25: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ukb-b-17243\n",
      "ukb-b-6358\n",
      "ukb-b-17006\n",
      "ukb-b-5779\n",
      "ukb-b-15541\n",
      "ukb-b-19732\n",
      "ukb-b-20289\n",
      "ukb-b-14057\n",
      "ukb-b-12963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4364/247646291.py:25: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_4364/247646291.py:25: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_4364/247646291.py:25: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_4364/247646291.py:25: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_4364/247646291.py:25: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_4364/247646291.py:25: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_4364/247646291.py:25: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_4364/247646291.py:25: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_4364/247646291.py:25: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ukb-b-12417\n",
      "ukb-b-11495\n",
      "ukb-b-12493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4364/247646291.py:25: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_4364/247646291.py:25: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
      "/tmp/ipykernel_4364/247646291.py:25: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os.path\n",
    "import json\n",
    "name_mapping={}\n",
    "# GWAS_ID\n",
    "# ukb-b-13806\n",
    "# ukb-b-12064\n",
    "# ukb-b-323\n",
    "# ukb-b-14699\n",
    "# ukb-b-5779\n",
    "# base_files=base_files-\n",
    "print('base files',base_files)\n",
    "newBaseFiles=[]\n",
    "for GWAS_ID in base_files:\n",
    "    prsice_output = f'./PRSice_output/{GWAS_ID}/{GWAS_ID}.best'\n",
    "    if os.path.exists(prsice_output):  \n",
    "        newBaseFiles.append(GWAS_ID)\n",
    "print('new base files',newBaseFiles)\n",
    "\n",
    "PRS_feature_matrix = np.zeros([len(newBaseFiles), 1816])\n",
    "for i, GWAS_ID in enumerate(newBaseFiles):\n",
    "    print(GWAS_ID)\n",
    "    prsice_output = f'./PRSice_output/{GWAS_ID}/{GWAS_ID}.best'\n",
    "    if os.path.exists(prsice_output):  \n",
    "        PRS_feature_matrix[i, :] = get_prs_values(GWAS_ID=GWAS_ID)\n",
    "        name_mapping[GWAS_ID] =df[df['GWAS_ID'] == GWAS_ID].to_numpy()[0, 1]\n",
    "    else :\n",
    "        print(\"no path exists\")\n",
    "        \n",
    "with open(inputFolder+\"traits_map.json\", \"w\") as outfile:\n",
    "    json.dump(name_mapping, outfile)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRS_feature_matrix = PRS_feature_matrix.T\n",
    "np.save(inputFolder+'PRS_feature_matrix', PRS_feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRS_feature_matrix.shape\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[706, 84, 728, 620, 57, 145, 456, 386, 120, 564, 313, 310, 656, 430, 679, 422, 128, 275, 72, 488, 80, 569, 538, 163, 699, 600, 509, 10, 344, 785, 282, 261, 358, 438, 644, 157, 400, 219, 646, 452, 827, 378, 754, 243, 327, 542, 123, 32, 278, 749, 622, 162, 590, 314, 510, 513, 692, 783, 693, 331, 713, 364, 660, 200, 140, 623, 348, 584, 389, 67, 148, 846, 596, 635, 555, 333, 79, 568, 833, 86, 755, 626, 727, 515, 27, 23, 836, 65, 121, 775, 696, 602, 734, 601, 491, 289, 467, 659, 263, 46, 465, 283, 196, 100, 631, 192, 35, 546, 662, 655, 547, 642, 392, 291, 789, 326, 698, 329, 715, 281, 122, 398, 598, 134, 778, 399, 341, 376, 461, 831, 690, 385, 141, 753, 60, 322, 519, 645, 796, 683, 533, 595, 349, 771, 787, 634, 608, 350, 369, 270, 379, 409, 497, 552, 93, 370, 207, 611, 767, 26, 250, 573, 296, 131, 238, 735, 607, 664, 293, 455, 711, 562, 702, 416, 71, 137, 210, 14, 486, 188, 85, 25, 780, 150, 649, 750, 522, 492, 94, 272, 224, 668, 202, 408, 842, 266, 170, 320, 242, 663, 809, 286, 262, 112, 680, 722, 31, 828, 277, 223, 543, 325, 306, 517, 6, 418, 267, 205, 428, 33, 236, 169, 211, 685, 319, 650, 832, 641, 115, 118, 19, 178, 22, 436, 761, 758, 323, 39, 548, 111, 769, 739, 426, 273, 731, 705, 714, 605, 361, 447, 88, 628, 469, 802, 490, 209, 725, 463, 204, 69, 762, 256, 81, 791, 95, 405, 388, 429, 751, 117, 466, 387, 813, 673, 355, 413, 176, 768, 21, 66, 674, 615, 156, 445, 485, 570, 360, 733, 154, 336, 619, 537, 480, 803, 578, 647, 135]\n",
      "550 297 847\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-0.02368163, -0.50353254, -0.24775783, -0.47251707, -0.08324405,\n",
       "         0.02422033, -0.07300881,  0.01604097,  0.03053623,  0.00979374,\n",
       "        -0.02381719, -0.49634019, -0.18916941,  0.00658408, -0.56717317,\n",
       "        -0.00405164, -0.02585978,  0.01578641,  0.0944516 ,  0.01755509,\n",
       "        -0.01280157, -0.54905321,  0.05179198, -0.64817529,  0.04284866,\n",
       "         0.04289331, -0.6363136 , -0.22897945, -0.17799649, -0.11391193,\n",
       "        -0.0650293 , -0.11014417, -0.50747783, -0.10198507, -0.55567919,\n",
       "        -0.08662832, -0.06746048, -0.49407727, -0.55526014]),\n",
       " array([1.01926618, 0.58047115, 0.88326029, 0.53844969, 1.08113995,\n",
       "        0.98695951, 0.98803143, 0.94135101, 0.95300595, 0.98682334,\n",
       "        1.00352771, 0.56102621, 0.94517039, 0.96012076, 0.59820564,\n",
       "        1.01376883, 1.03806579, 0.92807665, 0.67471095, 1.01869837,\n",
       "        1.03537451, 0.57607012, 0.98921052, 0.7153049 , 1.00890631,\n",
       "        1.01427554, 0.6937051 , 0.84098038, 0.9234935 , 0.99974419,\n",
       "        0.65343195, 1.01162386, 0.53594888, 1.02351902, 0.5892443 ,\n",
       "        0.64937792, 0.74649271, 0.57515466, 0.58556455]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_SAMPLE_SIZE = 550\n",
    "train_samples = list(range(847))\n",
    "random.shuffle(train_samples)\n",
    "train_samples, test_samples = train_samples[:TRAIN_SAMPLE_SIZE], train_samples[TRAIN_SAMPLE_SIZE:]\n",
    "print(test_samples)\n",
    "print(len(train_samples), len(test_samples), len(train_samples) + len(test_samples))\n",
    "PRS_feature_matrix[train_samples].mean(0), PRS_feature_matrix[train_samples].std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1.76000943e-01, -5.51244086e-01, -2.46491819e-01, -5.42307739e-01,\n",
       "        -4.37441728e-02,  6.00657014e-02, -8.80991326e-02,  2.89476589e-03,\n",
       "        -5.82942297e-02,  3.34977917e-02,  3.85465950e-02, -5.66259981e-01,\n",
       "        -1.47668693e-01,  2.51357133e-04, -6.18639962e-01, -8.48259314e-03,\n",
       "        -3.22589534e-02,  6.26494664e-03,  1.78320943e-01, -3.87794104e-02,\n",
       "         4.34865012e-02, -6.01037183e-01, -8.42375390e-03, -7.15486963e-01,\n",
       "         6.57855511e-02,  6.17779941e-02, -6.49179039e-01, -2.08953653e-01,\n",
       "        -1.97764790e-01, -4.26518817e-02, -1.54389361e-01, -5.48610834e-02,\n",
       "        -5.71232451e-01, -5.83867804e-02, -5.97502833e-01, -1.22271406e-01,\n",
       "        -1.65950597e-01, -5.57414040e-01, -5.86516237e-01]),\n",
       " array([0.89842647, 0.57093002, 0.83806135, 0.47210769, 0.94363407,\n",
       "        1.01954515, 0.95930109, 0.9873961 , 0.98733904, 0.93784124,\n",
       "        0.96426722, 0.53461648, 0.93392974, 0.96787378, 0.54768627,\n",
       "        0.99460568, 0.91905409, 0.9886577 , 0.68563002, 0.97210199,\n",
       "        0.89613581, 0.51009671, 0.98957026, 0.66891605, 0.94334763,\n",
       "        0.96478176, 0.62365512, 0.87842301, 0.8012836 , 0.95658943,\n",
       "        0.61698454, 0.98858035, 0.49979709, 0.98572523, 0.54305541,\n",
       "        0.58918339, 0.71824308, 0.53875858, 0.54066388]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PRS_feature_matrix[test_samples].mean(0), PRS_feature_matrix[test_samples].std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.80121253e-11, -7.23843658e-11, -4.03398744e-11, -1.24741255e-11,\n",
       "         1.19856782e-11,  8.02313086e-12, -3.06668484e-11, -2.29878925e-11,\n",
       "        -2.72191628e-11,  7.99063703e-12,  7.19383295e-11, -1.15251910e-12,\n",
       "        -3.74664176e-11,  1.85110097e-11, -5.24669764e-11,  1.11084739e-11,\n",
       "         5.59416361e-11,  3.21943862e-11, -5.24559427e-11, -2.76734093e-12,\n",
       "        -1.95044098e-11,  9.72282264e-12,  5.42070353e-12,  6.10582832e-11,\n",
       "         3.02257739e-11,  1.54763251e-11,  3.52919065e-11, -6.37114248e-12,\n",
       "        -8.16188233e-12,  4.53524247e-11, -1.82294982e-11,  3.02863363e-12,\n",
       "         6.98566804e-12,  3.05832070e-11, -1.58479201e-13,  4.16432195e-11,\n",
       "         2.62714803e-11,  1.76151057e-11, -4.53576677e-12]),\n",
       " array([0.99972463, 0.99972463, 0.99972463, 0.99972463, 0.99972463,\n",
       "        0.99972463, 0.99972463, 0.99972463, 0.99972463, 0.99972463,\n",
       "        0.99972463, 0.99972463, 0.99972463, 0.99972463, 0.99972463,\n",
       "        0.99972463, 0.99972463, 0.99972463, 0.99972463, 0.99972463,\n",
       "        0.99972463, 0.99972463, 0.99972463, 0.99972463, 0.99972463,\n",
       "        0.99972463, 0.99972463, 0.99972463, 0.99972463, 0.99972463,\n",
       "        0.99972463, 0.99972463, 0.99972463, 0.99972463, 0.99972463,\n",
       "        0.99972463, 0.99972463, 0.99972463, 0.99972463]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PRS_feature_matrix[:].mean(0), PRS_feature_matrix[:].std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naeem/anaconda3/envs/ad_venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3397: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(dict, 1816)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "GWAS_ID = 'ukb-b-14057'\n",
    "usable_samples_ADNI = pd.read_csv(f'./PRSice_output/{GWAS_ID}/{GWAS_ID}.best', ' ')['IID'].to_numpy().tolist()\n",
    "usable_samples_ADNI = {'_'.join(sample.split('_')[1:]):idx for idx,sample in enumerate(usable_samples_ADNI)}\n",
    "# json.dump(usable_samples_ADNI, open('./usable_samples_ADNI.json', 'w'))\n",
    "type(usable_samples_ADNI), len(usable_samples_ADNI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'25_7_22_thyroid traits.zip'   ukb-a-257     ukb-b-17006   ukb-b-5779\r\n",
      " bbj-a-46\t\t       ukb-b-11495   ukb-b-17243   ukb-b-6134\r\n",
      " bbj-a-78\t\t       ukb-b-12064   ukb-b-17627   ukb-b-6324\r\n",
      " ieu-b-109\t\t       ukb-b-12417   ukb-b-18275   ukb-b-6358\r\n",
      " ieu-b-110\t\t       ukb-b-12493   ukb-b-19732   ukb-b-7663\r\n",
      " ieu-b-111\t\t       ukb-b-12963   ukb-b-19953   ukb-b-770\r\n",
      " ieu-b-25\t\t       ukb-b-13806   ukb-b-20289   ukb-b-8476\r\n",
      " ieu-b-38\t\t       ukb-b-14057   ukb-b-2209    ukb-d-20405_0\r\n",
      " ieu-b-39\t\t       ukb-b-14180   ukb-b-323\t   ukb-d-20405_1\r\n",
      " lib\t\t\t       ukb-b-14699   ukb-b-3957    ukb-d-20405_2\r\n",
      " met-d-Total_C\t\t       ukb-b-15541   ukb-b-4424\r\n"
     ]
    }
   ],
   "source": [
    "!ls PRSice_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1816, 39) 1816\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "# PRS_feature_matrix = np.load('./PRS_feature_matrix.npy')\n",
    "PRS_feature_matrix = np.load(inputFolder+'PRS_feature_matrix.npy')\n",
    "# usable_samples_ADNI = json.load(open('./usable_samples_ADNI.json'))\n",
    "print(PRS_feature_matrix.shape, usable_samples_ADNI.__len__())\n",
    "\n",
    "# usable_samples_ADNI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prsice result used in our model\n",
    "usable_samples_adni-> from .best of prsice corresponding to larger dataset we get the IIDs ( ie the individuals that we considered for our studies )\n",
    "now , larger data set is actually a part of ADNIMERGE dataset . So, here we have all the considered patients, but some of the data that are in ADNIMERGE are not present in larger dataset. That leads to the check of \"sample in usable_samples_adni\". \n",
    "The reason behind this is related to the generation of \"larger dataset\" generation from \"ADNI\" dataset.\n",
    "Here our main task is to find out those samples that have corresponding .best file entry, ie included in larger dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5175/1588684655.py:2: DtypeWarning: Columns (18,19,20,103,104) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ADNIMERGE = pd.read_csv('ADNIMERGE.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RID        PTID VISCODE  SITE COLPROT ORIGPROT  EXAMDATE DX_bl   AGE  \\\n",
      "0    2  011_S_0002      bl    11   ADNI1    ADNI1  08-09-05    CN  74.3   \n",
      "1    3  011_S_0003      bl    11   ADNI1    ADNI1  12-09-05    AD  81.3   \n",
      "2    3  011_S_0003     m06    11   ADNI1    ADNI1  13-03-06    AD  81.3   \n",
      "3    3  011_S_0003     m12    11   ADNI1    ADNI1  12-09-06    AD  81.3   \n",
      "4    3  011_S_0003     m24    11   ADNI1    ADNI1  12-09-07    AD  81.3   \n",
      "\n",
      "  PTGENDER  ...  TAU_bl PTAU_bl   FDG_bl PIB_bl  AV45_bl  Years_bl  Month_bl  \\\n",
      "0     Male  ...     NaN     NaN  1.36665    NaN      NaN  0.000000   0.00000   \n",
      "1     Male  ...   239.7   22.83  1.08355    NaN      NaN  0.000000   0.00000   \n",
      "2     Male  ...   239.7   22.83  1.08355    NaN      NaN  0.498289   5.96721   \n",
      "3     Male  ...   239.7   22.83  1.08355    NaN      NaN  0.999316  11.96720   \n",
      "4     Male  ...   239.7   22.83  1.08355    NaN      NaN  1.998630  23.93440   \n",
      "\n",
      "   Month     M update_stamp  \n",
      "0      0   0.0      55:41.0  \n",
      "1      0   0.0      55:41.0  \n",
      "2      6   6.0      55:41.0  \n",
      "3     12  12.0      55:41.0  \n",
      "4     24  24.0      55:41.0  \n",
      "\n",
      "[5 rows x 113 columns]\n",
      "(15122, 113)\n",
      "Dementia shape :  (2338, 4)\n",
      "        RID        PTID        DX  Month\n",
      "1333    619  002_S_0619  Dementia      0\n",
      "6467    619  002_S_0619  Dementia      6\n",
      "6469    619  002_S_0619  Dementia     12\n",
      "6470    619  002_S_0619  Dementia     24\n",
      "1549    729  002_S_0729  Dementia     12\n",
      "...     ...         ...       ...    ...\n",
      "7928   1311  941_S_1311  Dementia     24\n",
      "8004   1363  941_S_1363  Dementia      6\n",
      "14030  6345  941_S_6345  Dementia     12\n",
      "14947  6345  941_S_6345  Dementia     30\n",
      "14672  6854  941_S_6854  Dementia      0\n",
      "\n",
      "[2338 rows x 4 columns]\n",
      "Samples Dementia length :  787\n",
      "Samples NonDementia length :  1481\n",
      "Final Samples Dementia length :  654\n",
      "Final Samples Non-Dementia length :  867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(654, 867, 1521)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "THRESHOLD_MONTH = 12*2\n",
    "ADNIMERGE = pd.read_csv('ADNIMERGE.csv')\n",
    "print(ADNIMERGE.head())\n",
    "print(ADNIMERGE.shape)\n",
    "ADNI_TEMP = ADNIMERGE[['RID', 'PTID', 'DX', 'Month']].dropna().sort_values(by=['PTID', 'Month'])\n",
    "Dementia = ADNI_TEMP[ADNI_TEMP['DX']=='Dementia']\n",
    "print(\"Dementia shape : \", Dementia.shape)\n",
    "print(Dementia)\n",
    "Samples_Dementia = set(Dementia['PTID'].unique())\n",
    "print(\"Samples Dementia length : \", len(Samples_Dementia) )\n",
    "Samples_NonDementia = set(ADNI_TEMP['PTID'].unique()) - Samples_Dementia\n",
    "print(\"Samples NonDementia length : \", len( Samples_NonDementia ) )\n",
    "\n",
    "# Samples_NonDementia\n",
    "Final_Samples_Dementia = set()\n",
    "for sample in Samples_Dementia:\n",
    "    last_dx = ADNI_TEMP[ADNI_TEMP['PTID']==sample]['DX'].iloc[-1]\n",
    "    last_month_of_dx = ADNI_TEMP[ADNI_TEMP['PTID']==sample]['Month'].iloc[-1]\n",
    "    \n",
    "    if True:\n",
    "#     if last_month_of_dx >= THRESHOLD_MONTH :\n",
    "#         if last_dx != 'Dementia':\n",
    "#             print(last_dx)\n",
    "        \n",
    "        if last_dx == 'Dementia' and sample in usable_samples_ADNI:\n",
    "            \n",
    "            Final_Samples_Dementia = Final_Samples_Dementia.union({sample})\n",
    "            \n",
    "        \n",
    "#             why check for dementia again?\n",
    "                \n",
    "\n",
    "Final_Samples_NonDementia = set()\n",
    "for sample in Samples_NonDementia:\n",
    "    last_month_of_dx = ADNI_TEMP[ADNI_TEMP['PTID']==sample]['Month'].iloc[-1]\n",
    "    if last_month_of_dx >= THRESHOLD_MONTH and sample in usable_samples_ADNI:\n",
    "#     if sample in usable_samples_ADNI:\n",
    "        Final_Samples_NonDementia = Final_Samples_NonDementia | {sample} # union symbol in python sets\n",
    "    \n",
    "# sum(ADNI_TEMP['Month'] == 6), ADNI_TEMP.shape\n",
    "# Dementia\n",
    "Final_Samples_Dementia = [[x, 1] for x in Final_Samples_Dementia]\n",
    "Final_Samples_NonDementia = [[x, 0] for x in Final_Samples_NonDementia]\n",
    "print(\"Final Samples Dementia length : \", len(Final_Samples_Dementia) )\n",
    "print(\"Final Samples Non-Dementia length : \", len(Final_Samples_NonDementia) )\n",
    "\n",
    "Final_Samples = Final_Samples_Dementia + Final_Samples_NonDementia\n",
    "# json.dump(Final_Samples, open(inputFolder+'Final_Samples.json', 'w'))\n",
    "json.dump(Final_Samples, open('Final_Samples_2yrs.json', 'w'))\n",
    "json.dump(Final_Samples_Dementia, open('Final_Samples_Dementia.json', 'w'))\n",
    "json.dump(Final_Samples_NonDementia, open('Final_Samples_NonDementia.json', 'w'))\n",
    "\n",
    "\n",
    "Final_Samples_Dementia.__len__(), Final_Samples_NonDementia.__len__(), Final_Samples.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naeem/anaconda3/envs/ad_venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3397: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "GWAS_ID = 'ukb-b-14057'\n",
    "usable_samples_ADNI = pd.read_csv(f'./PRSice_output/{GWAS_ID}/{GWAS_ID}.best', ' ')['IID'].to_numpy().tolist()\n",
    "usable_samples_ADNI = {sample:idx for idx,sample in enumerate(usable_samples_ADNI)}\n",
    "json.dump(usable_samples_ADNI, open('./usable_samples_ADNI.json', 'w'))\n",
    "# json.dump(usable_samples_ADNI, open(inputFolder+'usable_samples_ADNI.json', 'w'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ukb-b-13806', 'ukb-d-20405_0', 'ukb-d-20405_1', 'ukb-d-20405_2', 'met-d-Total_C', 'ieu-b-109', 'ieu-b-110', 'ieu-b-111', 'ieu-b-25', 'ieu-b-38', 'ieu-b-39', 'ukb-a-257', 'ukb-b-12064', 'ukb-b-17627', 'ukb-b-18275', 'ukb-b-19953', 'ukb-b-2209', 'ukb-b-3957', 'ukb-b-4424', 'ukb-b-6134', 'ukb-b-6324', 'ukb-b-7663', 'ukb-b-770', 'ukb-b-8476', 'ukb-b-323', 'ukb-b-14699', 'ukb-b-14180', 'ukb-b-17243', 'ukb-b-6358', 'ukb-b-17006', 'ukb-b-5779', 'ukb-b-15541', 'ukb-b-19732', 'ukb-b-20289', 'ukb-b-14057', 'ukb-b-12963', 'ukb-b-12417', 'ukb-b-11495', 'ukb-b-12493']\n"
     ]
    }
   ],
   "source": [
    "ALL_GWAS_IDS = [key for key in base_files]\n",
    "print(ALL_GWAS_IDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GWAS_ID</th>\n",
       "      <th>Trait</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ukb-b-13806</td>\n",
       "      <td>Non-cancer illness code, self-reported: type 2...</td>\n",
       "      <td>or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ukb-d-20405_0</td>\n",
       "      <td>Ever had known person concerned about, or reco...</td>\n",
       "      <td>or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ukb-d-20405_1</td>\n",
       "      <td>Ever had known person concerned about, or reco...</td>\n",
       "      <td>or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ukb-d-20405_2</td>\n",
       "      <td>Ever had known person concerned about, or reco...</td>\n",
       "      <td>or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>met-d-Total_C</td>\n",
       "      <td>Total cholesterol</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ieu-b-109</td>\n",
       "      <td>HDL cholesterol</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ieu-b-110</td>\n",
       "      <td>LDL cholesterol</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ieu-b-111</td>\n",
       "      <td>triglycerides</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ieu-b-25</td>\n",
       "      <td>Cigarettes per Day</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ieu-b-38</td>\n",
       "      <td>systolic blood pressure</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ieu-b-39</td>\n",
       "      <td>diastolic blood pressure</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ukb-a-257</td>\n",
       "      <td>Hearing difficulty/problems: Yes</td>\n",
       "      <td>or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ukb-b-12064</td>\n",
       "      <td>Non-cancer illness code, self-reported: depres...</td>\n",
       "      <td>or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ukb-b-17627</td>\n",
       "      <td>Non-oily fish intake</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ukb-b-18275</td>\n",
       "      <td>Hearing difficulty/problems with background noise</td>\n",
       "      <td>or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ukb-b-19953</td>\n",
       "      <td>Body mass index (BMI)</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ukb-b-2209</td>\n",
       "      <td>Oily fish intake</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ukb-b-3957</td>\n",
       "      <td>Sleeplessness / insomnia</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ukb-b-4424</td>\n",
       "      <td>Sleep duration</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ukb-b-6134</td>\n",
       "      <td>Age completed full time education</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ukb-b-6324</td>\n",
       "      <td>Processed meat intake</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ukb-b-7663</td>\n",
       "      <td>Types of physical activity in last 4 weeks: St...</td>\n",
       "      <td>or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ukb-b-770</td>\n",
       "      <td>Other meat intake</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ukb-b-8476</td>\n",
       "      <td>Loneliness, isolation</td>\n",
       "      <td>or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ukb-b-323</td>\n",
       "      <td>Illnesses of father: Alzheimer's disease/dementia</td>\n",
       "      <td>or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ukb-b-14699</td>\n",
       "      <td>Illnesses of mother: Alzheimer's disease/dementia</td>\n",
       "      <td>or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ukb-b-14180</td>\n",
       "      <td>Mood swings</td>\n",
       "      <td>or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ukb-b-17243</td>\n",
       "      <td>Non-cancer illness code, self-reported: anxiet...</td>\n",
       "      <td>or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ukb-b-6358</td>\n",
       "      <td>Non-cancer illness code, self-reported: stroke</td>\n",
       "      <td>or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ukb-b-17006</td>\n",
       "      <td>Non-cancer illness code, self-reported: head i...</td>\n",
       "      <td>or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ukb-b-5779</td>\n",
       "      <td>Alcohol intake frequency</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ukb-b-15541</td>\n",
       "      <td>Diagnoses - secondary ICD10: E66.9 Obesity, un...</td>\n",
       "      <td>or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ukb-b-19732</td>\n",
       "      <td>Non-cancer illness code, self-reported: hypoth...</td>\n",
       "      <td>or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ukb-b-20289</td>\n",
       "      <td>Non-cancer illness code, self-reported: hypert...</td>\n",
       "      <td>or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ukb-b-14057</td>\n",
       "      <td>Non-cancer illness code, self-reported: hypert...</td>\n",
       "      <td>or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ukb-b-12963</td>\n",
       "      <td>Particulate matter air pollution 2.5-10um; 2010</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ukb-b-12417</td>\n",
       "      <td>Nitrogen oxides air pollution; 2010</td>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ukb-b-11495</td>\n",
       "      <td>Types of physical activity in last 4 weeks: Li...</td>\n",
       "      <td>or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ukb-b-12493</td>\n",
       "      <td>Diagnoses - secondary ICD10: I10 Essential (pr...</td>\n",
       "      <td>or</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          GWAS_ID                                              Trait Category\n",
       "0     ukb-b-13806  Non-cancer illness code, self-reported: type 2...       or\n",
       "1   ukb-d-20405_0  Ever had known person concerned about, or reco...       or\n",
       "2   ukb-d-20405_1  Ever had known person concerned about, or reco...       or\n",
       "3   ukb-d-20405_2  Ever had known person concerned about, or reco...       or\n",
       "4   met-d-Total_C                                  Total cholesterol     beta\n",
       "5       ieu-b-109                                    HDL cholesterol     beta\n",
       "6       ieu-b-110                                    LDL cholesterol     beta\n",
       "7       ieu-b-111                                      triglycerides     beta\n",
       "8        ieu-b-25                                 Cigarettes per Day     beta\n",
       "9        ieu-b-38                            systolic blood pressure     beta\n",
       "10       ieu-b-39                           diastolic blood pressure     beta\n",
       "11      ukb-a-257                   Hearing difficulty/problems: Yes       or\n",
       "12    ukb-b-12064  Non-cancer illness code, self-reported: depres...       or\n",
       "13    ukb-b-17627                               Non-oily fish intake     beta\n",
       "14    ukb-b-18275  Hearing difficulty/problems with background noise       or\n",
       "15    ukb-b-19953                              Body mass index (BMI)     beta\n",
       "16     ukb-b-2209                                   Oily fish intake     beta\n",
       "17     ukb-b-3957                           Sleeplessness / insomnia     beta\n",
       "18     ukb-b-4424                                     Sleep duration     beta\n",
       "19     ukb-b-6134                  Age completed full time education     beta\n",
       "20     ukb-b-6324                              Processed meat intake     beta\n",
       "21     ukb-b-7663  Types of physical activity in last 4 weeks: St...       or\n",
       "22      ukb-b-770                                  Other meat intake     beta\n",
       "23     ukb-b-8476                              Loneliness, isolation       or\n",
       "24      ukb-b-323  Illnesses of father: Alzheimer's disease/dementia       or\n",
       "25    ukb-b-14699  Illnesses of mother: Alzheimer's disease/dementia       or\n",
       "26    ukb-b-14180                                        Mood swings       or\n",
       "27    ukb-b-17243  Non-cancer illness code, self-reported: anxiet...       or\n",
       "28     ukb-b-6358     Non-cancer illness code, self-reported: stroke       or\n",
       "29    ukb-b-17006  Non-cancer illness code, self-reported: head i...       or\n",
       "30     ukb-b-5779                           Alcohol intake frequency     beta\n",
       "31    ukb-b-15541  Diagnoses - secondary ICD10: E66.9 Obesity, un...       or\n",
       "32    ukb-b-19732  Non-cancer illness code, self-reported: hypoth...       or\n",
       "33    ukb-b-20289  Non-cancer illness code, self-reported: hypert...       or\n",
       "34    ukb-b-14057  Non-cancer illness code, self-reported: hypert...       or\n",
       "35    ukb-b-12963    Particulate matter air pollution 2.5-10um; 2010     beta\n",
       "36    ukb-b-12417                Nitrogen oxides air pollution; 2010     beta\n",
       "37    ukb-b-11495  Types of physical activity in last 4 weeks: Li...       or\n",
       "38    ukb-b-12493  Diagnoses - secondary ICD10: I10 Essential (pr...       or"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ukb-b-13806 : Non-cancer illness code, self-reported: type 2 diabetes\n",
      "ukb-d-20405_0 : Ever had known person concerned about, or recommend reduction of, alcohol consumption: No\n",
      "ukb-d-20405_1 : Ever had known person concerned about, or recommend reduction of, alcohol consumption: Yes, but not in the last year\n",
      "ukb-d-20405_2 : Ever had known person concerned about, or recommend reduction of, alcohol consumption: Yes, during the last year\n",
      "met-d-Total_C : Total cholesterol\n",
      "ieu-b-109 : HDL cholesterol\n",
      "ieu-b-110 : LDL cholesterol\n",
      "ieu-b-111 : triglycerides\n",
      "ieu-b-25 : Cigarettes per Day\n",
      "ieu-b-38 : systolic blood pressure\n",
      "ieu-b-39 : diastolic blood pressure\n",
      "ukb-a-257 : Hearing difficulty/problems: Yes\n",
      "ukb-b-12064 : Non-cancer illness code, self-reported: depression\n",
      "ukb-b-17627 : Non-oily fish intake\n",
      "ukb-b-18275 : Hearing difficulty/problems with background noise\n",
      "ukb-b-19953 : Body mass index (BMI)\n",
      "ukb-b-2209 : Oily fish intake\n",
      "ukb-b-3957 : Sleeplessness / insomnia\n",
      "ukb-b-4424 : Sleep duration\n",
      "ukb-b-6134 : Age completed full time education\n",
      "ukb-b-6324 : Processed meat intake\n",
      "ukb-b-7663 : Types of physical activity in last 4 weeks: Strenuous sports\n",
      "ukb-b-770 : Other meat intake\n",
      "ukb-b-8476 : Loneliness, isolation\n",
      "ukb-b-323 : Illnesses of father: Alzheimer's disease/dementia\n",
      "ukb-b-14699 : Illnesses of mother: Alzheimer's disease/dementia\n",
      "ukb-b-14180 : Mood swings\n",
      "ukb-b-17243 : Non-cancer illness code, self-reported: anxiety/panic attacks\n",
      "ukb-b-6358 : Non-cancer illness code, self-reported: stroke\n",
      "ukb-b-17006 : Non-cancer illness code, self-reported: head injury\n",
      "ukb-b-5779 : Alcohol intake frequency\n",
      "ukb-b-15541 : Diagnoses - secondary ICD10: E66.9 Obesity, unspecified\n",
      "ukb-b-19732 : Non-cancer illness code, self-reported: hypothyroidism/myxoedema\n",
      "ukb-b-20289 : Non-cancer illness code, self-reported: hyperthyroidism/thyrotoxicosis\n",
      "ukb-b-14057 : Non-cancer illness code, self-reported: hypertension\n",
      "ukb-b-12963 : Particulate matter air pollution 2.5-10um; 2010\n",
      "ukb-b-12417 : Nitrogen oxides air pollution; 2010\n",
      "ukb-b-11495 : Types of physical activity in last 4 weeks: Light DIY (eg: pruning, watering the lawn)\n",
      "ukb-b-12493 : Diagnoses - secondary ICD10: I10 Essential (primary) hypertension\n",
      "['Non-cancer illness code, self-reported: type 2 diabetes', 'Ever had known person concerned about, or recommend reduction of, alcohol consumption: No', 'Ever had known person concerned about, or recommend reduction of, alcohol consumption: Yes, but not in the last year', 'Ever had known person concerned about, or recommend reduction of, alcohol consumption: Yes, during the last year', 'Total cholesterol', 'HDL cholesterol', 'LDL cholesterol', 'triglycerides', 'Cigarettes per Day', 'systolic blood pressure', 'diastolic blood pressure', 'Hearing difficulty/problems: Yes', 'Non-cancer illness code, self-reported: depression', 'Non-oily fish intake', 'Hearing difficulty/problems with background noise', 'Body mass index (BMI)', 'Oily fish intake', 'Sleeplessness / insomnia', 'Sleep duration', 'Age completed full time education', 'Processed meat intake', 'Types of physical activity in last 4 weeks: Strenuous sports', 'Other meat intake', 'Loneliness, isolation', \"Illnesses of father: Alzheimer's disease/dementia\", \"Illnesses of mother: Alzheimer's disease/dementia\", 'Mood swings', 'Non-cancer illness code, self-reported: anxiety/panic attacks', 'Non-cancer illness code, self-reported: stroke', 'Non-cancer illness code, self-reported: head injury', 'Alcohol intake frequency', 'Diagnoses - secondary ICD10: E66.9 Obesity, unspecified', 'Non-cancer illness code, self-reported: hypothyroidism/myxoedema', 'Non-cancer illness code, self-reported: hyperthyroidism/thyrotoxicosis', 'Non-cancer illness code, self-reported: hypertension', 'Particulate matter air pollution 2.5-10um; 2010', 'Nitrogen oxides air pollution; 2010', 'Types of physical activity in last 4 weeks: Light DIY (eg: pruning, watering the lawn)', 'Diagnoses - secondary ICD10: I10 Essential (primary) hypertension']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('GWAS_datasets_to_consider.xlsx', engine='openpyxl')[['GWAS_ID', 'Trait', 'Category']]\n",
    "all_traits = []\n",
    "for GWAS_ID in ALL_GWAS_IDS:\n",
    "    trait = str(df[df['GWAS_ID'] == GWAS_ID]['Trait'].to_numpy()[0])\n",
    "    print(GWAS_ID, ':', trait)\n",
    "    all_traits += [trait]\n",
    "print(all_traits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this is for demo purpose\n",
    "# prsice_command = f'Rscript ./PRSice_linux/PRSice.R --dir ./PRSice_linux\t\\\n",
    "# --prsice ./PRSice_linux/PRSice_linux     \\\n",
    "# --base ./PRSice_linux/simple_table_with_pval.txt     \\\n",
    "# --target ./PRSice_linux/ADNI_plink     \\\n",
    "# --thread 1     \\\n",
    "# --beta     \\\n",
    "# --binary-target F\t\\\n",
    "# --out ./PRSice_output/PRSice\t\\\n",
    "# --snp ID --chr CHROM --bp POS --A2 REF --A1 ALT --stat UKB-b-6134:ES --pvalue PVAL_generated_from_LP\t\\\n",
    "# --extract ./PRSice_output/PRSice.valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     # this is for demo purpose\n",
    "#     import os\n",
    "#     return_status = os.system(prsice_command) # generate the file named {GWAS_ID}.valid\n",
    "#     print('1a:', return_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
