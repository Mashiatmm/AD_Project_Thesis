{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes :\n",
    "When you add age and gender, the shap value does not give proper output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the input dataset :\n",
    "\n",
    "1. usable_samples_ADNI.json : stores the IID for each row of PRS_feature_matrix.npy\n",
    "2. PRS_feature_matrix.npy : PR Score for different features\n",
    "3. Covar_FILE_bigger_dataset : for reading covar such as age, gender\n",
    "4. Final_Samples.json : test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    def warn(*args, **kwargs):\n",
    "        pass\n",
    "    import warnings\n",
    "    warnings.warn = warn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import torch as t\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, precision_recall_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold \n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "import shap\n",
    "from copy import deepcopy\n",
    "\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the installed packages with their versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at C:\\ProgramData\\Anaconda3:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "_ipyw_jlab_nb_ext_conf    0.1.0                    py37_0  \n",
      "alabaster                 0.7.12                   py37_0  \n",
      "anaconda                  2020.02                  py37_0  \n",
      "anaconda-client           1.7.2                    py37_0  \n",
      "anaconda-navigator        1.9.12                   py37_0  \n",
      "anaconda-project          0.8.4                      py_0  \n",
      "appdirs                   1.4.3                    pypi_0    pypi\n",
      "argh                      0.26.2                   py37_0  \n",
      "asn1crypto                1.3.0                    py37_0  \n",
      "astroid                   2.3.3                    py37_0  \n",
      "astropy                   4.0              py37he774522_0  \n",
      "atomicwrites              1.3.0                    py37_1  \n",
      "attrs                     19.3.0                     py_0  \n",
      "autopep8                  1.4.4                      py_0  \n",
      "babel                     2.8.0                      py_0  \n",
      "backcall                  0.1.0                    py37_0  \n",
      "backports                 1.0                        py_2  \n",
      "backports.functools_lru_cache 1.6.1                      py_0  \n",
      "backports.shutil_get_terminal_size 1.0.0                    py37_2  \n",
      "backports.tempfile        1.0                        py_1  \n",
      "backports.weakref         1.0.post1                  py_1  \n",
      "bcrypt                    3.1.7            py37he774522_0  \n",
      "beautifulsoup4            4.8.2                    py37_0  \n",
      "bitarray                  1.2.1            py37he774522_0  \n",
      "bkcharts                  0.2                      py37_0  \n",
      "blas                      1.0                         mkl  \n",
      "bleach                    3.1.0                    py37_0  \n",
      "blosc                     1.16.3               h7bd577a_0  \n",
      "bokeh                     1.4.0                    py37_0  \n",
      "boto                      2.49.0                   py37_0  \n",
      "bottleneck                1.3.2            py37h2a96729_0  \n",
      "bzip2                     1.0.8                he774522_0  \n",
      "ca-certificates           2020.1.1                      0  \n",
      "certifi                   2019.11.28               py37_0  \n",
      "cffi                      1.14.0           py37h7a1dbc1_0  \n",
      "chardet                   3.0.4                 py37_1003  \n",
      "click                     7.0                      py37_0  \n",
      "cloudpickle               1.3.0                      py_0  \n",
      "clyent                    1.2.2                    py37_1  \n",
      "colorama                  0.4.3                      py_0  \n",
      "comtypes                  1.1.7                    py37_0  \n",
      "conda                     4.8.3                    py37_0  \n",
      "conda-build               3.18.11                  py37_0  \n",
      "conda-env                 2.6.0                         1  \n",
      "conda-package-handling    1.6.0            py37h62dcd97_0  \n",
      "conda-verify              3.4.2                      py_1  \n",
      "console_shortcut          0.1.1                         4  \n",
      "contextlib2               0.6.0.post1                py_0  \n",
      "cryptography              2.8              py37h7a1dbc1_0  \n",
      "curl                      7.68.0               h2a8f88b_0  \n",
      "cycler                    0.10.0                   py37_0  \n",
      "cython                    0.29.15          py37ha925a31_0  \n",
      "cytoolz                   0.10.1           py37he774522_0  \n",
      "dask                      2.11.0                     py_0  \n",
      "dask-core                 2.11.0                     py_0  \n",
      "decorator                 4.4.1                      py_0  \n",
      "defusedxml                0.6.0                      py_0  \n",
      "diff-match-patch          20181111                   py_0  \n",
      "distlib                   0.3.0                    pypi_0    pypi\n",
      "distributed               2.11.0                   py37_0  \n",
      "docutils                  0.16                     py37_0  \n",
      "en-core-web-md            2.2.5                    pypi_0    pypi\n",
      "entrypoints               0.3                      py37_0  \n",
      "et_xmlfile                1.0.1                    py37_0  \n",
      "fastcache                 1.1.0            py37he774522_0  \n",
      "filelock                  3.0.12                     py_0  \n",
      "flake8                    3.7.9                    py37_0  \n",
      "flask                     1.1.1                      py_0  \n",
      "freetype                  2.9.1                ha9979f8_1  \n",
      "fsspec                    0.6.2                      py_0  \n",
      "future                    0.18.2                   py37_0  \n",
      "get_terminal_size         1.0.0                h38e98db_0  \n",
      "gevent                    1.4.0            py37he774522_0  \n",
      "glob2                     0.7                        py_0  \n",
      "greenlet                  0.4.15           py37hfa6e2cd_0  \n",
      "h5py                      2.10.0           py37h5e291fa_0  \n",
      "hdf5                      1.10.4               h7ebc959_0  \n",
      "heapdict                  1.0.1                      py_0  \n",
      "html5lib                  1.0.1                    py37_0  \n",
      "hypothesis                5.5.4                      py_0  \n",
      "icc_rt                    2019.0.0             h0cc432a_1  \n",
      "icu                       58.2                 ha66f8fd_1  \n",
      "idna                      2.8                      py37_0  \n",
      "imageio                   2.6.1                    py37_0  \n",
      "imagesize                 1.2.0                      py_0  \n",
      "importlib_metadata        1.5.0                    py37_0  \n",
      "intel-openmp              2020.0                      166  \n",
      "intervaltree              3.0.2                      py_0  \n",
      "ipykernel                 5.1.4            py37h39e3cac_0  \n",
      "ipython                   7.12.0           py37h5ca1d4c_0  \n",
      "ipython_genutils          0.2.0                    py37_0  \n",
      "ipywidgets                7.5.1                      py_0  \n",
      "isort                     4.3.21                   py37_0  \n",
      "itsdangerous              1.1.0                    py37_0  \n",
      "jdcal                     1.4.1                      py_0  \n",
      "jedi                      0.14.1                   py37_0  \n",
      "jinja2                    2.11.1                     py_0  \n",
      "joblib                    0.14.1                     py_0  \n",
      "jpeg                      9b                   hb83a4c4_2  \n",
      "json5                     0.9.1                      py_0  \n",
      "jsonschema                3.2.0                    py37_0  \n",
      "jupyter                   1.0.0                    py37_7  \n",
      "jupyter_client            5.3.4                    py37_0  \n",
      "jupyter_console           6.1.0                      py_0  \n",
      "jupyter_core              4.6.1                    py37_0  \n",
      "jupyterlab                1.2.6              pyhf63ae98_0  \n",
      "jupyterlab_server         1.0.6                      py_0  \n",
      "kaggle                    1.5.9                    pypi_0    pypi\n",
      "keyring                   21.1.0                   py37_0  \n",
      "kiwisolver                1.1.0            py37ha925a31_0  \n",
      "krb5                      1.17.1               hc04afaa_0  \n",
      "lazy-object-proxy         1.4.3            py37he774522_0  \n",
      "libarchive                3.3.3                h0643e63_5  \n",
      "libcurl                   7.68.0               h2a8f88b_0  \n",
      "libiconv                  1.15                 h1df5818_7  \n",
      "liblief                   0.9.0                ha925a31_2  \n",
      "libpng                    1.6.37               h2a8f88b_0  \n",
      "libsodium                 1.0.16               h9d3ae62_0  \n",
      "libspatialindex           1.9.3                h33f27b4_0  \n",
      "libssh2                   1.8.2                h7a1dbc1_0  \n",
      "libtiff                   4.1.0                h56a325e_0  \n",
      "libxml2                   2.9.9                h464c3ec_0  \n",
      "libxslt                   1.1.33               h579f668_0  \n",
      "llvmlite                  0.31.0           py37ha925a31_0  \n",
      "locket                    0.2.0                    py37_1  \n",
      "lxml                      4.5.0            py37h1350720_0  \n",
      "lz4-c                     1.8.1.2              h2fa13f4_0  \n",
      "lzo                       2.10                 h6df0209_2  \n",
      "m2w64-gcc-libgfortran     5.3.0                         6  \n",
      "m2w64-gcc-libs            5.3.0                         7  \n",
      "m2w64-gcc-libs-core       5.3.0                         7  \n",
      "m2w64-gmp                 6.1.0                         2  \n",
      "m2w64-libwinpthread-git   5.0.0.4634.697f757               2  \n",
      "markupsafe                1.1.1            py37he774522_0  \n",
      "matplotlib                3.1.3                    py37_0  \n",
      "matplotlib-base           3.1.3            py37h64f37c6_0  \n",
      "mccabe                    0.6.1                    py37_1  \n",
      "menuinst                  1.4.16           py37he774522_0  \n",
      "mistune                   0.8.4            py37he774522_0  \n",
      "mkl                       2020.0                      166  \n",
      "mkl-service               2.3.0            py37hb782905_0  \n",
      "mkl_fft                   1.0.15           py37h14836fe_0  \n",
      "mkl_random                1.1.0            py37h675688f_0  \n",
      "mock                      4.0.1                      py_0  \n",
      "more-itertools            8.2.0                      py_0  \n",
      "mpmath                    1.1.0                    py37_0  \n",
      "msgpack-python            0.6.1            py37h74a9793_1  \n",
      "msys2-conda-epoch         20160418                      1  \n",
      "multipledispatch          0.6.0                    py37_0  \n",
      "murmurhash                1.0.2                    pypi_0    pypi\n",
      "navigator-updater         0.2.1                    py37_0  \n",
      "nbconvert                 5.6.1                    py37_0  \n",
      "nbformat                  5.0.4                      py_0  \n",
      "networkx                  2.4                        py_0  \n",
      "nltk                      3.4.5                    py37_0  \n",
      "nose                      1.3.7                    py37_2  \n",
      "notebook                  6.0.3                    py37_0  \n",
      "numba                     0.48.0           py37h47e9c7a_0  \n",
      "numexpr                   2.7.1            py37h25d0782_0  \n",
      "numpy                     1.18.1           py37h93ca92e_0  \n",
      "numpy-base                1.18.1           py37hc3f5095_1  \n",
      "numpydoc                  0.9.2                      py_0  \n",
      "olefile                   0.46                     py37_0  \n",
      "openpyxl                  3.0.3                      py_0  \n",
      "openssl                   1.1.1d               he774522_4  \n",
      "packaging                 20.1                     pypi_0    pypi\n",
      "pandas                    1.0.1            py37h47e9c7a_0  \n",
      "pandoc                    2.2.3.2                       0  \n",
      "pandocfilters             1.4.2                    py37_1  \n",
      "paramiko                  2.7.1                      py_0  \n",
      "parso                     0.5.2                      py_0  \n",
      "partd                     1.1.0                      py_0  \n",
      "path                      13.1.0                   py37_0  \n",
      "path.py                   12.4.0                        0  \n",
      "pathlib2                  2.3.5                    py37_0  \n",
      "pathtools                 0.1.2                      py_1  \n",
      "patsy                     0.5.1                    py37_0  \n",
      "pep8                      1.7.1                    py37_0  \n",
      "pexpect                   4.8.0                    py37_0  \n",
      "pickleshare               0.7.5                    py37_0  \n",
      "pillow                    7.0.0            py37hcc1f983_0  \n",
      "pip                       20.0.2                   py37_1  \n",
      "pkginfo                   1.5.0.1                  py37_0  \n",
      "plac                      1.1.3                    pypi_0    pypi\n",
      "pluggy                    0.13.1                   py37_0  \n",
      "ply                       3.11                     py37_0  \n",
      "powershell_shortcut       0.0.1                         3  \n",
      "prometheus_client         0.7.1                      py_0  \n",
      "prompt_toolkit            3.0.3                      py_0  \n",
      "psutil                    5.6.7            py37he774522_0  \n",
      "py                        1.8.1                      py_0  \n",
      "py-lief                   0.9.0            py37ha925a31_2  \n",
      "pycodestyle               2.5.0                    py37_0  \n",
      "pycosat                   0.6.3            py37he774522_0  \n",
      "pycparser                 2.19                     py37_0  \n",
      "pycrypto                  2.6.1            py37hfa6e2cd_9  \n",
      "pycurl                    7.43.0.5         py37h7a1dbc1_0  \n",
      "pydocstyle                4.0.1                      py_0  \n",
      "pyflakes                  2.1.1                    py37_0  \n",
      "pygame                    1.9.6                    pypi_0    pypi\n",
      "pygments                  2.5.2                      py_0  \n",
      "pylint                    2.4.4                    py37_0  \n",
      "pynacl                    1.3.0            py37h62dcd97_0  \n",
      "pyodbc                    4.0.30           py37ha925a31_0  \n",
      "pyopenssl                 19.1.0                   py37_0  \n",
      "pyparsing                 2.4.6                      py_0  \n",
      "pyqt                      5.9.2            py37h6538335_2  \n",
      "pyreadline                2.1                      py37_1  \n",
      "pyrsistent                0.15.7           py37he774522_0  \n",
      "pysocks                   1.7.1                    py37_0  \n",
      "pytables                  3.6.1            py37h1da0976_0  \n",
      "pytest                    5.3.5                    py37_0  \n",
      "pytest-arraydiff          0.3              py37h39e3cac_0  \n",
      "pytest-astropy            0.8.0                      py_0  \n",
      "pytest-astropy-header     0.1.2                      py_0  \n",
      "pytest-doctestplus        0.5.0                      py_0  \n",
      "pytest-openfiles          0.4.0                      py_0  \n",
      "pytest-remotedata         0.3.2                    py37_0  \n",
      "python                    3.7.6                h60c2a47_2  \n",
      "python-dateutil           2.8.1                      py_0  \n",
      "python-jsonrpc-server     0.3.4                      py_0  \n",
      "python-language-server    0.31.7                   py37_0  \n",
      "python-libarchive-c       2.8                     py37_13  \n",
      "python-slugify            4.0.1                    pypi_0    pypi\n",
      "pytz                      2019.3                     py_0  \n",
      "pywavelets                1.1.1            py37he774522_0  \n",
      "pywin32                   227              py37he774522_1  \n",
      "pywin32-ctypes            0.2.0                 py37_1000  \n",
      "pywinpty                  0.5.7                    py37_0  \n",
      "pyyaml                    5.3              py37he774522_0  \n",
      "pyzmq                     18.1.1           py37ha925a31_0  \n",
      "qdarkstyle                2.8                        py_0  \n",
      "qt                        5.9.7            vc14h73c81de_0  \n",
      "qtawesome                 0.6.1                      py_0  \n",
      "qtconsole                 4.6.0                      py_1  \n",
      "qtpy                      1.9.0                      py_0  \n",
      "requests                  2.22.0                   py37_1  \n",
      "rope                      0.16.0                     py_0  \n",
      "rtree                     0.9.3            py37h21ff451_0  \n",
      "ruamel_yaml               0.15.87          py37he774522_0  \n",
      "scikit-image              0.16.2           py37h47e9c7a_0  \n",
      "scikit-learn              0.22.1           py37h6288b17_0  \n",
      "scipy                     1.4.1            py37h9439919_0  \n",
      "seaborn                   0.10.0                     py_0  \n",
      "send2trash                1.5.0                    py37_0  \n",
      "setuptools                45.2.0                   py37_0  \n",
      "simplegeneric             0.8.1                    py37_2  \n",
      "singledispatch            3.4.0.3                  py37_0  \n",
      "sip                       4.19.8           py37h6538335_0  \n",
      "six                       1.14.0                   py37_0  \n",
      "slicer                    0.0.7                    pypi_0    pypi\n",
      "slugify                   0.0.1                    pypi_0    pypi\n",
      "snappy                    1.1.7                h777316e_3  \n",
      "snowballstemmer           2.0.0                      py_0  \n",
      "sortedcollections         1.1.2                    py37_0  \n",
      "sortedcontainers          2.1.0                    py37_0  \n",
      "soupsieve                 1.9.5                    py37_0  \n",
      "sphinx                    2.4.0                      py_0  \n",
      "sphinxcontrib             1.0                      py37_1  \n",
      "sphinxcontrib-applehelp   1.0.1                      py_0  \n",
      "sphinxcontrib-devhelp     1.0.1                      py_0  \n",
      "sphinxcontrib-htmlhelp    1.0.2                      py_0  \n",
      "sphinxcontrib-jsmath      1.0.1                      py_0  \n",
      "sphinxcontrib-qthelp      1.0.2                      py_0  \n",
      "sphinxcontrib-serializinghtml 1.1.3                      py_0  \n",
      "sphinxcontrib-websupport  1.2.0                      py_0  \n",
      "spyder                    4.0.1                    py37_0  \n",
      "spyder-kernels            1.8.1                    py37_0  \n",
      "sqlalchemy                1.3.13           py37he774522_0  \n",
      "sqlite                    3.31.1               he774522_0  \n",
      "srsly                     1.0.2                    pypi_0    pypi\n",
      "statsmodels               0.11.0           py37he774522_0  \n",
      "sympy                     1.5.1                    py37_0  \n",
      "tbb                       2020.0               h74a9793_0  \n",
      "tblib                     1.6.0                      py_0  \n",
      "terminado                 0.8.3                    py37_0  \n",
      "testpath                  0.4.4                      py_0  \n",
      "text-unidecode            1.3                      pypi_0    pypi\n",
      "thinc                     7.4.0                    pypi_0    pypi\n",
      "tk                        8.6.8                hfa6e2cd_0  \n",
      "toolz                     0.10.0                     py_0  \n",
      "torch                     1.12.0                   pypi_0    pypi\n",
      "torchvision               0.13.0                   pypi_0    pypi\n",
      "tornado                   6.0.3            py37he774522_3  \n",
      "tqdm                      4.42.1                     py_0  \n",
      "traitlets                 4.3.3                    py37_0  \n",
      "typing-extensions         4.3.0                    pypi_0    pypi\n",
      "ujson                     1.35             py37hfa6e2cd_0  \n",
      "unicodecsv                0.14.1                   py37_0  \n",
      "urllib3                   1.25.8                   py37_0  \n",
      "vboxapi                   1.0                      pypi_0    pypi\n",
      "vc                        14.1                 h0510ff6_4  \n",
      "virtualenv                20.0.16                  pypi_0    pypi\n",
      "vs2015_runtime            14.16.27012          hf0eaf9b_1  \n",
      "watchdog                  0.10.2                   py37_0  \n",
      "wcwidth                   0.1.8                      py_0  \n",
      "webencodings              0.5.1                    py37_1  \n",
      "werkzeug                  1.0.0                      py_0  \n",
      "wheel                     0.34.2                   py37_0  \n",
      "widgetsnbextension        3.5.1                    py37_0  \n",
      "win_inet_pton             1.1.0                    py37_0  \n",
      "win_unicode_console       0.5                      py37_0  \n",
      "wincertstore              0.2                      py37_0  \n",
      "winpty                    0.4.3                         4  \n",
      "wrapt                     1.11.2           py37he774522_0  \n",
      "xlrd                      1.2.0                    py37_0  \n",
      "xlsxwriter                1.2.7                      py_0  \n",
      "xlwings                   0.17.1                   py37_0  \n",
      "xlwt                      1.3.0                    py37_0  \n",
      "xmltodict                 0.12.0                     py_0  \n",
      "xz                        5.2.4                h2fa13f4_4  \n",
      "yaml                      0.1.7                hc54c509_2  \n",
      "yapf                      0.28.0                     py_0  \n",
      "zeromq                    4.3.1                h33f27b4_3  \n",
      "zict                      1.0.0                      py_0  \n",
      "zipp                      2.2.0                      py_0  \n",
      "zlib                      1.2.11               h62dcd97_3  \n",
      "zstd                      1.3.7                h508b16e_0  \n"
     ]
    }
   ],
   "source": [
    "!conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "Final_Samples_path = 'Final_Samples_6yrs.json'\n",
    "Final_Samples = json.load(open(Final_Samples_path, 'r')) \n",
    "usable_samples_ADNI = json.load(open('./usable_samples_ADNI.json'))\n",
    "PRS_orig_feature_matrix = np.load('./PRS_feature_matrix.npy').astype(np.float32)\n",
    "# normalize feature matrix\n",
    "PRS_orig_feature_matrix = (PRS_orig_feature_matrix - PRS_orig_feature_matrix.mean(0))/PRS_orig_feature_matrix.std(0)\n",
    "# PRS_orig_feature_matrix.shape[1], len(usable_samples_ADNI), usable_samples_ADNI\n",
    "num_features=PRS_orig_feature_matrix.shape[1]\n",
    "print(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (1817, 14)\n",
      "(1817, 2) (1817, 2)\n",
      "                FID               IID       PC1       PC2       PC3       PC4  \\\n",
      "0  ADNI3_036_S_6231  ADNI3_036_S_6231 -0.006724 -0.010617  0.001596 -0.000460   \n",
      "1  ADNI3_006_S_6277  ADNI3_006_S_6277 -0.010432 -0.010269  0.012757  0.006921   \n",
      "2  ADNI3_129_S_6146  ADNI3_129_S_6146 -0.004919 -0.011656 -0.035521  0.064641   \n",
      "3  ADNI3_033_S_6352  ADNI3_033_S_6352 -0.014069 -0.010279  0.020014  0.053023   \n",
      "4  ADNI3_027_S_6183  ADNI3_027_S_6183 -0.010766 -0.012370 -0.010960  0.029830   \n",
      "\n",
      "        PC5       PC6       PC7       PC8       PC9      PC10  PTGENDER    AGE  \n",
      "0 -0.013131 -0.005855 -0.005142 -0.009063 -0.001739 -0.012863         1  0.691  \n",
      "1 -0.014958 -0.005860 -0.027775 -0.009632  0.054966  0.087390         1  0.707  \n",
      "2  0.012094  0.003860  0.035955  0.006561  0.019736 -0.023304         1  0.655  \n",
      "3  0.023691  0.000247 -0.002273 -0.030627 -0.053461  0.049984         0  0.714  \n",
      "4 -0.019520 -0.001955  0.023844  0.079138  0.002207  0.008892         0  0.656  \n"
     ]
    }
   ],
   "source": [
    "covar_df = pd.read_csv('./COVAR_FILE_bigger_dataset.txt', ' ') \n",
    "print(\"shape\",covar_df.shape)\n",
    "print( covar_df[['AGE', 'PTGENDER']].shape, covar_df[['AGE', 'PTGENDER']].dropna().shape ) \n",
    "# PC - Principal Component\n",
    "\n",
    "# trying to normalize AGE with having max age of 100\n",
    "covar_df['AGE'] = covar_df['AGE'] / 100.0\n",
    "print( covar_df.head() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alter parameters :\n",
    "    1. Number of features\n",
    "    2. Number of Hidden Layers \n",
    "    3. Dimension of Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 39\n",
    "hidden = 4\n",
    "hidden_dimension = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1816, 39)\n"
     ]
    }
   ],
   "source": [
    "# take the first num_features column from PRS_feature_matrix\n",
    "PRS_feature_matrix = PRS_orig_feature_matrix\n",
    "PRS_feature_matrix = PRS_feature_matrix[:, :num_features]\n",
    "print(PRS_feature_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Samples has two columns of data :\n",
    "    1. ID \n",
    "    2. output - true / false\n",
    "    \n",
    "Get the length of positive and negative samples of test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "974\n",
      "654\n",
      "320\n"
     ]
    }
   ],
   "source": [
    "# positive samples - output true\n",
    "# negative samples - output false\n",
    "len_positive_samples = 0\n",
    "len_negative_samples = 0\n",
    "for x in Final_Samples:\n",
    "    if x[1] == 1 :\n",
    "        len_positive_samples += 1\n",
    "    else :\n",
    "        len_negative_samples += 1\n",
    "        \n",
    "print(len(Final_Samples))\n",
    "print(len_positive_samples)\n",
    "print(len_negative_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining covar data with PRS Feature Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before adding covar_df columns, shape :  (1816, 39)\n",
      "Before adding covar_df columns, shape :  (1816, 51)\n",
      "Count of missing samples for covar data :  234\n"
     ]
    }
   ],
   "source": [
    "# cnt = number of missing IDs for which covar data doesn't exist\n",
    "cnt = 0\n",
    "print(\"Before adding covar_df columns, shape : \",PRS_feature_matrix.shape)\n",
    "# adding ( total columns - 2 ) of covar_df , excluding FID, IID\n",
    "FEATURE_MATRIX = np.concatenate([PRS_feature_matrix, np.zeros([PRS_feature_matrix.shape[0], covar_df.shape[1] - 2 ])], 1).astype(np.float32)\n",
    "print(\"Before adding covar_df columns, shape : \",FEATURE_MATRIX.shape)\n",
    "for sample in usable_samples_ADNI:\n",
    "    # taking from the PCs, skipping the first two columns of IID, FID\n",
    "    covar = covar_df[covar_df['IID'] == sample].to_numpy()[:, 2:].astype(np.float32) \n",
    "    # shape[0] = 1 means a row is found in covar for the following sample ID\n",
    "    # if not, that means no covar data exists for the sample in usable_samples_ADNI\n",
    "    if covar.shape[0] != 1:\n",
    "#         print(covar.shape)\n",
    "#         print(sample)\n",
    "        cnt += 1\n",
    "        continue\n",
    "    # Adding the covar values to the feature matrix\n",
    "    FEATURE_MATRIX[usable_samples_ADNI[sample], num_features:] = covar\n",
    "\n",
    "\n",
    "print(\"Count of missing samples for covar data : \", cnt)\n",
    "#     FEATURE_MATRIX[usable_samples_ADNI[sample], num_features:] = covar # naeem's modification\n",
    "# cnt/FEATURE_MATRIX.shape[0], FEATURE_MATRIX[:2], PRS_feature_matrix[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create directory for saving shap figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./shap/\" + str(num_features)\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing the index with the Age = 0\n",
    "\n",
    "age is zero for the rows that the covar data was not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234\n"
     ]
    }
   ],
   "source": [
    "age_zero = 0\n",
    "age_zero_idx = []\n",
    "for i in range( len(FEATURE_MATRIX) ):\n",
    "    if FEATURE_MATRIX[i, -1] == 0.00:\n",
    "        age_zero += 1\n",
    "        age_zero_idx.append(i)\n",
    "        \n",
    "print(age_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indices of features to consider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 49, 50]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# feature_indices_to_consider = list(range(23))#list(range(35)) #[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 18, 20, 22]\n",
    "# naeem modified\n",
    "print(FEATURE_MATRIX.shape[1])\n",
    "last_idx = FEATURE_MATRIX.shape[1] - 1\n",
    "feature_indices_to_consider = list(range(num_features))  + [last_idx - 1, last_idx] #list(range(35)) #[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 18, 20, 22]\n",
    "# remove_indices = [1, 2, 3]\n",
    "# for i in remove_indices:\n",
    "#     feature_indices_to_consider.remove(i)\n",
    "\n",
    "# feature_indices_to_consider = list(range(23, 36))\n",
    "\n",
    "# feature_indices_to_consider = [ 4, 11, 14, 21, 23, 26, 32, 34, 46]\n",
    "\n",
    "# feature_indices_to_consider = [ 9, 10, 11, 14, 21, 23, 26, 28, 32, 34, 46]\n",
    "# feature_indices_to_consider = [9, 10, 28, 34, 46]\n",
    "\n",
    "print(feature_indices_to_consider)\n",
    "# feature_indices_to_consider = [1, 2, 3, 11, 14, 21, 23, 26, 32, 45]\n",
    "# feature_indices_to_consider = [2, 26, 32, 45]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions & Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_in_file: saves model accuracy in a text file\n",
    "#     args : model_name : name of model with layers and dimensions\n",
    "#            accuracy : accuracy  score\n",
    "def save_in_file(model_name, accuracy):\n",
    "    model_file = open(\"model_details.txt\",\"a\")\n",
    "    model_file.write(model_name + \" -> accuracy : \" + str(accuracy) + \"\\n\" )\n",
    "    model_file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simple_model(nn.Module):\n",
    "    def __init__(self, num_features=FEATURE_MATRIX.shape[1], hidden_dim= hidden_dimension, drop_probab=.5):\n",
    "        super(simple_model, self).__init__()\n",
    "        \n",
    "        ####\n",
    "        num_hidden = hidden\n",
    "        hidden_dim = hidden_dimension\n",
    "        self.fc1 = nn.Linear(num_features, hidden_dim)\n",
    "        self.fc_hidden = nn.ModuleList([nn.Linear(hidden_dim, hidden_dim) for i in range(num_hidden)])\n",
    "        self.fc2 = nn.Linear(hidden_dim, 8)\n",
    "        self.outLayer = nn.Linear(8, 1)\n",
    "#         self.softmax = nn.Softmax(-1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.num_hidden = num_hidden\n",
    "        self.drop_probab = drop_probab\n",
    "        self.dropout = nn.functional.dropout\n",
    "        ####\n",
    "\n",
    "    def forward(self, features):\n",
    "        features = self.fc1(features)\n",
    "        features = self.dropout(features, p=self.drop_probab)\n",
    "        for i in range(self.num_hidden):\n",
    "            features = self.fc_hidden[i](features)\n",
    "        features = self.fc2(features)\n",
    "        features = self.dropout(features, p=self.drop_probab)\n",
    "        logit = self.outLayer(features)\n",
    "#         print(features.shape, features)\n",
    "        probab = self.sigmoid(logit)\n",
    "        return probab\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "simple_model(\n",
       "  (fc1): Linear(in_features=41, out_features=32, bias=True)\n",
       "  (fc_hidden): ModuleList(\n",
       "    (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (3): Linear(in_features=32, out_features=32, bias=True)\n",
       "  )\n",
       "  (fc2): Linear(in_features=32, out_features=8, bias=True)\n",
       "  (outLayer): Linear(in_features=8, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model(num_features=len(feature_indices_to_consider))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataSet class \n",
    "combines usable_samples_ADNI, Final_Samples, feature_matrix to one dataset with features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataSet(data.Dataset):\n",
    "    def __init__(self, Final_Samples, feature_matrix, usable_samples_ADNI, feature_indices_to_consider=feature_indices_to_consider):\n",
    "        super(dataSet, self).__init__()  \n",
    "        self.data_len = len(Final_Samples)\n",
    "        self.usable_samples_ADNI = usable_samples_ADNI\n",
    "        self.Final_Samples = Final_Samples\n",
    "        self.feature_indices_to_consider = feature_indices_to_consider\n",
    "        self.feature_matrix = feature_matrix[:, self.feature_indices_to_consider]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        features = torch.from_numpy(self.feature_matrix[self.usable_samples_ADNI[self.Final_Samples[index][0]]]).float()\n",
    "        label = torch.tensor([float(self.Final_Samples[index][1])]).float()\n",
    "        return features, label\n",
    "    \n",
    "    def update_prs_features(self, mean, std):\n",
    "        self.feature_matrix = (self.feature_matrix - mean) / std\n",
    "        \n",
    "    def get_mean_std(self):\n",
    "        mean = self.feature_matrix.mean(0)\n",
    "        std = self.feature_matrix.std(0)\n",
    "        return mean, std\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Pandas Dataframe to Dataset class\n",
    "\n",
    "overriding the constructor, getitem, len function of the original class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class df_dataSet(data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        \n",
    "        self.features = torch.tensor(X.values, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(y.values, dtype=torch.float32)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.features[index], self.labels[index]\n",
    "    \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min length :  320\n",
      "320 320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1816, 41)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random samples : sample test dataset taking equal number of positive & negative outputs\n",
    "#                 args : \n",
    "#                         total_folds : fold number for splitting\n",
    "#                         random_seed : seed value for randomization\n",
    "#                 return :\n",
    "#                         N_splits : test dataset splitted according to fold numbers\n",
    "                        \n",
    "def random_samples(total_folds, random_seed=None):\n",
    "    Final_Samples = json.load(open(Final_Samples_path, 'r')) \n",
    "    positive_samples = Final_Samples[:len_positive_samples]\n",
    "    negative_samples = Final_Samples[len_positive_samples:]\n",
    "    min_len = min( len(positive_samples), len(negative_samples))\n",
    "    if random_seed is not None: \n",
    "        random.seed(random_seed * 2)\n",
    "    random.shuffle(positive_samples)\n",
    "    random.shuffle(negative_samples)\n",
    "    print(\"min length : \", min_len)\n",
    "    Final_Samples = positive_samples[:min_len] + negative_samples[:min_len]\n",
    "    random.shuffle(Final_Samples)\n",
    "    print(len([x[1] for x in Final_Samples if x[1] == 1]), len([x[1] for x in Final_Samples if x[1] == 0]))\n",
    "    Final_Samples = np.array(Final_Samples)\n",
    "\n",
    "#   -----------------------------------------------------------------------\n",
    "#     positive_samples = Final_Samples[:654]\n",
    "#     negative_samples = Final_Samples[654:]\n",
    "#     if random_seed is not None: \n",
    "#         random.seed(random_seed * 2)\n",
    "#     random.shuffle(positive_samples)\n",
    "#     random.shuffle(negative_samples)\n",
    "#     Final_Samples = positive_samples[:500] + negative_samples[:500]\n",
    "#     if random_seed is not None: \n",
    "#         random.seed(random_seed)\n",
    "#     random.shuffle(Final_Samples)\n",
    "#     Final_Samples = np.array(Final_Samples)\n",
    "# --------------------------------------------------------------------------\n",
    "    N_splits = Final_Samples.reshape(total_folds, -1, 2)\n",
    "    return N_splits\n",
    "\n",
    "# generate_datasets : get train, validation & test datasets\n",
    "#                 args : \n",
    "#                         N_splits : data splitted according to folds; output of random samples\n",
    "#                         fold_num : fold_num for test dataset\n",
    "#                         random_seed : seed value for randomization\n",
    "#                 return :\n",
    "#                         train_set, test_set, val_set : datasets\n",
    "def generate_datasets(N_splits, fold_num, random_seed):\n",
    "    test_samples = N_splits[fold_num:fold_num+1].reshape([-1, 2])\n",
    "    train_samples = np.concatenate([N_splits[0:fold_num],N_splits[fold_num+1:]], 0).reshape([-1, 2]).tolist()\n",
    "    if random_seed is not None: \n",
    "        random.seed(random_seed * 3)\n",
    "    random.shuffle(train_samples)\n",
    "    train_samples = np.array(train_samples)\n",
    "    # take all as training dataset, leaves nothing for validation - multiply shpae by 1\n",
    "    split_pos = int(train_samples.shape[0] * 1.) \n",
    "    #split_pos = int(train_samples.shape[0] * .8) \n",
    "#     print(train_samples.shape, split_pos, train_samples.shape[0])\n",
    "    train_samples, val_samples = train_samples[:split_pos], train_samples[split_pos:]\n",
    "    train_set = dataSet(Final_Samples=train_samples, \n",
    "                        feature_matrix=FEATURE_MATRIX, \n",
    "                        usable_samples_ADNI=usable_samples_ADNI)\n",
    "    val_set = dataSet(Final_Samples=val_samples, \n",
    "                      feature_matrix=FEATURE_MATRIX, \n",
    "                      usable_samples_ADNI=usable_samples_ADNI)\n",
    "    test_set = dataSet(Final_Samples=test_samples, \n",
    "                      feature_matrix=FEATURE_MATRIX, \n",
    "                      usable_samples_ADNI=usable_samples_ADNI)\n",
    "    mean, std = train_set.get_mean_std()\n",
    "    # normalize dataset\n",
    "    train_set.update_prs_features(mean, std)\n",
    "    val_set.update_prs_features(mean, std)\n",
    "    test_set.update_prs_features(mean, std)\n",
    "#     print(len(train_set))\n",
    "#     print(len(val_set))\n",
    "#     print(len(test_set))\n",
    "    return train_set, val_set, test_set\n",
    "\n",
    "\n",
    "\n",
    "# generate_loader : get train, validation & test as torch dataset\n",
    "#                 args : \n",
    "#                         train_set, test_set, val_set : datasets\n",
    "#                 returns :\n",
    "#                         train, val & test torch datasets\n",
    "def generate_loader(train_set, val_set, test_set, num_workers):\n",
    "    train_batch_size = train_set.__len__()\n",
    "    val_batch_size = val_set.__len__()\n",
    "    test_batch_size = test_set.__len__()\n",
    "    train_loader = torch.utils.data.DataLoader(train_set,\n",
    "                                              batch_size=train_batch_size,\n",
    "                                              shuffle=True,\n",
    "                                              pin_memory=(torch.cuda.is_available()),\n",
    "                                              num_workers=num_workers)\n",
    "    val_loader = torch.utils.data.DataLoader(val_set,\n",
    "                                              batch_size=val_batch_size,\n",
    "                                              shuffle=False,\n",
    "                                              pin_memory=(torch.cuda.is_available()),\n",
    "                                              num_workers=num_workers)\n",
    "    test_loader = torch.utils.data.DataLoader(test_set,\n",
    "                                              batch_size=test_batch_size,\n",
    "                                              shuffle=False,\n",
    "                                              pin_memory=(torch.cuda.is_available()),\n",
    "                                              num_workers=num_workers)\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "train_set, val_set, test_set = generate_datasets(N_splits=random_samples(total_folds=10, random_seed=0), fold_num=0, random_seed=0)\n",
    "val_set.feature_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch function : runs an epoch of a model\n",
    "#                 args :\n",
    "#                         model : neural network model\n",
    "#                         optimizer :\n",
    "#                         criterion :\n",
    "#                         is_training : train - true or test - false\n",
    "#                         loader : torch dataset\n",
    "#                 returns :\n",
    "#                         different accuracy score for the dataset of per epoch\n",
    "def epoch(model, optimizer, criterion, is_training, loader):\n",
    "    pred = []\n",
    "    true = []\n",
    "    total_loss = 0.\n",
    "#     print(loader)\n",
    "    for batch_idx, (features, label) in enumerate(loader):\n",
    "        features = torch.autograd.Variable(features.to(DEVICE).float())\n",
    "        label = torch.autograd.Variable(label.to(DEVICE).float())\n",
    "        label = torch.reshape(label, (label.shape[0], 1))\n",
    "        probab = model(features)\n",
    "        if is_training:  \n",
    "#             print(probab.shape, label.shape)\n",
    "            loss = criterion(probab, label)\n",
    "            ## compute gradient and do SGD step \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "#             print(batch_idx, ':', loss) \n",
    "        pred += probab.detach().cpu().numpy().tolist()\n",
    "        true += label.detach().cpu().numpy().tolist()\n",
    "    \n",
    "    pred, true, total_loss = np.array(pred).reshape([-1]), np.array(true).reshape([-1]), total_loss\n",
    "    pred_binary = (pred > .5).astype(float)\n",
    "    precision, recall, fscore, support = precision_recall_fscore_support(true, pred_binary)\n",
    "    auroc = roc_auc_score(true, pred)\n",
    "    p, r, thresholds = precision_recall_curve(true, pred)\n",
    "    auprc = auc(r, p)\n",
    "    acc = (pred_binary==true).mean()\n",
    "    \n",
    "    return precision[1], recall[1], fscore[1], support, auroc, auprc, acc, total_loss, pred, pred_binary, true\n",
    "#     return None, None, None, None, None, None, acc, total_loss, pred, pred_binary, true\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# usable_samples_ADNI from a PRSice output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1816\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "GWAS_ID = 'ieu-b-25'\n",
    "usable_samples_ADNI = pd.read_csv(f'./PRSice_output/{GWAS_ID}/{GWAS_ID}.best', ' ')['IID'].to_numpy().tolist()\n",
    "usable_samples_ADNI = {'_'.join(sample.split('_')[1:]):idx for idx,sample in enumerate(usable_samples_ADNI)}\n",
    "# usable_samples_ADNI = {sample:idx for idx,sample in enumerate(usable_samples_ADNI)}\n",
    "print(len( usable_samples_ADNI ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "974\n",
      "974\n",
      "Shape of usable features :  (974, 41)\n"
     ]
    }
   ],
   "source": [
    "# usable_indices : take indices from usable_samples_ADNI which are in Final_Samples\n",
    "# usable_features : take the part of feature matrix with usable_indices( rows )\n",
    "#                   and feature_indices_to_consider ( columns )\n",
    "\n",
    "print(len(Final_Samples))\n",
    "usable_indices = [( usable_samples_ADNI[Final_Samples[i][0]] if ( Final_Samples[i][0] in usable_samples_ADNI.keys() ) else None ) for i in range(len(Final_Samples))]\n",
    "print(len(usable_indices))\n",
    "# print(usable_indices)\n",
    "usable_features = FEATURE_MATRIX[usable_indices][:, feature_indices_to_consider]\n",
    "print(\"Shape of usable features : \", usable_features.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing age values with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166\n",
      "(974, 41) 974\n",
      "(808, 41) 808\n",
      "['012_S_0689' '1']\n"
     ]
    }
   ],
   "source": [
    "# removing age with value 0\n",
    "#--------------------------------------------------------------------------------\n",
    "age_zero = 0\n",
    "age_zero_idx = []\n",
    "for i in range(len(usable_features)):\n",
    "    if usable_features[i, -1] == 0.00:\n",
    "        age_zero += 1\n",
    "        age_zero_idx.append(i)\n",
    "print(len(age_zero_idx))\n",
    "print(usable_features.shape, len( Final_Samples ) )\n",
    "usable_features = np.delete(usable_features, age_zero_idx, axis = 0)\n",
    "Final_Samples = np.delete(Final_Samples, age_zero_idx, axis = 0)\n",
    "print(usable_features.shape, len( Final_Samples ) )\n",
    "print(Final_Samples[0])\n",
    "#--------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# usable_labels : output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of usable labels :  808\n"
     ]
    }
   ],
   "source": [
    "usable_labels = np.array([float(Final_Samples[i][1]) for i in range(len(Final_Samples))])\n",
    "print(\"Length of usable labels : \", len(usable_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read all traits from json file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Non-cancer illness code, self-reported: type 2 diabetes', 'Ever had known person concerned about, or recommend reduction of, alcohol consumption: No', 'Ever had known person concerned about, or recommend reduction of, alcohol consumption: Yes, but not in the last year', 'Ever had known person concerned about, or recommend reduction of, alcohol consumption: Yes, during the last year', 'Total cholesterol', 'HDL cholesterol', 'LDL cholesterol', 'triglycerides', 'Cigarettes per Day', 'systolic blood pressure', 'diastolic blood pressure', 'Hearing difficulty/problems: Yes', 'Non-cancer illness code, self-reported: depression', 'Non-oily fish intake', 'Hearing difficulty/problems with background noise', 'Body mass index (BMI)', 'Oily fish intake', 'Sleeplessness / insomnia', 'Sleep duration', 'Age completed full time education', 'Processed meat intake', 'Types of physical activity in last 4 weeks: Strenuous sports', 'Other meat intake', 'Loneliness, isolation', \"Illnesses of father: Alzheimer's disease/dementia\", \"Illnesses of mother: Alzheimer's disease/dementia\", 'Mood swings', 'Non-cancer illness code, self-reported: anxiety/panic attacks', 'Non-cancer illness code, self-reported: stroke', 'Non-cancer illness code, self-reported: head injury', 'Alcohol intake frequency', 'Diagnoses - secondary ICD10: E66.9 Obesity, unspecified', 'Non-cancer illness code, self-reported: hypothyroidism/myxoedema', 'Non-cancer illness code, self-reported: hyperthyroidism/thyrotoxicosis', 'Non-cancer illness code, self-reported: hypertension', 'Particulate matter air pollution 2.5-10um; 2010', 'Nitrogen oxides air pollution; 2010', 'Types of physical activity in last 4 weeks: Light DIY (eg: pruning, watering the lawn)', 'Diagnoses - secondary ICD10: I10 Essential (primary) hypertension']\n"
     ]
    }
   ],
   "source": [
    "all_traits = json.load(open('traits_map.json', 'r'))\n",
    "# print(all_traits)\n",
    "GWAS_IDS = list(all_traits)\n",
    "# print(GWAS_IDS)\n",
    "traits = [all_traits[x] for x in all_traits]\n",
    "print(traits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get traits corresponding to features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "39\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 49, 50]\n",
      "49\n",
      "gender_include\n",
      "50\n",
      "age include\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38]\n",
      "['Non-cancer illness code, self-reported: type 2 diabetes', 'Ever had known person concerned about, or recommend reduction of, alcohol consumption: No', 'Ever had known person concerned about, or recommend reduction of, alcohol consumption: Yes, but not in the last year', 'Ever had known person concerned about, or recommend reduction of, alcohol consumption: Yes, during the last year', 'Total cholesterol', 'HDL cholesterol', 'LDL cholesterol', 'triglycerides', 'Cigarettes per Day', 'systolic blood pressure', 'diastolic blood pressure', 'Hearing difficulty/problems: Yes', 'Non-cancer illness code, self-reported: depression', 'Non-oily fish intake', 'Hearing difficulty/problems with background noise', 'Body mass index (BMI)', 'Oily fish intake', 'Sleeplessness / insomnia', 'Sleep duration', 'Age completed full time education', 'Processed meat intake', 'Types of physical activity in last 4 weeks: Strenuous sports', 'Other meat intake', 'Loneliness, isolation', \"Illnesses of father: Alzheimer's disease/dementia\", \"Illnesses of mother: Alzheimer's disease/dementia\", 'Mood swings', 'Non-cancer illness code, self-reported: anxiety/panic attacks', 'Non-cancer illness code, self-reported: stroke', 'Non-cancer illness code, self-reported: head injury', 'Alcohol intake frequency', 'Diagnoses - secondary ICD10: E66.9 Obesity, unspecified', 'Non-cancer illness code, self-reported: hypothyroidism/myxoedema', 'Non-cancer illness code, self-reported: hyperthyroidism/thyrotoxicosis', 'Non-cancer illness code, self-reported: hypertension', 'Particulate matter air pollution 2.5-10um; 2010', 'Nitrogen oxides air pollution; 2010', 'Types of physical activity in last 4 weeks: Light DIY (eg: pruning, watering the lawn)', 'Diagnoses - secondary ICD10: I10 Essential (primary) hypertension', 'gender', 'age']\n"
     ]
    }
   ],
   "source": [
    "print(PRS_orig_feature_matrix.shape[1])\n",
    "# print(feature_indices_to_consider)\n",
    "\n",
    "print(len(traits))\n",
    "print(feature_indices_to_consider)\n",
    "\n",
    "# check if age and gender is included\n",
    "# if they are included, their index will be larger than the original feature matrix\n",
    "if any(y >PRS_orig_feature_matrix.shape[1] for y in feature_indices_to_consider):\n",
    "    features = feature_indices_to_consider.copy()\n",
    "    age_include = False\n",
    "    gender_include = False\n",
    "    print(features[-2])\n",
    "    if(features[-2] == PRS_orig_feature_matrix.shape[1] + 10):\n",
    "        print(\"gender_include\")\n",
    "        features.pop(-2)\n",
    "        gender_include = True\n",
    "    print(features[-1])\n",
    "    if(features[-1] == PRS_orig_feature_matrix.shape[1] + 11):\n",
    "        print(\"age include\")\n",
    "        features.pop(-1)\n",
    "        age_include = True\n",
    "    \n",
    "    print(features)\n",
    "    traits = [ traits[i] for i in features]\n",
    "    if gender_include == True:\n",
    "        traits.append(\"gender\")\n",
    "    if age_include == True:\n",
    "        traits.append(\"age\")\n",
    "    \n",
    "#     traits.append(\"output prediction\")\n",
    "#     traits.append(\"age\")\n",
    "#     traits.append(\"gender\")\n",
    "else:\n",
    "    # not included - age, gender\n",
    "    traits = [ traits[i] for i in feature_indices_to_consider]\n",
    "print(traits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Panda dataframe conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Non-cancer illness code, self-reported: type 2 diabetes  \\\n",
      "0                                          -0.199552         \n",
      "1                                          -1.424821         \n",
      "2                                           0.197245         \n",
      "3                                           0.282853         \n",
      "4                                          -1.470427         \n",
      "\n",
      "   Ever had known person concerned about, or recommend reduction of, alcohol consumption: No  \\\n",
      "0                                          -0.078667                                           \n",
      "1                                          -0.030907                                           \n",
      "2                                           0.210018                                           \n",
      "3                                          -0.344919                                           \n",
      "4                                          -0.242059                                           \n",
      "\n",
      "   Ever had known person concerned about, or recommend reduction of, alcohol consumption: Yes, but not in the last year  \\\n",
      "0                                           0.533900                                                                      \n",
      "1                                           0.752546                                                                      \n",
      "2                                          -0.088817                                                                      \n",
      "3                                          -0.129505                                                                      \n",
      "4                                          -0.428346                                                                      \n",
      "\n",
      "   Ever had known person concerned about, or recommend reduction of, alcohol consumption: Yes, during the last year  \\\n",
      "0                                           0.902520                                                                  \n",
      "1                                          -0.213336                                                                  \n",
      "2                                          -0.267127                                                                  \n",
      "3                                           0.714236                                                                  \n",
      "4                                          -0.492558                                                                  \n",
      "\n",
      "   Total cholesterol  HDL cholesterol  LDL cholesterol  triglycerides  \\\n",
      "0           1.289177        -0.101959         0.955844       0.096106   \n",
      "1          -0.037941         0.639087         0.193886      -0.679011   \n",
      "2          -0.811164         0.222568        -0.532153      -0.549571   \n",
      "3           0.455240        -0.158346        -0.081108      -1.123990   \n",
      "4          -0.180141        -1.691231        -0.819078      -0.004684   \n",
      "\n",
      "   Cigarettes per Day  systolic blood pressure  ...  \\\n",
      "0           -0.167859                 0.407097  ...   \n",
      "1            0.461611                 1.672851  ...   \n",
      "2            0.347313                 1.623332  ...   \n",
      "3            1.559013                 0.280248  ...   \n",
      "4            0.951004                 0.877744  ...   \n",
      "\n",
      "   Non-cancer illness code, self-reported: hypothyroidism/myxoedema  \\\n",
      "0                                           0.470350                  \n",
      "1                                          -0.284196                  \n",
      "2                                          -0.196247                  \n",
      "3                                           0.518326                  \n",
      "4                                          -0.014251                  \n",
      "\n",
      "   Non-cancer illness code, self-reported: hyperthyroidism/thyrotoxicosis  \\\n",
      "0                                          -0.102107                        \n",
      "1                                          -0.486811                        \n",
      "2                                          -0.672931                        \n",
      "3                                          -1.382669                        \n",
      "4                                          -1.219903                        \n",
      "\n",
      "   Non-cancer illness code, self-reported: hypertension  \\\n",
      "0                                           0.101466      \n",
      "1                                           0.094323      \n",
      "2                                          -0.321495      \n",
      "3                                           0.164900      \n",
      "4                                          -0.178165      \n",
      "\n",
      "   Particulate matter air pollution 2.5-10um; 2010  \\\n",
      "0                                         0.013099   \n",
      "1                                        -0.433962   \n",
      "2                                        -0.927708   \n",
      "3                                        -0.619431   \n",
      "4                                        -0.159202   \n",
      "\n",
      "   Nitrogen oxides air pollution; 2010  \\\n",
      "0                            -0.401920   \n",
      "1                            -0.312076   \n",
      "2                            -0.590049   \n",
      "3                             0.001594   \n",
      "4                            -0.630256   \n",
      "\n",
      "   Types of physical activity in last 4 weeks: Light DIY (eg: pruning, watering the lawn)  \\\n",
      "0                                           0.211109                                        \n",
      "1                                          -0.576694                                        \n",
      "2                                          -0.461158                                        \n",
      "3                                           0.245050                                        \n",
      "4                                          -0.414213                                        \n",
      "\n",
      "   Diagnoses - secondary ICD10: I10 Essential (primary) hypertension  gender  \\\n",
      "0                                           0.198678                     0.0   \n",
      "1                                          -0.516837                     0.0   \n",
      "2                                          -0.249631                     1.0   \n",
      "3                                           0.128983                     0.0   \n",
      "4                                          -0.117418                     1.0   \n",
      "\n",
      "     age  output  \n",
      "0  0.636     1.0  \n",
      "1  0.753     1.0  \n",
      "2  0.739     1.0  \n",
      "3  0.826     1.0  \n",
      "4  0.757     1.0  \n",
      "\n",
      "[5 rows x 42 columns]\n"
     ]
    }
   ],
   "source": [
    "total_features = np.c_[ usable_features, usable_labels ]\n",
    "# print(total_features.shape)\n",
    "# print(num_features)\n",
    "# column_list = list(range(num_features)) + [last_idx - 1, last_idx - 2, num_features ] \n",
    "column_list = feature_indices_to_consider + [num_features]\n",
    "# print( column_list )\n",
    "\n",
    "df = pd.DataFrame(total_features, columns = column_list )\n",
    "\n",
    "# turn column names to strings\n",
    "# df.columns = df.columns.astype(str)\n",
    "\n",
    "# assign traits as column names\n",
    "column_names = traits.copy()\n",
    "column_names.append('output')\n",
    "df.columns = column_names\n",
    "# print( df.columns )\n",
    "\n",
    "# dropping last / output column in df\n",
    "df_X = df.iloc[: , :-1]\n",
    "# taking the output column of df\n",
    "df_Y = df.iloc[: , -1]\n",
    "\n",
    "print( df.head() )\n",
    "# print( df_X.head() )\n",
    "# print( df_Y.head() )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get equal amount of positive & negative data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    576\n",
      "0.0    232\n",
      "Name: output, dtype: int64\n",
      "(464, 42)\n"
     ]
    }
   ],
   "source": [
    "print( df['output'].value_counts() )\n",
    "\n",
    "ones = df[df['output'] == 1]\n",
    "zeros = df[df['output'] == 0]\n",
    "min_len = min( len(ones), len(zeros) ) \n",
    "\n",
    "ones = ones.iloc[:min_len, :]\n",
    "zeros = zeros.iloc[:min_len, :]\n",
    "\n",
    "df = ones.append(zeros, ignore_index=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffling dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Non-cancer illness code, self-reported: type 2 diabetes  \\\n",
      "0                                          -0.421382         \n",
      "1                                           0.688749         \n",
      "2                                           1.121913         \n",
      "3                                           0.194266         \n",
      "4                                           0.552410         \n",
      "\n",
      "   Ever had known person concerned about, or recommend reduction of, alcohol consumption: No  \\\n",
      "0                                          -0.599900                                           \n",
      "1                                           0.020808                                           \n",
      "2                                           0.424100                                           \n",
      "3                                          -0.062207                                           \n",
      "4                                          -1.291026                                           \n",
      "\n",
      "   Ever had known person concerned about, or recommend reduction of, alcohol consumption: Yes, but not in the last year  \\\n",
      "0                                          -0.337019                                                                      \n",
      "1                                           1.277872                                                                      \n",
      "2                                           0.781011                                                                      \n",
      "3                                           1.252684                                                                      \n",
      "4                                           0.827579                                                                      \n",
      "\n",
      "   Ever had known person concerned about, or recommend reduction of, alcohol consumption: Yes, during the last year  \\\n",
      "0                                          -0.504597                                                                  \n",
      "1                                           0.528241                                                                  \n",
      "2                                           1.336627                                                                  \n",
      "3                                          -1.021808                                                                  \n",
      "4                                          -0.623034                                                                  \n",
      "\n",
      "   Total cholesterol  HDL cholesterol  LDL cholesterol  triglycerides  \\\n",
      "0          -1.261271         1.053050        -1.261458      -2.877441   \n",
      "1           0.055195        -0.249925         0.807666      -0.798085   \n",
      "2           1.108847        -0.581287         0.944888       2.447461   \n",
      "3           0.847331         0.002001         1.394513       0.364300   \n",
      "4           0.791683         1.483333         1.399949      -1.209215   \n",
      "\n",
      "   Cigarettes per Day  systolic blood pressure  ...  \\\n",
      "0           -0.944212                 0.533938  ...   \n",
      "1           -2.310074                -0.321179  ...   \n",
      "2           -0.383240                 0.286876  ...   \n",
      "3            1.298409                 0.233528  ...   \n",
      "4           -0.777571                 2.182085  ...   \n",
      "\n",
      "   Non-cancer illness code, self-reported: hypothyroidism/myxoedema  \\\n",
      "0                                          -0.707556                  \n",
      "1                                           0.482980                  \n",
      "2                                           1.019929                  \n",
      "3                                          -0.677044                  \n",
      "4                                          -1.048461                  \n",
      "\n",
      "   Non-cancer illness code, self-reported: hyperthyroidism/thyrotoxicosis  \\\n",
      "0                                           1.114374                        \n",
      "1                                           0.944520                        \n",
      "2                                           0.492285                        \n",
      "3                                           0.265637                        \n",
      "4                                          -0.574402                        \n",
      "\n",
      "   Non-cancer illness code, self-reported: hypertension  \\\n",
      "0                                          -0.465929      \n",
      "1                                           0.923035      \n",
      "2                                           0.986780      \n",
      "3                                          -0.870738      \n",
      "4                                          -1.175289      \n",
      "\n",
      "   Particulate matter air pollution 2.5-10um; 2010  \\\n",
      "0                                        -0.181811   \n",
      "1                                         0.148479   \n",
      "2                                         0.170843   \n",
      "3                                        -0.169990   \n",
      "4                                        -0.327179   \n",
      "\n",
      "   Nitrogen oxides air pollution; 2010  \\\n",
      "0                             0.263638   \n",
      "1                            -0.287492   \n",
      "2                             1.062485   \n",
      "3                            -0.351421   \n",
      "4                            -1.391555   \n",
      "\n",
      "   Types of physical activity in last 4 weeks: Light DIY (eg: pruning, watering the lawn)  \\\n",
      "0                                           0.004771                                        \n",
      "1                                           0.516092                                        \n",
      "2                                           0.845148                                        \n",
      "3                                          -0.628626                                        \n",
      "4                                          -1.276180                                        \n",
      "\n",
      "   Diagnoses - secondary ICD10: I10 Essential (primary) hypertension  gender  \\\n",
      "0                                          -0.735762                     0.0   \n",
      "1                                           0.478446                     0.0   \n",
      "2                                           0.431657                     0.0   \n",
      "3                                          -0.688728                     1.0   \n",
      "4                                          -1.340661                     1.0   \n",
      "\n",
      "     age  output  \n",
      "0  0.770     0.0  \n",
      "1  0.732     1.0  \n",
      "2  0.705     1.0  \n",
      "3  0.821     1.0  \n",
      "4  0.704     0.0  \n",
      "\n",
      "[5 rows x 42 columns]\n"
     ]
    }
   ],
   "source": [
    "# # keep the index same\n",
    "# shuffled = df.sample(frac=1)\n",
    "# print( shuffled.head() )\n",
    "\n",
    "# reset the index\n",
    "shuffled = df.sample(frac=1).reset_index()\n",
    "# print(shuffled.columns)\n",
    "shuffled = shuffled.drop( ['index'], axis = 1 )\n",
    "print( shuffled.head() )\n",
    "\n",
    "# dropping last / output column in df\n",
    "shuffled_X = shuffled.iloc[: , :-1]\n",
    "# taking the output column of df\n",
    "shuffled_Y = shuffled.iloc[: , -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usable Features :  tensor([[-0.1996, -0.0787,  0.5339,  0.9025,  1.2892, -0.1020,  0.9558,  0.0961,\n",
      "         -0.1679,  0.4071, -0.3760,  0.4662,  0.7154,  0.8526,  0.3706,  1.0664,\n",
      "          0.7412, -0.3504,  0.5314, -0.1906, -0.7136,  0.4565,  0.7651,  0.9028,\n",
      "         -1.5873, -1.8491,  0.5254,  2.3811, -1.0168, -0.8178,  0.4206,  0.8846,\n",
      "          0.4704, -0.1021,  0.1015,  0.0131, -0.4019,  0.2111,  0.1987,  0.0000,\n",
      "          0.6360],\n",
      "        [-1.4248, -0.0309,  0.7525, -0.2133, -0.0379,  0.6391,  0.1939, -0.6790,\n",
      "          0.4616,  1.6729,  0.1152, -0.2222, -1.1023, -0.2652, -0.0758,  0.0575,\n",
      "         -0.0237, -0.0800,  0.5817,  0.8746,  0.8904, -0.2774,  0.1091, -0.1658,\n",
      "          0.7632, -0.5017, -0.1041,  0.2584, -0.2892,  0.5141, -0.2424, -0.7987,\n",
      "         -0.2842, -0.4868,  0.0943, -0.4340, -0.3121, -0.5767, -0.5168,  0.0000,\n",
      "          0.7530]])\n",
      "torch.Size([808, 41])\n"
     ]
    }
   ],
   "source": [
    "usable_features = torch.autograd.Variable(torch.from_numpy(usable_features)).to(DEVICE).float()\n",
    "\n",
    "print(\"Usable Features : \", usable_features[:2])\n",
    "\n",
    "print(usable_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NF:41\n",
      "\n",
      "#F10\n",
      "10 : [0.7446808510638298]\n",
      "10 : [0.7446808510638298, 0.723404255319149]\n"
     ]
    }
   ],
   "source": [
    "tensor_X = torch.tensor(shuffled_X.values, dtype=torch.float32)\n",
    "\n",
    "GENERATE_SHAP = True\n",
    "total_epochs = 500 #250(ideal)\n",
    "num_features_list = [shuffled_X.shape[1]]\n",
    "# random_integers = [2, 6, 108, 90, 5]\n",
    "random_integers = [90]#, 92, 0, 87, 73, 82, 54]\n",
    "\n",
    "folds_list = [10]#[37*2]\n",
    "\n",
    "avg_val_acc = []\n",
    "\n",
    "shap_values_list = []\n",
    "for num_features in num_features_list:\n",
    "    print(f'NF:{num_features}')\n",
    "    global_best_acc_val = 0.\n",
    "    precision_avg = 0\n",
    "    recall_avg = 0\n",
    "    auprc_avg = 0\n",
    "    auroc_avg = 0\n",
    "    fscore_avg = 0\n",
    "    for total_folds in folds_list:\n",
    "        print(f'\\n#F{total_folds}')\n",
    "        for random_seed in random_integers:\n",
    "            accuracies = []\n",
    "            accuracies_val = []\n",
    "            temp_shap_values = np.zeros(shuffled_X.shape)\n",
    "            \n",
    "            kf = KFold(n_splits = total_folds, random_state=None)\n",
    "            acc_score = []\n",
    "\n",
    "            for train_index , test_index in kf.split(shuffled):\n",
    "                X_train , X_test = shuffled_X.iloc[train_index,:], shuffled_X.iloc[test_index,:]\n",
    "                y_train , y_test = shuffled_Y[train_index] , shuffled_Y[test_index]\n",
    "                \n",
    "                train_dataset = df_dataSet( X_train, y_train )\n",
    "                valid_dataset = df_dataSet( X_test, y_test )\n",
    "                \n",
    "                train_batch_size = train_dataset.__len__()\n",
    "                val_batch_size = valid_dataset.__len__()\n",
    "                \n",
    "#                 print( train_batch_size, val_batch_size )\n",
    "                \n",
    "                train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = train_batch_size, shuffle = True, num_workers = 0)\n",
    "                valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size = val_batch_size, shuffle = False, num_workers = 0)\n",
    "\n",
    "                model = simple_model(num_features = shuffled_X.shape[1], hidden_dim = hidden_dimension)\n",
    "                model = model.to(DEVICE)\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "                criterion = torch.nn.BCEWithLogitsLoss() \n",
    "                best_acc_val = 0.\n",
    "                model_best = None\n",
    "                \n",
    "                for epoch_num in range(total_epochs):\n",
    "#                     print(epoch_num)\n",
    "                    model.train()\n",
    "#                     model.drop_probab=.8\n",
    "#                     print(\"model trained\")\n",
    "                    precision, recall, fscore, support, auroc, auprc, acc_train, total_loss, pred, pred_binary, true = epoch(model=model, optimizer=optimizer, \n",
    "                                                                                             criterion=criterion, is_training=True, \n",
    "                                                                                           loader=train_loader)\n",
    "#                     print(\"model validated\")\n",
    "                    model.eval()\n",
    "#                     model.drop_probab=.0\n",
    "                    precision, recall, fscore, support, auroc, auprc, acc_val, total_loss, pred, pred_binary, true = epoch(model=model, \n",
    "                                                                                             optimizer=optimizer, \n",
    "                                                                                             criterion=criterion, is_training=False, \n",
    "                                                                                            loader=valid_loader)\n",
    "#                     print(\"model kahini done\")\n",
    "                    if acc_val > best_acc_val:\n",
    "                        best_acc_val = acc_val\n",
    "                        if acc_val > global_best_acc_val:\n",
    "                            global_best_acc_val = acc_val\n",
    "    #                         print('global updated!')\n",
    "                        torch.save(model.state_dict(), 'PRS_model.pt')\n",
    "    #                     print(f'#F:{total_folds}| seed:{random_seed}, fold:{fold_num}, epoch:{epoch_num} -> local:{best_acc_val}, global:{global_best_acc_val}')  \n",
    "#                     if epoch_num + 1 == total_epochs:\n",
    "#     #                     print(f'LAST_Epoch:{epoch_num}, train_acc:{acc_train}, val_acc:{acc_val}, local_best:{best_acc_val}, global_best:{global_best_acc_val}')\n",
    "#                         pass\n",
    "                model_best = simple_model(num_features= shuffled_X.shape[1], hidden_dim = hidden_dimension, drop_probab=.0)\n",
    "                model_best.load_state_dict(torch.load('PRS_model.pt'))\n",
    "                model_best = model_best.to(DEVICE)\n",
    "                model_best.eval()\n",
    "                precision, recall, fscore, support, auroc, auprc, acc_test, total_loss, pred, pred_binary, true = epoch(model=model_best, \n",
    "                                                                                         optimizer=optimizer, \n",
    "                                                                                         criterion=criterion, is_training=False, \n",
    "                                                                                         loader=valid_loader)\n",
    "                accuracies += [acc_test]\n",
    "                accuracies_val += [best_acc_val]\n",
    "#                 print(\"precision : \", precision, \" ; recall : \", recall)\n",
    "                precision_avg += precision\n",
    "                recall_avg += recall\n",
    "                auprc_avg += auprc\n",
    "                auroc_avg += auroc\n",
    "                fscore_avg += fscore\n",
    "                \n",
    "#                 print(precision, recall, fscore, support, auroc, auprc, acc_test, total_loss)\n",
    "#                 print(\"pred\")\n",
    "#                 print(pred)\n",
    "#                 print(\"pred binary\")\n",
    "#                 print(type(pred_binary))\n",
    "#                 print(pred_binary)\n",
    "                \n",
    "                print(total_folds, ':', accuracies)\n",
    "                if GENERATE_SHAP:\n",
    "                    explainer = shap.GradientExplainer(model_best.to(DEVICE), tensor_X,\n",
    "                                                       batch_size=shuffled_X.shape[0]) #https://shap-lrjball.readthedocs.io/en/latest/generated/shap.KernelExplainer.html\n",
    "#                     print(\"usable features : \", usable_features.shape[0])\n",
    "#                     print(usable_features.shape)\n",
    "#                     print(usable_features)\n",
    "                    shap_values = explainer.shap_values(tensor_X, nsamples=500)\n",
    "#                     print(\"shap values shape : \", shap_values.shape)\n",
    "#                     print(\"Shap values : \", shap_values)\n",
    "#                     print(\"shap values of 0 index\", shap_values[0, :])\n",
    "                    \n",
    "                    temp_shap_values += shap_values \n",
    "            if GENERATE_SHAP:\n",
    "                temp_shap_values /= total_folds\n",
    "                shap_values_list += [temp_shap_values] \n",
    "            print(f'random_seed:{random_seed}:', np.mean(accuracies), np.std(accuracies), \n",
    "                  np.mean(accuracies_val), np.std(accuracies_val), 'train acc:', acc_train)\n",
    "            avg_val_acc += [np.mean(accuracies_val)]\n",
    "    \n",
    "    print(f'global_best_acc_val:{global_best_acc_val}')\n",
    "    precision_avg = precision_avg * 1.0 / total_folds\n",
    "    recall_avg = recall_avg * 1.0 / total_folds\n",
    "    auprc_avg = auprc_avg * 1.0 / total_folds\n",
    "    auroc_avg = auroc_avg * 1.0 / total_folds\n",
    "    fscore_avg = fscore_avg * 1.0 / total_folds\n",
    "    print( \"precision avg : \", precision_avg )\n",
    "    print( \"recall avg : \", recall_avg )\n",
    "    print( \"AUPRC avg : \", auprc_avg )\n",
    "    print( \"AUROC avg : \", auroc_avg )\n",
    "    print( \"FScore avg : \", fscore_avg )\n",
    "# usable_features = usable_features.cpu().detach().numpy().astype(np.float64)\n",
    "avg_val_acc = np.array(avg_val_acc)\n",
    "print(avg_val_acc.max(), avg_val_acc.min(), avg_val_acc.mean(), avg_val_acc.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GENERATE_SHAP = True\n",
    "# total_epochs = 500 #250(ideal)\n",
    "# num_features_list = [usable_features.shape[1]]\n",
    "# # random_integers = [2, 6, 108, 90, 5]\n",
    "# random_integers = [90]#, 92, 0, 87, 73, 82, 54]\n",
    "\n",
    "# folds_list = [10]#[37*2]\n",
    "\n",
    "# avg_val_acc = []\n",
    "\n",
    "# shap_values_list = []\n",
    "# for num_features in num_features_list:\n",
    "#     print(f'NF:{num_features}')\n",
    "#     global_best_acc_val = 0.\n",
    "#     precision_avg = 0\n",
    "#     recall_avg = 0\n",
    "#     auprc_avg = 0\n",
    "#     auroc_avg = 0\n",
    "#     fscore_avg = 0\n",
    "#     for total_folds in folds_list:\n",
    "#         print(f'\\n#F{total_folds}')\n",
    "#         for random_seed in random_integers:\n",
    "#             N_splits = random_samples(total_folds=total_folds, random_seed=random_seed)\n",
    "#             accuracies = []\n",
    "#             accuracies_val = []\n",
    "#             temp_shap_values = np.zeros(usable_features.shape)\n",
    "#             for fold_num in tqdm(range(total_folds)):\n",
    "#     #             print(f'fold-{fold_num}:')\n",
    "# #                 train_set, val_set, test_set = generate_datasets(N_splits=N_splits, fold_num=fold_num, random_seed=random_seed)\n",
    "#                 train_set, _, test_set = generate_datasets(N_splits=N_splits, fold_num=fold_num, random_seed=random_seed)\n",
    "#                 val_set = test_set        \n",
    "#                 train_loader, val_loader, test_loader = generate_loader(train_set=train_set, val_set=val_set, \n",
    "#                                                                         test_set=test_set, num_workers=0)\n",
    "#                 model = simple_model(num_features=usable_features.shape[1], hidden_dim= hidden_dimension)\n",
    "#                 model = model.to(DEVICE)\n",
    "#                 optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "#                 criterion = torch.nn.BCEWithLogitsLoss() \n",
    "#                 best_acc_val = 0.\n",
    "#                 model_best = None\n",
    "#                 for epoch_num in range(total_epochs):\n",
    "#                     model.train()\n",
    "# #                     model.drop_probab=.8\n",
    "#                     precision, recall, fscore, support, auroc, auprc, acc_train, total_loss, pred, pred_binary, true = epoch(model=model, optimizer=optimizer, \n",
    "#                                                                                              criterion=criterion, is_training=True, \n",
    "#                                                                                              loader=train_loader)\n",
    "#                     model.eval()\n",
    "# #                     model.drop_probab=.0\n",
    "#                     precision, recall, fscore, support, auroc, auprc, acc_val, total_loss, pred, pred_binary, true = epoch(model=model, \n",
    "#                                                                                              optimizer=optimizer, \n",
    "#                                                                                              criterion=criterion, is_training=False, \n",
    "#                                                                                             loader=val_loader)\n",
    "#                     if acc_val > best_acc_val:\n",
    "#                         best_acc_val = acc_val\n",
    "#                         if acc_val > global_best_acc_val:\n",
    "#                             global_best_acc_val = acc_val\n",
    "#     #                         print('global updated!')\n",
    "#                         torch.save(model.state_dict(), 'PRS_model.pt')\n",
    "#     #                     print(f'#F:{total_folds}| seed:{random_seed}, fold:{fold_num}, epoch:{epoch_num} -> local:{best_acc_val}, global:{global_best_acc_val}')  \n",
    "# #                     if epoch_num + 1 == total_epochs:\n",
    "# #     #                     print(f'LAST_Epoch:{epoch_num}, train_acc:{acc_train}, val_acc:{acc_val}, local_best:{best_acc_val}, global_best:{global_best_acc_val}')\n",
    "# #                         pass\n",
    "#                 model_best = simple_model(num_features=usable_features.shape[1], hidden_dim= hidden_dimension, drop_probab=.0)\n",
    "#                 model_best.load_state_dict(torch.load('PRS_model.pt'))\n",
    "#                 model_best = model_best.to(DEVICE)\n",
    "#                 model_best.eval()\n",
    "#                 precision, recall, fscore, support, auroc, auprc, acc_test, total_loss, pred, pred_binary, true = epoch(model=model_best, \n",
    "#                                                                                          optimizer=optimizer, \n",
    "#                                                                                          criterion=criterion, is_training=False, \n",
    "#                                                                                          loader=val_loader)\n",
    "#                 accuracies += [acc_test]\n",
    "#                 accuracies_val += [best_acc_val]\n",
    "# #                 print(\"precision : \", precision, \" ; recall : \", recall)\n",
    "#                 precision_avg += precision\n",
    "#                 recall_avg += recall\n",
    "#                 auprc_avg += auprc\n",
    "#                 auroc_avg += auroc\n",
    "#                 fscore_avg += fscore\n",
    "                \n",
    "# #                 print(precision, recall, fscore, support, auroc, auprc, acc_test, total_loss)\n",
    "# #                 print(\"pred\")\n",
    "# #                 print(pred)\n",
    "# #                 print(\"pred binary\")\n",
    "# #                 print(type(pred_binary))\n",
    "# #                 print(pred_binary)\n",
    "                \n",
    "# #                 print(fold_num, ':', accuracies)\n",
    "#                 if GENERATE_SHAP:\n",
    "#                     explainer = shap.GradientExplainer(model_best.to(DEVICE), usable_features,\n",
    "#                                                        batch_size=usable_features.shape[0]) #https://shap-lrjball.readthedocs.io/en/latest/generated/shap.KernelExplainer.html\n",
    "# #                     print(\"usable features : \", usable_features.shape[0])\n",
    "# #                     print(usable_features.shape)\n",
    "# #                     print(usable_features)\n",
    "#                     shap_values = explainer.shap_values(usable_features, nsamples=500)\n",
    "# #                     print(\"shap values shape : \", shap_values.shape)\n",
    "# #                     print(\"Shap values : \", shap_values)\n",
    "# #                     print(\"shap values of 0 index\", shap_values[0, :])\n",
    "                    \n",
    "#                     temp_shap_values += shap_values \n",
    "#             if GENERATE_SHAP:\n",
    "#                 temp_shap_values /= total_folds\n",
    "#                 shap_values_list += [temp_shap_values] \n",
    "#             print(f'random_seed:{random_seed}:', np.mean(accuracies), np.std(accuracies), \n",
    "#                   np.mean(accuracies_val), np.std(accuracies_val), 'train acc:', acc_train)\n",
    "#             avg_val_acc += [np.mean(accuracies_val)]\n",
    "    \n",
    "#     print(f'global_best_acc_val:{global_best_acc_val}')\n",
    "#     precision_avg = precision_avg * 1.0 / total_folds\n",
    "#     recall_avg = recall_avg * 1.0 / total_folds\n",
    "#     auprc_avg = auprc_avg * 1.0 / total_folds\n",
    "#     auroc_avg = auroc_avg * 1.0 / total_folds\n",
    "#     fscore_avg = fscore_avg * 1.0 / total_folds\n",
    "#     print( \"precision avg : \", precision_avg )\n",
    "#     print( \"recall avg : \", recall_avg )\n",
    "#     print( \"AUPRC avg : \", auprc_avg )\n",
    "#     print( \"AUROC avg : \", auroc_avg )\n",
    "#     print( \"FScore avg : \", fscore_avg )\n",
    "# # usable_features = usable_features.cpu().detach().numpy().astype(np.float64)\n",
    "# avg_val_acc = np.array(avg_val_acc)\n",
    "# print(avg_val_acc.max(), avg_val_acc.min(), avg_val_acc.mean(), avg_val_acc.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model accuracy in model_details.txt\n",
    "save_in_file(\"Neural Network with \" + str(hidden)  + \" layers_4yrs_\" + str(len(feature_indices_to_consider)), global_best_acc_val)\n",
    "# save_in_file(\"Neural Network with \" + str(hidden) + \" layers\", global_best_acc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usable_features = usable_features.cpu().detach().numpy().astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shap Analysis\n",
    "\n",
    "https://medium.com/dataman-in-ai/explain-your-model-with-the-shap-values-bc36aac4de3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print( shap_values_list )\n",
    "# write shap_values_list to pkl file\n",
    "pickle.dump(shap_values_list, open('shap_values_list.pkl', 'wb'))\n",
    "shap_values = np.mean(shap_values_list, axis=0)\n",
    "print( shap_values.shape )\n",
    "# print(shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Force plot :\n",
    "\n",
    "\n",
    "The shap.force_plot() takes three values: \n",
    "\n",
    "(i) the base value (explainerModel.expected_value[0]),\n",
    "\n",
    "(ii) the SHAP values (shap_values_Model[j][0]) and \n",
    "\n",
    "(iii) the matrix of feature values (S.iloc[[j]]). The base value or the expected value is the average of the model output over the training data X_train. It is the base value used in the following plot.\n",
    "\n",
    "https://medium.com/mlearning-ai/shap-force-plots-for-classification-d30be430e195\n",
    "\n",
    "the bold 0.80 is the model’s score for this observation. Higher scores lead the model to predict 1 and lower scores lead the model to predict 0. The features that were important to making the prediction for this observation are shown in red and blue, with red representing features that pushed the model score higher, and blue representing features that pushed the score lower. Features that had more of an impact on the score are located closer to the dividing boundary between red and blue, and the size of that impact is represented by the size of the bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print( shap_values_list )\n",
    "\n",
    "# print the JS visualization code to the notebook\n",
    "shap.initjs()\n",
    "\n",
    "# print(shap_values[0, :])\n",
    "# print(usable_features[0, :])\n",
    "# shap.summary_plot(shap_values[:, :], usable_features[:, :])\n",
    "\n",
    "# shap.force_plot(.5, shap_values[0,:], usable_features[0, :], link = \"logit\", matplotlib = True)  \n",
    "\n",
    "# using pandas dataframe\n",
    "shap.force_plot(.5, shap_values[0,:], shuffled_X.iloc[0, :], link = \"logit\", matplotlib = True  )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# shap.force_plot(.5, shap_values[:,:], usable_features[:, :], link=\"logit\")\n",
    "\n",
    "# using pandas dataframe\n",
    "print(shap_values.shape)\n",
    "print(shuffled_X.shape)\n",
    "shap.force_plot(.5, shap_values[:,:], shuffled_X.iloc[:, :], link=\"logit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary Plot\n",
    "This plot is made of all the dots in the train data. It delivers the following information:\n",
    "\n",
    "Feature importance: Variables are ranked in descending order.\n",
    "\n",
    "Impact: The horizontal location shows whether the effect of that value is associated with a higher or lower prediction.\n",
    "\n",
    "Original value: Color shows whether that variable is high (in red) or low (in blue) for that observation.\n",
    "\n",
    "Correlation: A high level of the “alcohol” content has a high and positive impact on the quality rating. The “high” comes from the red color, and the “positive” impact is shown on the X-axis. Similarly, we will say the “volatile acidity” is negatively correlated with the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./shap/\" + str(num_features)\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    \n",
    "# for trait in traits:\n",
    "#     print(trait)\n",
    "# https://shap-lrjball.readthedocs.io/en/latest/generated/shap.summary_plot.html?highlight=beeswarm#shap.summary_plot\n",
    "# usable_features_std = (usable_features - usable_features.mean(0))/usable_features.std(0)\n",
    "# shap.summary_plot(shap_values, features=usable_features, feature_names=traits, plot_type='dot', max_display=len(traits), show = False)\n",
    "# plt.savefig('shap/' + str(num_features) + '/summary_plot_hidden_'+ str(hidden) + '_dim_' + str(hidden_dimension) + '.pdf',  bbox_inches='tight')\n",
    "# shap.summary_plot(shap_values, features=usable_features, feature_names=list(range(23)), plot_type='dot', max_display=len(traits))\n",
    "\n",
    "shap.summary_plot(shap_values, features = shuffled_X, feature_names=traits, plot_type='dot', max_display=len(traits), show = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://shap-lrjball.readthedocs.io/en/latest/generated/shap.summary_plot.html?highlight=beeswarm#shap.summary_plot\n",
    "# shap.summary_plot(shap_values, features=usable_features, feature_names=list(range(23)), plot_type='bar', max_display=len(traits), show=False)\n",
    "# plt.savefig('shap/summary_plot_hidden_'+ str(hidden) + '_bar.png', bbox_inches='tight')\n",
    "# naeem modified\n",
    "# shap.summary_plot(shap_values, features=usable_features, feature_names=list(range(num_features)), plot_type='bar', max_display=len(traits), show=False)\n",
    "# shap.summary_plot(shap_values, features=usable_features, feature_names = traits, plot_type='bar', max_display=len(traits), show=False)\n",
    "# plt.savefig('shap/' + str(num_features) + 'summary_plot_hidden_'+ str(hidden) + '_bar.png', bbox_inches='tight')\n",
    "\n",
    "shap.summary_plot(shap_values, features = shuffled_X, feature_names = traits, plot_type='bar', max_display=len(traits), show=False)\n",
    "plt.savefig('shap/' + str(num_features) + 'summary_plot_hidden_'+ str(hidden) + '_bar.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(list(zip(list(range(23)), abs(shap_values).mean(0))), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(shap.force_plot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # print(Final_Samples)\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn import svm\n",
    "# from sklearn.neural_network import MLPClassifier, MLPRegressor, BernoulliRBM\n",
    "\n",
    "# feature_indices_to_consider = list(range(0, 23)) #[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 18, 20, 22]\n",
    "\n",
    "# usable_indices = [usable_samples_ADNI[Final_Samples[i][0]] for i in range(len(Final_Samples))]\n",
    "# usable_features = FEATURE_MATRIX[usable_indices][:, feature_indices_to_consider]\n",
    "# usable_labels = np.array([float(Final_Samples[i][1]) for i in range(len(Final_Samples))])\n",
    "\n",
    "# Final_Samples = positive_samples[:500] + negative_samples[:500]\n",
    "# random.seed(2);random.shuffle(Final_Samples)\n",
    "# # Final_Samples = np.array(Final_Samples)\n",
    "# print(len([x[1] for x in Final_Samples if x[1] == 1]), len([x[1] for x in Final_Samples if x[1] == 0]))\n",
    "# print(sum(usable_labels), len(usable_labels))\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     usable_features, usable_labels, test_size=0.1)\n",
    "\n",
    "# X_train.shape, y_train.shape\n",
    "\n",
    "# X_test.shape, y_test.shape\n",
    "\n",
    "# print(y_test.sum(), y_test.shape)\n",
    "# clf = svm.SVC(kernel='rbf', C=1).fit(X_train, y_train)\n",
    "# # clf = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam').fit(X_train, y_train)\n",
    "# clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.shuffle(Final_Samples)\n",
    "# usable_indices = [usable_samples_ADNI[Final_Samples[i][0]] for i in range(len(Final_Samples))]\n",
    "# usable_features = FEATURE_MATRIX[usable_indices][:, feature_indices_to_consider]\n",
    "# usable_labels = np.array([float(Final_Samples[i][1]) for i in range(len(Final_Samples))])\n",
    "\n",
    "\n",
    "# from sklearn.model_selection import KFold\n",
    "# X = usable_features[:, :23]\n",
    "# y = usable_labels\n",
    "# kf = KFold(n_splits=10)\n",
    "# kf.get_n_splits(X)\n",
    "\n",
    "# print(kf)\n",
    "# # print(y_test)\n",
    "# accuracies = []\n",
    "# for train_index, test_index in kf.split(X):\n",
    "# #     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#     X_train, X_test = X[train_index], X[test_index]\n",
    "#     y_train, y_test = y[train_index], y[test_index]\n",
    "#     clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "# #     clf = MLPClassifier(hidden_layer_sizes=(32,8), activation='relu', solver='adam', max_iter=100, learning_rate='invscaling').fit(X_train, y_train)\n",
    "# #     print(y_test.sum(), y_test.shape)\n",
    "#     print(clf.score(X_test, y_test))\n",
    "#     accuracies += [clf.score(X_test, y_test)]\n",
    "# print(np.mean(accuracies), np.std(accuracies))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "# accuracies = []\n",
    "# X = usable_features[:, :23]\n",
    "# y = usable_labels\n",
    "# kf = KFold(n_splits=10)\n",
    "# kf.get_n_splits(X)\n",
    "\n",
    "# for train_index, test_index in kf.split(X):\n",
    "# #     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#     X_train, X_test = X[train_index], X[test_index]\n",
    "#     y_train, y_test = y[train_index], y[test_index]\n",
    "#     reg = RandomForestClassifier(random_state=0)\n",
    "#     reg.fit(X_train, y_train)\n",
    "#     print(\"Accuracy of model : \",reg.score(X_test, y_test)*100,\"%\")\n",
    "# #     clf = MLPClassifier(hidden_layer_sizes=(32,8), activation='relu', solver='adam', max_iter=100, learning_rate='invscaling').fit(X_train, y_train)\n",
    "# #     print(y_test.sum(), y_test.shape)\n",
    "#     accuracies += [reg.score(X_test, y_test)]\n",
    "# print(np.mean(accuracies), np.std(accuracies))\n",
    "# save_in_file(\"Random Forest\", np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBRegressor, XGBClassifier\n",
    "# model_name = \"XGB\"\n",
    "\n",
    "# accuracies = []\n",
    "# for train_index, test_index in kf.split(X):\n",
    "# #     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#     X_train, X_test = X[train_index], X[test_index]\n",
    "#     y_train, y_test = y[train_index], y[test_index]\n",
    "#     reg = XGBClassifier()\n",
    "#     reg.fit(X_train, y_train)\n",
    "#     print(\"Accuracy of model : \",reg.score(X_test, y_test)*100,\"%\")\n",
    "# #     clf = MLPClassifier(hidden_layer_sizes=(32,8), activation='relu', solver='adam', max_iter=100, learning_rate='invscaling').fit(X_train, y_train)\n",
    "# #     print(y_test.sum(), y_test.shape)\n",
    "#     accuracies += [reg.score(X_test, y_test)]\n",
    "# print(np.mean(accuracies), np.std(accuracies))\n",
    "# save_in_file(\"XGBoost\", np.mean(accuracies))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save accuracy in CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# open the file in the write mode\n",
    "f = open('model_global_best_accuracy.csv', 'a')\n",
    "\n",
    "# create the csv writer\n",
    "writer = csv.writer(f)\n",
    "\n",
    "# write a row to the csv file\n",
    "# writer.writerow(['num_features','num_nn_layers','global_best_accuracy'])\n",
    "writer.writerow([str(num_features),str(hidden),str(global_best_acc_val)])\n",
    "\n",
    "# close the file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ad_venv_2",
   "language": "python",
   "name": "ad_venv_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
