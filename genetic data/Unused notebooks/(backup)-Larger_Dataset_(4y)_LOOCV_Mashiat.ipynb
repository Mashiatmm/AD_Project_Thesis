{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes :\n",
    "When you add age and gender, the shap value does not give proper output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "# Final_Samples\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "usable_samples_ADNI = json.load(open('./usable_samples_ADNI.json'))\n",
    "PRS_orig_feature_matrix = np.load('./PRS_feature_matrix.npy').astype(np.float32)\n",
    "PRS_orig_feature_matrix = (PRS_orig_feature_matrix - PRS_orig_feature_matrix.mean(0))/PRS_orig_feature_matrix.std(0)\n",
    "PRS_orig_feature_matrix.shape[1], len(usable_samples_ADNI), usable_samples_ADNI\n",
    "num_features=PRS_orig_feature_matrix.shape[1]\n",
    "print(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 35\n",
    "hidden = 4\n",
    "hidden_dimension = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = \"./shap/\" + str(num_features)\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1816, 35)\n"
     ]
    }
   ],
   "source": [
    "PRS_feature_matrix = PRS_orig_feature_matrix\n",
    "PRS_feature_matrix = PRS_feature_matrix[:, :num_features]\n",
    "print(PRS_feature_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['d', '4'], ['b', '2'], ['a', '1'], ['c', '3']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([['a',1],['b',2],['c',3],['d',4]]).tolist()\n",
    "random.shuffle(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (1817, 14)\n",
      "(1817, 2) (1817, 2)\n",
      "                FID               IID       PC1       PC2       PC3       PC4  \\\n",
      "0  ADNI3_036_S_6231  ADNI3_036_S_6231 -0.006724 -0.010617  0.001596 -0.000460   \n",
      "1  ADNI3_006_S_6277  ADNI3_006_S_6277 -0.010432 -0.010269  0.012757  0.006921   \n",
      "2  ADNI3_129_S_6146  ADNI3_129_S_6146 -0.004919 -0.011656 -0.035521  0.064641   \n",
      "3  ADNI3_033_S_6352  ADNI3_033_S_6352 -0.014069 -0.010279  0.020014  0.053023   \n",
      "4  ADNI3_027_S_6183  ADNI3_027_S_6183 -0.010766 -0.012370 -0.010960  0.029830   \n",
      "\n",
      "        PC5       PC6       PC7       PC8       PC9      PC10  PTGENDER   AGE  \n",
      "0 -0.013131 -0.005855 -0.005142 -0.009063 -0.001739 -0.012863         1  69.1  \n",
      "1 -0.014958 -0.005860 -0.027775 -0.009632  0.054966  0.087390         1  70.7  \n",
      "2  0.012094  0.003860  0.035955  0.006561  0.019736 -0.023304         1  65.5  \n",
      "3  0.023691  0.000247 -0.002273 -0.030627 -0.053461  0.049984         0  71.4  \n",
      "4 -0.019520 -0.001955  0.023844  0.079138  0.002207  0.008892         0  65.6  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\.conda\\envs\\ad_venv_2\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3397: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./COVAR_FILE_bigger_dataset.txt', ' ') \n",
    "print(\"shape\",df.shape)\n",
    "print( df[['AGE', 'PTGENDER']].shape, df[['AGE', 'PTGENDER']].dropna().shape )\n",
    "print( df.head() ) # PC - Principal Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                FID               IID       PC1       PC2       PC3       PC4  \\\n",
      "0  ADNI3_036_S_6231  ADNI3_036_S_6231 -0.006724 -0.010617  0.001596 -0.000460   \n",
      "1  ADNI3_006_S_6277  ADNI3_006_S_6277 -0.010432 -0.010269  0.012757  0.006921   \n",
      "2  ADNI3_129_S_6146  ADNI3_129_S_6146 -0.004919 -0.011656 -0.035521  0.064641   \n",
      "3  ADNI3_033_S_6352  ADNI3_033_S_6352 -0.014069 -0.010279  0.020014  0.053023   \n",
      "4  ADNI3_027_S_6183  ADNI3_027_S_6183 -0.010766 -0.012370 -0.010960  0.029830   \n",
      "\n",
      "        PC5       PC6       PC7       PC8       PC9      PC10  PTGENDER    AGE  \n",
      "0 -0.013131 -0.005855 -0.005142 -0.009063 -0.001739 -0.012863         1  0.691  \n",
      "1 -0.014958 -0.005860 -0.027775 -0.009632  0.054966  0.087390         1  0.707  \n",
      "2  0.012094  0.003860  0.035955  0.006561  0.019736 -0.023304         1  0.655  \n",
      "3  0.023691  0.000247 -0.002273 -0.030627 -0.053461  0.049984         0  0.714  \n",
      "4 -0.019520 -0.001955  0.023844  0.079138  0.002207  0.008892         0  0.656  \n"
     ]
    }
   ],
   "source": [
    "# trying to normalize AGE with having max age of 100\n",
    "df['AGE'] = df['AGE'] / 100.0\n",
    "print( df.head() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape1 (1816, 35)\n",
      "shape2 (1816, 47)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.1288546255506608,\n",
       " array([[ 6.0254073e-01,  3.8611200e-01, -5.8913165e-01, -5.6206602e-01,\n",
       "          1.3769143e+00,  1.1957877e+00,  6.7549521e-01, -8.1201518e-01,\n",
       "          1.4735116e+00,  1.5833879e+00,  1.1038882e+00,  4.7303710e-02,\n",
       "         -2.5817478e-01,  2.0768111e+00,  3.4892298e-02,  1.5471818e+00,\n",
       "          2.1130602e-01, -7.8878814e-01,  1.1477689e+00, -7.1390218e-01,\n",
       "          6.5592009e-01,  3.6035888e-02, -1.0208811e+00,  4.2786098e-01,\n",
       "          4.4062281e-01,  4.1337675e-01,  1.9010180e-01, -2.0883363e-01,\n",
       "          6.4279914e-01,  8.8049096e-01, -1.5337672e+00, -5.0156575e-01,\n",
       "         -4.5751646e-02,  8.8257521e-01, -3.8061208e-01, -6.7239902e-03,\n",
       "         -1.0617300e-02,  1.5955199e-03, -4.6042900e-04, -1.3131300e-02,\n",
       "         -5.8546802e-03, -5.1415302e-03, -9.0632401e-03, -1.7389200e-03,\n",
       "         -1.2863100e-02,  1.0000000e+00,  6.9099998e-01],\n",
       "        [ 3.2023571e-02, -7.2182208e-01,  5.6008160e-01, -4.5909986e-01,\n",
       "         -2.8283790e-01,  6.9074273e-01,  8.7522858e-01,  2.1927162e-01,\n",
       "         -3.7697020e-01, -4.5436200e-01,  7.2349036e-01, -4.9750850e-01,\n",
       "          1.0644186e+00,  5.9753662e-01, -2.4813785e-01,  2.8968764e-02,\n",
       "         -2.7886992e-02,  2.6224835e+00,  4.3087134e-01, -2.8895292e-01,\n",
       "          2.4560858e-01, -5.2110817e-02, -4.4763651e-02, -1.8602200e-01,\n",
       "          3.0547190e-01,  5.5778086e-01, -2.0424709e-01,  3.5013828e-02,\n",
       "         -5.5759084e-01, -4.4283944e-01,  6.1258554e-01, -9.1423553e-01,\n",
       "          6.6405241e-03,  1.3060592e+00, -1.9559491e-01, -1.0432100e-02,\n",
       "         -1.0269200e-02,  1.2757200e-02,  6.9213500e-03, -1.4958400e-02,\n",
       "         -5.8604302e-03, -2.7775100e-02, -9.6316896e-03,  5.4965999e-02,\n",
       "          8.7389797e-02,  1.0000000e+00,  7.0700002e-01]], dtype=float32),\n",
       " array([[ 0.60254073,  0.386112  , -0.58913165, -0.562066  ,  1.3769143 ,\n",
       "          1.1957877 ,  0.6754952 , -0.8120152 ,  1.4735116 ,  1.5833879 ,\n",
       "          1.1038882 ,  0.04730371, -0.25817478,  2.076811  ,  0.0348923 ,\n",
       "          1.5471818 ,  0.21130602, -0.78878814,  1.1477689 , -0.7139022 ,\n",
       "          0.6559201 ,  0.03603589, -1.020881  ,  0.42786098,  0.4406228 ,\n",
       "          0.41337675,  0.1901018 , -0.20883363,  0.64279914,  0.88049096,\n",
       "         -1.5337672 , -0.50156575, -0.04575165,  0.8825752 , -0.38061208],\n",
       "        [ 0.03202357, -0.7218221 ,  0.5600816 , -0.45909986, -0.2828379 ,\n",
       "          0.69074273,  0.8752286 ,  0.21927162, -0.3769702 , -0.454362  ,\n",
       "          0.72349036, -0.4975085 ,  1.0644186 ,  0.5975366 , -0.24813785,\n",
       "          0.02896876, -0.02788699,  2.6224835 ,  0.43087134, -0.28895292,\n",
       "          0.24560858, -0.05211082, -0.04476365, -0.186022  ,  0.3054719 ,\n",
       "          0.55778086, -0.20424709,  0.03501383, -0.55759084, -0.44283944,\n",
       "          0.61258554, -0.91423553,  0.00664052,  1.3060592 , -0.1955949 ]],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# COVAR_FILE = df.to_numpy()[:, 2:].astype(np.float32)\n",
    "cnt = 0\n",
    "print(\"shape1\",PRS_feature_matrix.shape)\n",
    "FEATURE_MATRIX = np.concatenate([PRS_feature_matrix, np.zeros([PRS_feature_matrix.shape[0], 12])], 1).astype(np.float32)\n",
    "print(\"shape2\",FEATURE_MATRIX.shape)\n",
    "for sample in usable_samples_ADNI:\n",
    "    covar = df[df['IID'] == sample].to_numpy()[:, 2:].astype(np.float32) # taking from the PCs, skipping the first two columns of IID, FID\n",
    "#     if cnt < 2:\n",
    "#         print(covar)\n",
    "    if covar.shape[0] != 1:\n",
    "#         print(sample)\n",
    "        cnt += 1\n",
    "        continue\n",
    "    \n",
    "    FEATURE_MATRIX[usable_samples_ADNI[sample], num_features:] = covar\n",
    "# cnt/FEATURE_MATRIX.shape[0], FEATURE_MATRIX[:2], PRS_feature_matrix[:2]\n",
    "\n",
    "#     FEATURE_MATRIX[usable_samples_ADNI[sample], num_features:] = covar # naeem's modification\n",
    "cnt/FEATURE_MATRIX.shape[0], FEATURE_MATRIX[:2], PRS_feature_matrix[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.691 0.707 0.655 ... 0.769 0.667 0.804]\n"
     ]
    }
   ],
   "source": [
    "print( FEATURE_MATRIX[:, -1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234\n"
     ]
    }
   ],
   "source": [
    "age_zero = 0\n",
    "age_zero_idx = []\n",
    "for i in range( len(FEATURE_MATRIX) ):\n",
    "    if FEATURE_MATRIX[i, -1] == 0.00:\n",
    "        age_zero += 1\n",
    "        age_zero_idx.append(i)\n",
    "        \n",
    "print(age_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REMOVING AGE ROWS WITH ZERO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(FEATURE_MATRIX.shape)\n",
    "# FEATURE_MATRIX = FEATURE_MATRIX[~(FEATURE_MATRIX[:,-1] == 0.0),:]\n",
    "# print(FEATURE_MATRIX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at C:\\ProgramData\\Anaconda3:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "_ipyw_jlab_nb_ext_conf    0.1.0                    py37_0  \n",
      "alabaster                 0.7.12                   py37_0  \n",
      "anaconda                  2020.02                  py37_0  \n",
      "anaconda-client           1.7.2                    py37_0  \n",
      "anaconda-navigator        1.9.12                   py37_0  \n",
      "anaconda-project          0.8.4                      py_0  \n",
      "appdirs                   1.4.3                    pypi_0    pypi\n",
      "argh                      0.26.2                   py37_0  \n",
      "asn1crypto                1.3.0                    py37_0  \n",
      "astroid                   2.3.3                    py37_0  \n",
      "astropy                   4.0              py37he774522_0  \n",
      "atomicwrites              1.3.0                    py37_1  \n",
      "attrs                     19.3.0                     py_0  \n",
      "autopep8                  1.4.4                      py_0  \n",
      "babel                     2.8.0                      py_0  \n",
      "backcall                  0.1.0                    py37_0  \n",
      "backports                 1.0                        py_2  \n",
      "backports.functools_lru_cache 1.6.1                      py_0  \n",
      "backports.shutil_get_terminal_size 1.0.0                    py37_2  \n",
      "backports.tempfile        1.0                        py_1  \n",
      "backports.weakref         1.0.post1                  py_1  \n",
      "bcrypt                    3.1.7            py37he774522_0  \n",
      "beautifulsoup4            4.8.2                    py37_0  \n",
      "bitarray                  1.2.1            py37he774522_0  \n",
      "bkcharts                  0.2                      py37_0  \n",
      "blas                      1.0                         mkl  \n",
      "bleach                    3.1.0                    py37_0  \n",
      "blosc                     1.16.3               h7bd577a_0  \n",
      "bokeh                     1.4.0                    py37_0  \n",
      "boto                      2.49.0                   py37_0  \n",
      "bottleneck                1.3.2            py37h2a96729_0  \n",
      "bzip2                     1.0.8                he774522_0  \n",
      "ca-certificates           2020.1.1                      0  \n",
      "certifi                   2019.11.28               py37_0  \n",
      "cffi                      1.14.0           py37h7a1dbc1_0  \n",
      "chardet                   3.0.4                 py37_1003  \n",
      "click                     7.0                      py37_0  \n",
      "cloudpickle               1.3.0                      py_0  \n",
      "clyent                    1.2.2                    py37_1  \n",
      "colorama                  0.4.3                      py_0  \n",
      "comtypes                  1.1.7                    py37_0  \n",
      "conda                     4.8.3                    py37_0  \n",
      "conda-build               3.18.11                  py37_0  \n",
      "conda-env                 2.6.0                         1  \n",
      "conda-package-handling    1.6.0            py37h62dcd97_0  \n",
      "conda-verify              3.4.2                      py_1  \n",
      "console_shortcut          0.1.1                         4  \n",
      "contextlib2               0.6.0.post1                py_0  \n",
      "cryptography              2.8              py37h7a1dbc1_0  \n",
      "curl                      7.68.0               h2a8f88b_0  \n",
      "cycler                    0.10.0                   py37_0  \n",
      "cython                    0.29.15          py37ha925a31_0  \n",
      "cytoolz                   0.10.1           py37he774522_0  \n",
      "dask                      2.11.0                     py_0  \n",
      "dask-core                 2.11.0                     py_0  \n",
      "decorator                 4.4.1                      py_0  \n",
      "defusedxml                0.6.0                      py_0  \n",
      "diff-match-patch          20181111                   py_0  \n",
      "distlib                   0.3.0                    pypi_0    pypi\n",
      "distributed               2.11.0                   py37_0  \n",
      "docutils                  0.16                     py37_0  \n",
      "en-core-web-md            2.2.5                    pypi_0    pypi\n",
      "entrypoints               0.3                      py37_0  \n",
      "et_xmlfile                1.0.1                    py37_0  \n",
      "fastcache                 1.1.0            py37he774522_0  \n",
      "filelock                  3.0.12                     py_0  \n",
      "flake8                    3.7.9                    py37_0  \n",
      "flask                     1.1.1                      py_0  \n",
      "freetype                  2.9.1                ha9979f8_1  \n",
      "fsspec                    0.6.2                      py_0  \n",
      "future                    0.18.2                   py37_0  \n",
      "get_terminal_size         1.0.0                h38e98db_0  \n",
      "gevent                    1.4.0            py37he774522_0  \n",
      "glob2                     0.7                        py_0  \n",
      "greenlet                  0.4.15           py37hfa6e2cd_0  \n",
      "h5py                      2.10.0           py37h5e291fa_0  \n",
      "hdf5                      1.10.4               h7ebc959_0  \n",
      "heapdict                  1.0.1                      py_0  \n",
      "html5lib                  1.0.1                    py37_0  \n",
      "hypothesis                5.5.4                      py_0  \n",
      "icc_rt                    2019.0.0             h0cc432a_1  \n",
      "icu                       58.2                 ha66f8fd_1  \n",
      "idna                      2.8                      py37_0  \n",
      "imageio                   2.6.1                    py37_0  \n",
      "imagesize                 1.2.0                      py_0  \n",
      "importlib_metadata        1.5.0                    py37_0  \n",
      "intel-openmp              2020.0                      166  \n",
      "intervaltree              3.0.2                      py_0  \n",
      "ipykernel                 5.1.4            py37h39e3cac_0  \n",
      "ipython                   7.12.0           py37h5ca1d4c_0  \n",
      "ipython_genutils          0.2.0                    py37_0  \n",
      "ipywidgets                7.5.1                      py_0  \n",
      "isort                     4.3.21                   py37_0  \n",
      "itsdangerous              1.1.0                    py37_0  \n",
      "jdcal                     1.4.1                      py_0  \n",
      "jedi                      0.14.1                   py37_0  \n",
      "jinja2                    2.11.1                     py_0  \n",
      "joblib                    0.14.1                     py_0  \n",
      "jpeg                      9b                   hb83a4c4_2  \n",
      "json5                     0.9.1                      py_0  \n",
      "jsonschema                3.2.0                    py37_0  \n",
      "jupyter                   1.0.0                    py37_7  \n",
      "jupyter_client            5.3.4                    py37_0  \n",
      "jupyter_console           6.1.0                      py_0  \n",
      "jupyter_core              4.6.1                    py37_0  \n",
      "jupyterlab                1.2.6              pyhf63ae98_0  \n",
      "jupyterlab_server         1.0.6                      py_0  \n",
      "kaggle                    1.5.9                    pypi_0    pypi\n",
      "keyring                   21.1.0                   py37_0  \n",
      "kiwisolver                1.1.0            py37ha925a31_0  \n",
      "krb5                      1.17.1               hc04afaa_0  \n",
      "lazy-object-proxy         1.4.3            py37he774522_0  \n",
      "libarchive                3.3.3                h0643e63_5  \n",
      "libcurl                   7.68.0               h2a8f88b_0  \n",
      "libiconv                  1.15                 h1df5818_7  \n",
      "liblief                   0.9.0                ha925a31_2  \n",
      "libpng                    1.6.37               h2a8f88b_0  \n",
      "libsodium                 1.0.16               h9d3ae62_0  \n",
      "libspatialindex           1.9.3                h33f27b4_0  \n",
      "libssh2                   1.8.2                h7a1dbc1_0  \n",
      "libtiff                   4.1.0                h56a325e_0  \n",
      "libxml2                   2.9.9                h464c3ec_0  \n",
      "libxslt                   1.1.33               h579f668_0  \n",
      "llvmlite                  0.31.0           py37ha925a31_0  \n",
      "locket                    0.2.0                    py37_1  \n",
      "lxml                      4.5.0            py37h1350720_0  \n",
      "lz4-c                     1.8.1.2              h2fa13f4_0  \n",
      "lzo                       2.10                 h6df0209_2  \n",
      "m2w64-gcc-libgfortran     5.3.0                         6  \n",
      "m2w64-gcc-libs            5.3.0                         7  \n",
      "m2w64-gcc-libs-core       5.3.0                         7  \n",
      "m2w64-gmp                 6.1.0                         2  \n",
      "m2w64-libwinpthread-git   5.0.0.4634.697f757               2  \n",
      "markupsafe                1.1.1            py37he774522_0  \n",
      "matplotlib                3.1.3                    py37_0  \n",
      "matplotlib-base           3.1.3            py37h64f37c6_0  \n",
      "mccabe                    0.6.1                    py37_1  \n",
      "menuinst                  1.4.16           py37he774522_0  \n",
      "mistune                   0.8.4            py37he774522_0  \n",
      "mkl                       2020.0                      166  \n",
      "mkl-service               2.3.0            py37hb782905_0  \n",
      "mkl_fft                   1.0.15           py37h14836fe_0  \n",
      "mkl_random                1.1.0            py37h675688f_0  \n",
      "mock                      4.0.1                      py_0  \n",
      "more-itertools            8.2.0                      py_0  \n",
      "mpmath                    1.1.0                    py37_0  \n",
      "msgpack-python            0.6.1            py37h74a9793_1  \n",
      "msys2-conda-epoch         20160418                      1  \n",
      "multipledispatch          0.6.0                    py37_0  \n",
      "murmurhash                1.0.2                    pypi_0    pypi\n",
      "navigator-updater         0.2.1                    py37_0  \n",
      "nbconvert                 5.6.1                    py37_0  \n",
      "nbformat                  5.0.4                      py_0  \n",
      "networkx                  2.4                        py_0  \n",
      "nltk                      3.4.5                    py37_0  \n",
      "nose                      1.3.7                    py37_2  \n",
      "notebook                  6.0.3                    py37_0  \n",
      "numba                     0.48.0           py37h47e9c7a_0  \n",
      "numexpr                   2.7.1            py37h25d0782_0  \n",
      "numpy                     1.18.1           py37h93ca92e_0  \n",
      "numpy-base                1.18.1           py37hc3f5095_1  \n",
      "numpydoc                  0.9.2                      py_0  \n",
      "olefile                   0.46                     py37_0  \n",
      "openpyxl                  3.0.3                      py_0  \n",
      "openssl                   1.1.1d               he774522_4  \n",
      "packaging                 20.1                     pypi_0    pypi\n",
      "pandas                    1.0.1            py37h47e9c7a_0  \n",
      "pandoc                    2.2.3.2                       0  \n",
      "pandocfilters             1.4.2                    py37_1  \n",
      "paramiko                  2.7.1                      py_0  \n",
      "parso                     0.5.2                      py_0  \n",
      "partd                     1.1.0                      py_0  \n",
      "path                      13.1.0                   py37_0  \n",
      "path.py                   12.4.0                        0  \n",
      "pathlib2                  2.3.5                    py37_0  \n",
      "pathtools                 0.1.2                      py_1  \n",
      "patsy                     0.5.1                    py37_0  \n",
      "pep8                      1.7.1                    py37_0  \n",
      "pexpect                   4.8.0                    py37_0  \n",
      "pickleshare               0.7.5                    py37_0  \n",
      "pillow                    7.0.0            py37hcc1f983_0  \n",
      "pip                       20.0.2                   py37_1  \n",
      "pkginfo                   1.5.0.1                  py37_0  \n",
      "plac                      1.1.3                    pypi_0    pypi\n",
      "pluggy                    0.13.1                   py37_0  \n",
      "ply                       3.11                     py37_0  \n",
      "powershell_shortcut       0.0.1                         3  \n",
      "prometheus_client         0.7.1                      py_0  \n",
      "prompt_toolkit            3.0.3                      py_0  \n",
      "psutil                    5.6.7            py37he774522_0  \n",
      "py                        1.8.1                      py_0  \n",
      "py-lief                   0.9.0            py37ha925a31_2  \n",
      "pycodestyle               2.5.0                    py37_0  \n",
      "pycosat                   0.6.3            py37he774522_0  \n",
      "pycparser                 2.19                     py37_0  \n",
      "pycrypto                  2.6.1            py37hfa6e2cd_9  \n",
      "pycurl                    7.43.0.5         py37h7a1dbc1_0  \n",
      "pydocstyle                4.0.1                      py_0  \n",
      "pyflakes                  2.1.1                    py37_0  \n",
      "pygame                    1.9.6                    pypi_0    pypi\n",
      "pygments                  2.5.2                      py_0  \n",
      "pylint                    2.4.4                    py37_0  \n",
      "pynacl                    1.3.0            py37h62dcd97_0  \n",
      "pyodbc                    4.0.30           py37ha925a31_0  \n",
      "pyopenssl                 19.1.0                   py37_0  \n",
      "pyparsing                 2.4.6                      py_0  \n",
      "pyqt                      5.9.2            py37h6538335_2  \n",
      "pyreadline                2.1                      py37_1  \n",
      "pyrsistent                0.15.7           py37he774522_0  \n",
      "pysocks                   1.7.1                    py37_0  \n",
      "pytables                  3.6.1            py37h1da0976_0  \n",
      "pytest                    5.3.5                    py37_0  \n",
      "pytest-arraydiff          0.3              py37h39e3cac_0  \n",
      "pytest-astropy            0.8.0                      py_0  \n",
      "pytest-astropy-header     0.1.2                      py_0  \n",
      "pytest-doctestplus        0.5.0                      py_0  \n",
      "pytest-openfiles          0.4.0                      py_0  \n",
      "pytest-remotedata         0.3.2                    py37_0  \n",
      "python                    3.7.6                h60c2a47_2  \n",
      "python-dateutil           2.8.1                      py_0  \n",
      "python-jsonrpc-server     0.3.4                      py_0  \n",
      "python-language-server    0.31.7                   py37_0  \n",
      "python-libarchive-c       2.8                     py37_13  \n",
      "python-slugify            4.0.1                    pypi_0    pypi\n",
      "pytz                      2019.3                     py_0  \n",
      "pywavelets                1.1.1            py37he774522_0  \n",
      "pywin32                   227              py37he774522_1  \n",
      "pywin32-ctypes            0.2.0                 py37_1000  \n",
      "pywinpty                  0.5.7                    py37_0  \n",
      "pyyaml                    5.3              py37he774522_0  \n",
      "pyzmq                     18.1.1           py37ha925a31_0  \n",
      "qdarkstyle                2.8                        py_0  \n",
      "qt                        5.9.7            vc14h73c81de_0  \n",
      "qtawesome                 0.6.1                      py_0  \n",
      "qtconsole                 4.6.0                      py_1  \n",
      "qtpy                      1.9.0                      py_0  \n",
      "requests                  2.22.0                   py37_1  \n",
      "rope                      0.16.0                     py_0  \n",
      "rtree                     0.9.3            py37h21ff451_0  \n",
      "ruamel_yaml               0.15.87          py37he774522_0  \n",
      "scikit-image              0.16.2           py37h47e9c7a_0  \n",
      "scikit-learn              0.22.1           py37h6288b17_0  \n",
      "scipy                     1.4.1            py37h9439919_0  \n",
      "seaborn                   0.10.0                     py_0  \n",
      "send2trash                1.5.0                    py37_0  \n",
      "setuptools                45.2.0                   py37_0  \n",
      "simplegeneric             0.8.1                    py37_2  \n",
      "singledispatch            3.4.0.3                  py37_0  \n",
      "sip                       4.19.8           py37h6538335_0  \n",
      "six                       1.14.0                   py37_0  \n",
      "slicer                    0.0.7                    pypi_0    pypi\n",
      "slugify                   0.0.1                    pypi_0    pypi\n",
      "snappy                    1.1.7                h777316e_3  \n",
      "snowballstemmer           2.0.0                      py_0  \n",
      "sortedcollections         1.1.2                    py37_0  \n",
      "sortedcontainers          2.1.0                    py37_0  \n",
      "soupsieve                 1.9.5                    py37_0  \n",
      "sphinx                    2.4.0                      py_0  \n",
      "sphinxcontrib             1.0                      py37_1  \n",
      "sphinxcontrib-applehelp   1.0.1                      py_0  \n",
      "sphinxcontrib-devhelp     1.0.1                      py_0  \n",
      "sphinxcontrib-htmlhelp    1.0.2                      py_0  \n",
      "sphinxcontrib-jsmath      1.0.1                      py_0  \n",
      "sphinxcontrib-qthelp      1.0.2                      py_0  \n",
      "sphinxcontrib-serializinghtml 1.1.3                      py_0  \n",
      "sphinxcontrib-websupport  1.2.0                      py_0  \n",
      "spyder                    4.0.1                    py37_0  \n",
      "spyder-kernels            1.8.1                    py37_0  \n",
      "sqlalchemy                1.3.13           py37he774522_0  \n",
      "sqlite                    3.31.1               he774522_0  \n",
      "srsly                     1.0.2                    pypi_0    pypi\n",
      "statsmodels               0.11.0           py37he774522_0  \n",
      "sympy                     1.5.1                    py37_0  \n",
      "tbb                       2020.0               h74a9793_0  \n",
      "tblib                     1.6.0                      py_0  \n",
      "terminado                 0.8.3                    py37_0  \n",
      "testpath                  0.4.4                      py_0  \n",
      "text-unidecode            1.3                      pypi_0    pypi\n",
      "thinc                     7.4.0                    pypi_0    pypi\n",
      "tk                        8.6.8                hfa6e2cd_0  \n",
      "toolz                     0.10.0                     py_0  \n",
      "torch                     1.12.0                   pypi_0    pypi\n",
      "torchvision               0.13.0                   pypi_0    pypi\n",
      "tornado                   6.0.3            py37he774522_3  \n",
      "tqdm                      4.42.1                     py_0  \n",
      "traitlets                 4.3.3                    py37_0  \n",
      "typing-extensions         4.3.0                    pypi_0    pypi\n",
      "ujson                     1.35             py37hfa6e2cd_0  \n",
      "unicodecsv                0.14.1                   py37_0  \n",
      "urllib3                   1.25.8                   py37_0  \n",
      "vboxapi                   1.0                      pypi_0    pypi\n",
      "vc                        14.1                 h0510ff6_4  \n",
      "virtualenv                20.0.16                  pypi_0    pypi\n",
      "vs2015_runtime            14.16.27012          hf0eaf9b_1  \n",
      "watchdog                  0.10.2                   py37_0  \n",
      "wcwidth                   0.1.8                      py_0  \n",
      "webencodings              0.5.1                    py37_1  \n",
      "werkzeug                  1.0.0                      py_0  \n",
      "wheel                     0.34.2                   py37_0  \n",
      "widgetsnbextension        3.5.1                    py37_0  \n",
      "win_inet_pton             1.1.0                    py37_0  \n",
      "win_unicode_console       0.5                      py37_0  \n",
      "wincertstore              0.2                      py37_0  \n",
      "winpty                    0.4.3                         4  \n",
      "wrapt                     1.11.2           py37he774522_0  \n",
      "xlrd                      1.2.0                    py37_0  \n",
      "xlsxwriter                1.2.7                      py_0  \n",
      "xlwings                   0.17.1                   py37_0  \n",
      "xlwt                      1.3.0                    py37_0  \n",
      "xmltodict                 0.12.0                     py_0  \n",
      "xz                        5.2.4                h2fa13f4_4  \n",
      "yaml                      0.1.7                hc54c509_2  \n",
      "yapf                      0.28.0                     py_0  \n",
      "zeromq                    4.3.1                h33f27b4_3  \n",
      "zict                      1.0.0                      py_0  \n",
      "zipp                      2.2.0                      py_0  \n",
      "zlib                      1.2.11               h62dcd97_3  \n",
      "zstd                      1.3.7                h508b16e_0  \n"
     ]
    }
   ],
   "source": [
    "!conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_in_file(model_name, accuracy):\n",
    "    model_file = open(\"model_details.txt\",\"a\")\n",
    "    model_file.write(model_name + \" -> accuracy : \" + str(accuracy) + \"\\n\" )\n",
    "    model_file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:   \n",
    "    def warn(*args, **kwargs):\n",
    "        pass\n",
    "    import warnings\n",
    "    warnings.warn = warn\n",
    "\n",
    "\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import torch as t\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# feature_indices_to_consider = list(range(23))#list(range(35)) #[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 18, 20, 22]\n",
    "hidden = 4\n",
    "class simple_model(nn.Module):\n",
    "    def __init__(self, num_features=FEATURE_MATRIX.shape[1], hidden_dim=32*4, drop_probab=0.3):\n",
    "        super(simple_model, self).__init__()\n",
    "        \n",
    "        ####\n",
    "        self.drop_probab = drop_probab\n",
    "        self.dropout_feature = nn.Dropout(p=0.3)\n",
    "        self.fc1 = nn.Linear(num_features, hidden_dim)\n",
    "        self.dropout1 = nn.Dropout(p=self.drop_probab)\n",
    "        num_hidden = hidden\n",
    "        self.fc_hidden = nn.ModuleList([nn.Linear(hidden_dim, hidden_dim) for i in range(num_hidden)])\n",
    "        self.dropout_hidden = nn.ModuleList([nn.Dropout(p=0.0) for i in range(num_hidden)])\n",
    "        self.fc2 = nn.Linear(hidden_dim, 8)\n",
    "        self.dropout2 = nn.Dropout(p=0.3)\n",
    "        self.outLayer = nn.Linear(8, 1)\n",
    "#         self.softmax = nn.Softmax(-1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.num_hidden = num_hidden\n",
    "        ####\n",
    "\n",
    "    def forward(self, features):\n",
    "        features = self.dropout_feature(features)\n",
    "        features = self.fc1(features)\n",
    "        features = self.dropout1(features)\n",
    "        for i in range(self.num_hidden):\n",
    "            features = self.fc_hidden[i](features)\n",
    "            features = self.dropout_hidden[i](features)\n",
    "        features = self.fc2(features)\n",
    "        features = self.dropout2(features)\n",
    "        logit = self.outLayer(features)\n",
    "#         print(features.shape, features)\n",
    "        probab = self.sigmoid(logit)\n",
    "        return probab\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n",
      "[0, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 46, 45]\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    def warn(*args, **kwargs):\n",
    "        pass\n",
    "    import warnings\n",
    "    warnings.warn = warn\n",
    "\n",
    "\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import torch as t\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# feature_indices_to_consider = list(range(23))#list(range(35)) #[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 18, 20, 22]\n",
    "# naeem modified\n",
    "print(FEATURE_MATRIX.shape[1])\n",
    "last_idx = FEATURE_MATRIX.shape[1] - 1\n",
    "feature_indices_to_consider = list(range(num_features))  + [last_idx, last_idx - 1] #list(range(35)) #[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 18, 20, 22]\n",
    "remove_indices = [1, 2, 3]\n",
    "for i in remove_indices:\n",
    "    feature_indices_to_consider.remove(i)\n",
    "print(feature_indices_to_consider)\n",
    "# feature_indices_to_consider = [1, 2, 3, 11, 14, 21, 23, 26, 32, 45]\n",
    "# feature_indices_to_consider = [2, 26, 32, 45]\n",
    "\n",
    "class simple_model(nn.Module):\n",
    "    def __init__(self, num_features=FEATURE_MATRIX.shape[1], hidden_dim=32, drop_probab=.8):\n",
    "        super(simple_model, self).__init__()\n",
    "        \n",
    "        ####\n",
    "        num_hidden = hidden\n",
    "        hidden_dim = hidden_dimension\n",
    "        self.fc1 = nn.Linear(num_features, hidden_dim)\n",
    "        self.fc_hidden = nn.ModuleList([nn.Linear(hidden_dim, hidden_dim) for i in range(num_hidden)])\n",
    "        self.fc2 = nn.Linear(hidden_dim, 8)\n",
    "        self.outLayer = nn.Linear(8, 1)\n",
    "#         self.softmax = nn.Softmax(-1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.num_hidden = num_hidden\n",
    "        self.drop_probab = drop_probab\n",
    "        self.dropout = nn.functional.dropout\n",
    "        ####\n",
    "\n",
    "    def forward(self, features):\n",
    "        features = self.fc1(features)\n",
    "        features = self.dropout(features, p=self.drop_probab)\n",
    "        for i in range(self.num_hidden):\n",
    "            features = self.fc_hidden[i](features)\n",
    "        features = self.fc2(features)\n",
    "        features = self.dropout(features, p=self.drop_probab)\n",
    "        logit = self.outLayer(features)\n",
    "#         print(features.shape, features)\n",
    "        probab = self.sigmoid(logit)\n",
    "        return probab\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "974\n",
      "654\n",
      "320\n"
     ]
    }
   ],
   "source": [
    "Final_Samples = json.load(open('Final_Samples_6yrs.json', 'r')) \n",
    "len_positive_samples = 0\n",
    "len_negative_samples = 0\n",
    "for x in Final_Samples:\n",
    "    if x[1] == 1 :\n",
    "        len_positive_samples += 1\n",
    "    else :\n",
    "        len_negative_samples += 1\n",
    "        \n",
    "print(len(Final_Samples))\n",
    "print(len_positive_samples)\n",
    "print(len_negative_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "974\n",
      "[['012_S_0689', 1], ['018_S_4733', 1]]\n",
      "500 320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(820, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Final_Samples = json.load(open('Final_Samples_6yrs.json', 'r')) \n",
    "print(len(Final_Samples))\n",
    "print(Final_Samples[:2])\n",
    "positive_samples = Final_Samples[:len_positive_samples] # Final_Samples[654:]\n",
    "positive_samples = Final_Samples[:len_positive_samples]\n",
    "negative_samples = Final_Samples[len_positive_samples:]\n",
    "random_seed = None\n",
    "if random_seed is not None: \n",
    "    random.seed(random_seed * 2)\n",
    "random.shuffle(positive_samples)\n",
    "random.shuffle(negative_samples)\n",
    "Final_Samples = positive_samples[:500] + negative_samples[:500]\n",
    "print(len([x[1] for x in Final_Samples if x[1] == 1]), len([x[1] for x in Final_Samples if x[1] == 0]))\n",
    "Final_Samples = np.array(Final_Samples)\n",
    "Final_Samples.shape\n",
    "# Final_Samples.reshape(10, -1, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "simple_model(\n",
       "  (fc1): Linear(in_features=34, out_features=32, bias=True)\n",
       "  (fc_hidden): ModuleList(\n",
       "    (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (3): Linear(in_features=32, out_features=32, bias=True)\n",
       "  )\n",
       "  (fc2): Linear(in_features=32, out_features=8, bias=True)\n",
       "  (outLayer): Linear(in_features=8, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model(num_features=len(feature_indices_to_consider))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "\n",
    "class dataSet(data.Dataset):\n",
    "    def __init__(self, Final_Samples, feature_matrix, usable_samples_ADNI, feature_indices_to_consider=feature_indices_to_consider):\n",
    "        super(dataSet, self).__init__()  \n",
    "        self.data_len = len(Final_Samples)\n",
    "        self.usable_samples_ADNI = usable_samples_ADNI\n",
    "        self.Final_Samples = Final_Samples\n",
    "        self.feature_indices_to_consider = feature_indices_to_consider\n",
    "        self.feature_matrix = feature_matrix[:, self.feature_indices_to_consider]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        features = torch.from_numpy(self.feature_matrix[self.usable_samples_ADNI[self.Final_Samples[index][0]]]).float()\n",
    "        label = torch.tensor([float(self.Final_Samples[index][1])]).float()\n",
    "        return features, label\n",
    "    \n",
    "    def update_prs_features(self, mean, std):\n",
    "        self.feature_matrix = (self.feature_matrix - mean) / std\n",
    "        \n",
    "    def get_mean_std(self):\n",
    "        mean = self.feature_matrix.mean(0)\n",
    "        std = self.feature_matrix.std(0)\n",
    "        return mean, std\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "654 320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1816, 34)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "\n",
    "\n",
    "def random_samples(total_folds, random_seed=None):\n",
    "    Final_Samples = json.load(open('Final_Samples_6yrs.json', 'r')) \n",
    "# #     print(len(Final_Samples))\n",
    "# #     print(Final_Samples[:2])\n",
    "#     positive_samples = Final_Samples[:len_positive_samples]\n",
    "#     negative_samples = Final_Samples[len_positive_samples:]\n",
    "#     min_len = min( len(positive_samples), len(negative_samples))\n",
    "# #     random_seed = None\n",
    "#     if random_seed is not None: \n",
    "#         random.seed(random_seed * 2)\n",
    "#     random.shuffle(positive_samples)\n",
    "#     random.shuffle(negative_samples)\n",
    "#     print(min_len)\n",
    "#     Final_Samples = positive_samples[:min_len] + negative_samples[:min_len]\n",
    "    print(len([x[1] for x in Final_Samples if x[1] == 1]), len([x[1] for x in Final_Samples if x[1] == 0]))\n",
    "    Final_Samples = np.array(Final_Samples)\n",
    "    Final_Samples.shape\n",
    "    # Final_Samples.reshape(10, -1, 2).shape\n",
    "    Final_Samples = json.load(open('Final_Samples_6yrs.json', 'r')) \n",
    "    positive_samples = Final_Samples[:654]\n",
    "    negative_samples = Final_Samples[654:]\n",
    "    if random_seed is not None: \n",
    "        random.seed(random_seed * 2)\n",
    "    random.shuffle(positive_samples)\n",
    "    random.shuffle(negative_samples)\n",
    "    Final_Samples = positive_samples[:500] + negative_samples[:500]\n",
    "    if random_seed is not None: \n",
    "        random.seed(random_seed)\n",
    "    random.shuffle(Final_Samples)\n",
    "    Final_Samples = np.array(Final_Samples)\n",
    "#     N_splits = Final_Samples.reshape(total_folds, -1, 2)\n",
    "#     print(N_splits.shape)\n",
    "#     print(Final_Samples.shape)\n",
    "    return Final_Samples\n",
    "#     return N_splits\n",
    "\n",
    "def generate_datasets(N_splits, fold_num, random_seed):\n",
    "#     loo.get_n_splits(X)\n",
    "    test_samples = N_splits[fold_num:fold_num+1].reshape([-1, 2])\n",
    "    train_samples = np.concatenate([N_splits[0:fold_num],N_splits[fold_num+1:]], 0).reshape([-1, 2]).tolist()\n",
    "    if random_seed is not None: \n",
    "        random.seed(random_seed * 3)\n",
    "    random.shuffle(train_samples)\n",
    "    train_samples = np.array(train_samples)\n",
    "    split_pos = int(train_samples.shape[0] * 1.) \n",
    "    #split_pos = int(train_samples.shape[0] * .8) \n",
    "#     print(train_samples.shape, split_pos, train_samples.shape[0])\n",
    "    train_samples, val_samples = train_samples[:split_pos], train_samples[split_pos:]\n",
    "    train_set = dataSet(Final_Samples=train_samples, \n",
    "                        feature_matrix=FEATURE_MATRIX, \n",
    "                        usable_samples_ADNI=usable_samples_ADNI)\n",
    "    val_set = dataSet(Final_Samples=val_samples, \n",
    "                      feature_matrix=FEATURE_MATRIX, \n",
    "                      usable_samples_ADNI=usable_samples_ADNI)\n",
    "    test_set = dataSet(Final_Samples=test_samples, \n",
    "                      feature_matrix=FEATURE_MATRIX, \n",
    "                      usable_samples_ADNI=usable_samples_ADNI)\n",
    "    mean, std = train_set.get_mean_std()\n",
    "    train_set.update_prs_features(mean, std)\n",
    "    val_set.update_prs_features(mean, std)\n",
    "    test_set.update_prs_features(mean, std)\n",
    "#     print(\"normal one\")\n",
    "#     print(train_set.shape, test_set.shape, val_set.shape)\n",
    "    return train_set, val_set, test_set\n",
    "\n",
    "def generate_datasets_loocv(train_index, test_index, random_seed):\n",
    "#     X_train, X_test = N_splits[train_index], N_splits[test_index]\n",
    "#     y_train, y_test = N_splits[train_index], N_splits[test_index]\n",
    "#     print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "#     loo.get_n_splits(X)\n",
    "#     test_samples = N_splits[fold_num:fold_num+1].reshape([-1, 2])\n",
    "    test_samples = N_splits[test_index]\n",
    "    train_samples = N_splits[train_index]\n",
    "#     train_samples = np.concatenate([N_splits[0:fold_num],N_splits[fold_num+1:]], 0).reshape([-1, 2]).tolist()\n",
    "    if random_seed is not None: \n",
    "        random.seed(random_seed * 3)\n",
    "    random.shuffle(train_samples)\n",
    "    train_samples = np.array(train_samples)\n",
    "    split_pos = int(train_samples.shape[0] * 1.) \n",
    "    #split_pos = int(train_samples.shape[0] * .8) \n",
    "#     print(train_samples.shape, split_pos, train_samples.shape[0])\n",
    "    train_samples, val_samples = train_samples[:split_pos], train_samples[split_pos:]\n",
    "    train_set = dataSet(Final_Samples=train_samples, \n",
    "                        feature_matrix=FEATURE_MATRIX, \n",
    "                        usable_samples_ADNI=usable_samples_ADNI)\n",
    "    val_set = dataSet(Final_Samples=val_samples, \n",
    "                      feature_matrix=FEATURE_MATRIX, \n",
    "                      usable_samples_ADNI=usable_samples_ADNI)\n",
    "    test_set = dataSet(Final_Samples=test_samples, \n",
    "                      feature_matrix=FEATURE_MATRIX, \n",
    "                      usable_samples_ADNI=usable_samples_ADNI)\n",
    "    mean, std = train_set.get_mean_std()\n",
    "    train_set.update_prs_features(mean, std)\n",
    "    val_set.update_prs_features(mean, std)\n",
    "    test_set.update_prs_features(mean, std)\n",
    "#     print(\"loocv\")\n",
    "#     print(len(train_set))\n",
    "#     print(len(val_set))\n",
    "#     print(len(test_set))\n",
    "    return train_set, val_set, test_set\n",
    "\n",
    "def generate_loader(train_set, val_set, test_set, num_workers):\n",
    "    train_batch_size = train_set.__len__()\n",
    "    val_batch_size = val_set.__len__()\n",
    "    test_batch_size = test_set.__len__()\n",
    "    train_loader = torch.utils.data.DataLoader(train_set,\n",
    "                                              batch_size=train_batch_size,\n",
    "                                              shuffle=True,\n",
    "                                              pin_memory=(torch.cuda.is_available()),\n",
    "                                              num_workers=num_workers)\n",
    "    val_loader = torch.utils.data.DataLoader(val_set,\n",
    "                                              batch_size=val_batch_size,\n",
    "                                              shuffle=False,\n",
    "                                              pin_memory=(torch.cuda.is_available()),\n",
    "                                              num_workers=num_workers)\n",
    "    test_loader = torch.utils.data.DataLoader(test_set,\n",
    "                                              batch_size=test_batch_size,\n",
    "                                              shuffle=False,\n",
    "                                              pin_memory=(torch.cuda.is_available()),\n",
    "                                              num_workers=num_workers)\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "train_set, val_set, test_set = generate_datasets(N_splits=random_samples(total_folds=10, random_seed=0), fold_num=0, random_seed=0)\n",
    "val_set.feature_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1816\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, precision_recall_curve, auc\n",
    "\n",
    "\n",
    "def epoch(model, optimizer, criterion, is_training, loader):\n",
    "    pred = []\n",
    "    true = []\n",
    "    total_loss = 0.\n",
    "    \n",
    "    for batch_idx, (features, label) in enumerate(loader):\n",
    "        features = torch.autograd.Variable(features.to(DEVICE).float())\n",
    "        label = torch.autograd.Variable(label.to(DEVICE).float())\n",
    "#         print(features.shape, label.shape)\n",
    "        probab = model(features)\n",
    "    \n",
    "        if is_training:  \n",
    "            loss = criterion(probab, label)\n",
    "            ## compute gradient and do SGD step \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "#             print(batch_idx, ':', loss) \n",
    "        pred += probab.detach().cpu().numpy().tolist()\n",
    "        true += label.detach().cpu().numpy().tolist()\n",
    "    \n",
    "    pred, true, total_loss = np.array(pred).reshape([-1]), np.array(true).reshape([-1]), total_loss\n",
    "    pred_binary = (pred > .5).astype(float)\n",
    "#     precision, recall, fscore, support = precision_recall_fscore_support(true, pred_binary)\n",
    "#     auroc = roc_auc_score(true, pred)\n",
    "#     p, r, thresholds = precision_recall_curve(true, pred)\n",
    "#     auprc = auc(r, p)\n",
    "#     acc = (pred_binary==true).mean()\n",
    "    \n",
    "#     return precision[1], recall[1], fscore[1], support, auroc, auprc, acc, total_loss, pred, pred_binary, true\n",
    "    return None, None, None, None, None, None, None, total_loss, pred, pred_binary, true\n",
    "    \n",
    "import json\n",
    "import pandas as pd\n",
    "GWAS_ID = 'ieu-b-25'\n",
    "usable_samples_ADNI = pd.read_csv(f'./PRSice_output/{GWAS_ID}/{GWAS_ID}.best', ' ')['IID'].to_numpy().tolist()\n",
    "usable_samples_ADNI = {'_'.join(sample.split('_')[1:]):idx for idx,sample in enumerate(usable_samples_ADNI)}\n",
    "# usable_samples_ADNI = {sample:idx for idx,sample in enumerate(usable_samples_ADNI)}\n",
    "print(len( usable_samples_ADNI ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820\n",
      "820\n",
      "Shape of usable features :  (820, 34)\n",
      "151\n",
      "(820, 34) (820, 2)\n",
      "(669, 34) (669, 2)\n",
      "Length of usable labels :  669\n",
      "Usable Features :  tensor([[ 1.2005,  1.4352,  0.5413,  1.4029,  1.9579,  2.0498,  0.1080,  0.4447,\n",
      "         -0.3195,  0.6849,  0.4690,  0.2255, -0.5383, -1.4164, -1.2869, -0.4523,\n",
      "         -0.4373,  0.5819,  0.2597,  0.2019, -0.0252,  0.5176, -0.0695, -0.0468,\n",
      "          0.3372,  0.7456, -0.6969, -0.4416, -0.3498, -0.0318,  2.0358,  0.2293,\n",
      "          0.6070,  1.0000],\n",
      "        [ 1.2046,  1.1214, -1.7508, -0.1151, -0.4027,  0.7424, -0.4675,  1.2003,\n",
      "         -0.1221,  0.1562,  0.5051,  0.4414, -0.6254,  0.5254, -0.6106, -0.4560,\n",
      "         -0.6200,  0.4354,  0.2572,  0.6991, -0.3323, -0.5618, -0.2380, -0.3121,\n",
      "          0.1095, -0.2321,  0.6335, -0.3431,  0.8644, -0.0313,  0.8078,  0.0029,\n",
      "          0.8150,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "import shap\n",
    "from copy import deepcopy\n",
    "\n",
    "print(len(Final_Samples))\n",
    "usable_indices = [( usable_samples_ADNI[Final_Samples[i][0]] if ( Final_Samples[i][0] in usable_samples_ADNI.keys() ) else None ) for i in range(len(Final_Samples))]\n",
    "print(len(usable_indices))\n",
    "# print(usable_indices)\n",
    "usable_features = FEATURE_MATRIX[usable_indices][:, feature_indices_to_consider]\n",
    "print(\"Shape of usable features : \", usable_features.shape)\n",
    "\n",
    "\n",
    "# removing age with value 0\n",
    "#--------------------------------------------------------------------------------\n",
    "age_zero = 0\n",
    "age_zero_idx = []\n",
    "for i in range(len(usable_features)):\n",
    "    if usable_features[i, -2] == 0.00:\n",
    "        age_zero += 1\n",
    "        age_zero_idx.append(i)\n",
    "print(len(age_zero_idx))\n",
    "print(usable_features.shape, Final_Samples.shape)\n",
    "usable_features = np.delete(usable_features, age_zero_idx, axis = 0)\n",
    "Final_Samples = np.delete(Final_Samples, age_zero_idx, axis = 0)\n",
    "print(usable_features.shape, Final_Samples.shape)\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "usable_labels = np.array([float(Final_Samples[i][1]) for i in range(len(Final_Samples))])\n",
    "print(\"Length of usable labels : \", len(usable_labels))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "usable_features = torch.autograd.Variable(torch.from_numpy(usable_features)).to(DEVICE).float()\n",
    "\n",
    "print(\"Usable Features : \", usable_features[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([669, 34])\n"
     ]
    }
   ],
   "source": [
    "print(usable_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NF:34\n",
      "\n",
      "#F10\n",
      "654 320\n",
      "TEST :  [0]\n",
      "total loss :  0.0\n",
      "TEST :  [1]\n",
      "total loss :  0.0\n",
      "TEST :  [2]\n",
      "total loss :  0.0\n",
      "TEST :  [3]\n",
      "total loss :  0.0\n",
      "TEST :  [4]\n",
      "total loss :  0.0\n",
      "TEST :  [5]\n",
      "total loss :  0.0\n",
      "TEST :  [6]\n",
      "total loss :  0.0\n",
      "TEST :  [7]\n",
      "total loss :  0.0\n",
      "TEST :  [8]\n",
      "total loss :  0.0\n",
      "TEST :  [9]\n",
      "total loss :  0.0\n",
      "TEST :  [10]\n",
      "total loss :  0.0\n",
      "TEST :  [11]\n",
      "total loss :  0.0\n",
      "TEST :  [12]\n",
      "total loss :  0.0\n",
      "TEST :  [13]\n",
      "total loss :  0.0\n",
      "TEST :  [14]\n",
      "total loss :  0.0\n",
      "TEST :  [15]\n",
      "total loss :  0.0\n",
      "TEST :  [16]\n",
      "total loss :  0.0\n",
      "TEST :  [17]\n",
      "total loss :  0.0\n",
      "TEST :  [18]\n",
      "total loss :  0.0\n",
      "TEST :  [19]\n",
      "total loss :  0.0\n",
      "TEST :  [20]\n",
      "total loss :  0.0\n",
      "TEST :  [21]\n",
      "total loss :  0.0\n",
      "TEST :  [22]\n",
      "total loss :  0.0\n",
      "TEST :  [23]\n",
      "total loss :  0.0\n",
      "TEST :  [24]\n",
      "total loss :  0.0\n",
      "TEST :  [25]\n",
      "total loss :  0.0\n",
      "TEST :  [26]\n",
      "total loss :  0.0\n",
      "TEST :  [27]\n",
      "total loss :  0.0\n",
      "TEST :  [28]\n",
      "total loss :  0.0\n",
      "TEST :  [29]\n",
      "total loss :  0.0\n",
      "TEST :  [30]\n",
      "total loss :  0.0\n",
      "TEST :  [31]\n",
      "total loss :  0.0\n",
      "TEST :  [32]\n",
      "total loss :  0.0\n",
      "TEST :  [33]\n",
      "total loss :  0.0\n",
      "TEST :  [34]\n",
      "total loss :  0.0\n",
      "TEST :  [35]\n",
      "total loss :  0.0\n",
      "TEST :  [36]\n",
      "total loss :  0.0\n",
      "TEST :  [37]\n",
      "total loss :  0.0\n",
      "TEST :  [38]\n",
      "total loss :  0.0\n",
      "TEST :  [39]\n",
      "total loss :  0.0\n",
      "TEST :  [40]\n",
      "total loss :  0.0\n",
      "TEST :  [41]\n",
      "total loss :  0.0\n",
      "TEST :  [42]\n",
      "total loss :  0.0\n",
      "TEST :  [43]\n",
      "total loss :  0.0\n",
      "TEST :  [44]\n",
      "total loss :  0.0\n",
      "TEST :  [45]\n",
      "total loss :  0.0\n",
      "TEST :  [46]\n",
      "total loss :  0.0\n",
      "TEST :  [47]\n",
      "total loss :  0.0\n",
      "TEST :  [48]\n",
      "total loss :  0.0\n",
      "TEST :  [49]\n",
      "total loss :  0.0\n",
      "TEST :  [50]\n",
      "total loss :  0.0\n",
      "TEST :  [51]\n",
      "total loss :  0.0\n",
      "TEST :  [52]\n",
      "total loss :  0.0\n",
      "TEST :  [53]\n",
      "total loss :  0.0\n",
      "TEST :  [54]\n",
      "total loss :  0.0\n",
      "TEST :  [55]\n",
      "total loss :  0.0\n",
      "TEST :  [56]\n",
      "total loss :  0.0\n",
      "TEST :  [57]\n",
      "total loss :  0.0\n",
      "TEST :  [58]\n",
      "total loss :  0.0\n",
      "TEST :  [59]\n",
      "total loss :  0.0\n",
      "TEST :  [60]\n",
      "total loss :  0.0\n",
      "TEST :  [61]\n",
      "total loss :  0.0\n",
      "TEST :  [62]\n",
      "total loss :  0.0\n",
      "TEST :  [63]\n",
      "total loss :  0.0\n",
      "TEST :  [64]\n",
      "total loss :  0.0\n",
      "TEST :  [65]\n",
      "total loss :  0.0\n",
      "TEST :  [66]\n",
      "total loss :  0.0\n",
      "TEST :  [67]\n",
      "total loss :  0.0\n",
      "TEST :  [68]\n",
      "total loss :  0.0\n",
      "TEST :  [69]\n",
      "total loss :  0.0\n",
      "TEST :  [70]\n",
      "total loss :  0.0\n",
      "TEST :  [71]\n",
      "total loss :  0.0\n",
      "TEST :  [72]\n",
      "total loss :  0.0\n",
      "TEST :  [73]\n",
      "total loss :  0.0\n",
      "TEST :  [74]\n",
      "total loss :  0.0\n",
      "TEST :  [75]\n",
      "total loss :  0.0\n",
      "TEST :  [76]\n",
      "total loss :  0.0\n",
      "TEST :  [77]\n",
      "total loss :  0.0\n",
      "TEST :  [78]\n",
      "total loss :  0.0\n",
      "TEST :  [79]\n",
      "total loss :  0.0\n",
      "TEST :  [80]\n",
      "total loss :  0.0\n",
      "TEST :  [81]\n",
      "total loss :  0.0\n",
      "TEST :  [82]\n",
      "total loss :  0.0\n",
      "TEST :  [83]\n",
      "total loss :  0.0\n",
      "TEST :  [84]\n",
      "total loss :  0.0\n",
      "TEST :  [85]\n",
      "total loss :  0.0\n",
      "TEST :  [86]\n",
      "total loss :  0.0\n",
      "TEST :  [87]\n",
      "total loss :  0.0\n",
      "TEST :  [88]\n",
      "total loss :  0.0\n",
      "TEST :  [89]\n",
      "total loss :  0.0\n",
      "TEST :  [90]\n",
      "total loss :  0.0\n",
      "TEST :  [91]\n",
      "total loss :  0.0\n",
      "TEST :  [92]\n",
      "total loss :  0.0\n",
      "TEST :  [93]\n",
      "total loss :  0.0\n",
      "TEST :  [94]\n",
      "total loss :  0.0\n",
      "TEST :  [95]\n",
      "total loss :  0.0\n",
      "TEST :  [96]\n",
      "total loss :  0.0\n",
      "TEST :  [97]\n",
      "total loss :  0.0\n",
      "TEST :  [98]\n",
      "total loss :  0.0\n",
      "TEST :  [99]\n",
      "total loss :  0.0\n",
      "TEST :  [100]\n",
      "total loss :  0.0\n",
      "TEST :  [101]\n",
      "total loss :  0.0\n",
      "TEST :  [102]\n",
      "total loss :  0.0\n",
      "TEST :  [103]\n",
      "total loss :  0.0\n",
      "TEST :  [104]\n",
      "total loss :  0.0\n",
      "TEST :  [105]\n",
      "total loss :  0.0\n",
      "TEST :  [106]\n",
      "total loss :  0.0\n",
      "TEST :  [107]\n",
      "total loss :  0.0\n",
      "TEST :  [108]\n",
      "total loss :  0.0\n",
      "TEST :  [109]\n",
      "total loss :  0.0\n",
      "TEST :  [110]\n",
      "total loss :  0.0\n",
      "TEST :  [111]\n",
      "total loss :  0.0\n",
      "TEST :  [112]\n",
      "total loss :  0.0\n",
      "TEST :  [113]\n",
      "total loss :  0.0\n",
      "TEST :  [114]\n",
      "total loss :  0.0\n",
      "TEST :  [115]\n",
      "total loss :  0.0\n",
      "TEST :  [116]\n",
      "total loss :  0.0\n",
      "TEST :  [117]\n",
      "total loss :  0.0\n",
      "TEST :  [118]\n",
      "total loss :  0.0\n",
      "TEST :  [119]\n",
      "total loss :  0.0\n",
      "TEST :  [120]\n",
      "total loss :  0.0\n",
      "TEST :  [121]\n",
      "total loss :  0.0\n",
      "TEST :  [122]\n",
      "total loss :  0.0\n",
      "TEST :  [123]\n",
      "total loss :  0.0\n",
      "TEST :  [124]\n",
      "total loss :  0.0\n",
      "TEST :  [125]\n",
      "total loss :  0.0\n",
      "TEST :  [126]\n",
      "total loss :  0.0\n",
      "TEST :  [127]\n",
      "total loss :  0.0\n",
      "TEST :  [128]\n",
      "total loss :  0.0\n",
      "TEST :  [129]\n",
      "total loss :  0.0\n",
      "TEST :  [130]\n",
      "total loss :  0.0\n",
      "TEST :  [131]\n",
      "total loss :  0.0\n",
      "TEST :  [132]\n",
      "total loss :  0.0\n",
      "TEST :  [133]\n",
      "total loss :  0.0\n",
      "TEST :  [134]\n",
      "total loss :  0.0\n",
      "TEST :  [135]\n",
      "total loss :  0.0\n",
      "TEST :  [136]\n",
      "total loss :  0.0\n",
      "TEST :  [137]\n",
      "total loss :  0.0\n",
      "TEST :  [138]\n",
      "total loss :  0.0\n",
      "TEST :  [139]\n",
      "total loss :  0.0\n",
      "TEST :  [140]\n",
      "total loss :  0.0\n",
      "TEST :  [141]\n",
      "total loss :  0.0\n",
      "TEST :  [142]\n",
      "total loss :  0.0\n",
      "TEST :  [143]\n",
      "total loss :  0.0\n",
      "TEST :  [144]\n",
      "total loss :  0.0\n",
      "TEST :  [145]\n",
      "total loss :  0.0\n",
      "TEST :  [146]\n",
      "total loss :  0.0\n",
      "TEST :  [147]\n",
      "total loss :  0.0\n",
      "TEST :  [148]\n",
      "total loss :  0.0\n",
      "TEST :  [149]\n",
      "total loss :  0.0\n",
      "TEST :  [150]\n",
      "total loss :  0.0\n",
      "TEST :  [151]\n",
      "total loss :  0.0\n",
      "TEST :  [152]\n",
      "total loss :  0.0\n",
      "TEST :  [153]\n",
      "total loss :  0.0\n",
      "TEST :  [154]\n",
      "total loss :  0.0\n",
      "TEST :  [155]\n",
      "total loss :  0.0\n",
      "TEST :  [156]\n",
      "total loss :  0.0\n",
      "TEST :  [157]\n",
      "total loss :  0.0\n",
      "TEST :  [158]\n",
      "total loss :  0.0\n",
      "TEST :  [159]\n",
      "total loss :  0.0\n",
      "TEST :  [160]\n",
      "total loss :  0.0\n",
      "TEST :  [161]\n",
      "total loss :  0.0\n",
      "TEST :  [162]\n",
      "total loss :  0.0\n",
      "TEST :  [163]\n",
      "total loss :  0.0\n",
      "TEST :  [164]\n",
      "total loss :  0.0\n",
      "TEST :  [165]\n",
      "total loss :  0.0\n",
      "TEST :  [166]\n",
      "total loss :  0.0\n",
      "TEST :  [167]\n",
      "total loss :  0.0\n",
      "TEST :  [168]\n",
      "total loss :  0.0\n",
      "TEST :  [169]\n",
      "total loss :  0.0\n",
      "TEST :  [170]\n",
      "total loss :  0.0\n",
      "TEST :  [171]\n",
      "total loss :  0.0\n",
      "TEST :  [172]\n",
      "total loss :  0.0\n",
      "TEST :  [173]\n",
      "total loss :  0.0\n",
      "TEST :  [174]\n",
      "total loss :  0.0\n",
      "TEST :  [175]\n",
      "total loss :  0.0\n",
      "TEST :  [176]\n",
      "total loss :  0.0\n",
      "TEST :  [177]\n",
      "total loss :  0.0\n",
      "TEST :  [178]\n",
      "total loss :  0.0\n",
      "TEST :  [179]\n",
      "total loss :  0.0\n",
      "TEST :  [180]\n",
      "total loss :  0.0\n",
      "TEST :  [181]\n",
      "total loss :  0.0\n",
      "TEST :  [182]\n",
      "total loss :  0.0\n",
      "TEST :  [183]\n",
      "total loss :  0.0\n",
      "TEST :  [184]\n",
      "total loss :  0.0\n",
      "TEST :  [185]\n",
      "total loss :  0.0\n",
      "TEST :  [186]\n",
      "total loss :  0.0\n",
      "TEST :  [187]\n",
      "total loss :  0.0\n",
      "TEST :  [188]\n",
      "total loss :  0.0\n",
      "TEST :  [189]\n",
      "total loss :  0.0\n",
      "TEST :  [190]\n",
      "total loss :  0.0\n",
      "TEST :  [191]\n",
      "total loss :  0.0\n",
      "TEST :  [192]\n",
      "total loss :  0.0\n",
      "TEST :  [193]\n",
      "total loss :  0.0\n",
      "TEST :  [194]\n",
      "total loss :  0.0\n",
      "TEST :  [195]\n",
      "total loss :  0.0\n",
      "TEST :  [196]\n",
      "total loss :  0.0\n",
      "TEST :  [197]\n",
      "total loss :  0.0\n",
      "TEST :  [198]\n",
      "total loss :  0.0\n",
      "TEST :  [199]\n",
      "total loss :  0.0\n",
      "TEST :  [200]\n",
      "total loss :  0.0\n",
      "TEST :  [201]\n",
      "total loss :  0.0\n",
      "TEST :  [202]\n",
      "total loss :  0.0\n",
      "TEST :  [203]\n",
      "total loss :  0.0\n",
      "TEST :  [204]\n",
      "total loss :  0.0\n",
      "TEST :  [205]\n",
      "total loss :  0.0\n",
      "TEST :  [206]\n",
      "total loss :  0.0\n",
      "TEST :  [207]\n",
      "total loss :  0.0\n",
      "TEST :  [208]\n",
      "total loss :  0.0\n",
      "TEST :  [209]\n",
      "total loss :  0.0\n",
      "TEST :  [210]\n",
      "total loss :  0.0\n",
      "TEST :  [211]\n",
      "total loss :  0.0\n",
      "TEST :  [212]\n",
      "total loss :  0.0\n",
      "TEST :  [213]\n",
      "total loss :  0.0\n",
      "TEST :  [214]\n",
      "total loss :  0.0\n",
      "TEST :  [215]\n",
      "total loss :  0.0\n",
      "TEST :  [216]\n",
      "total loss :  0.0\n",
      "TEST :  [217]\n",
      "total loss :  0.0\n",
      "TEST :  [218]\n",
      "total loss :  0.0\n",
      "TEST :  [219]\n",
      "total loss :  0.0\n",
      "TEST :  [220]\n",
      "total loss :  0.0\n",
      "TEST :  [221]\n",
      "total loss :  0.0\n",
      "TEST :  [222]\n",
      "total loss :  0.0\n",
      "TEST :  [223]\n",
      "total loss :  0.0\n",
      "TEST :  [224]\n",
      "total loss :  0.0\n",
      "TEST :  [225]\n",
      "total loss :  0.0\n",
      "TEST :  [226]\n",
      "total loss :  0.0\n",
      "TEST :  [227]\n",
      "total loss :  0.0\n",
      "TEST :  [228]\n",
      "total loss :  0.0\n",
      "TEST :  [229]\n",
      "total loss :  0.0\n",
      "TEST :  [230]\n",
      "total loss :  0.0\n",
      "TEST :  [231]\n",
      "total loss :  0.0\n",
      "TEST :  [232]\n",
      "total loss :  0.0\n",
      "TEST :  [233]\n",
      "total loss :  0.0\n",
      "TEST :  [234]\n",
      "total loss :  0.0\n",
      "TEST :  [235]\n",
      "total loss :  0.0\n",
      "TEST :  [236]\n",
      "total loss :  0.0\n",
      "TEST :  [237]\n",
      "total loss :  0.0\n",
      "TEST :  [238]\n",
      "total loss :  0.0\n",
      "TEST :  [239]\n",
      "total loss :  0.0\n",
      "TEST :  [240]\n",
      "total loss :  0.0\n",
      "TEST :  [241]\n",
      "total loss :  0.0\n",
      "TEST :  [242]\n",
      "total loss :  0.0\n",
      "TEST :  [243]\n",
      "total loss :  0.0\n",
      "TEST :  [244]\n",
      "total loss :  0.0\n",
      "TEST :  [245]\n",
      "total loss :  0.0\n",
      "TEST :  [246]\n",
      "total loss :  0.0\n",
      "TEST :  [247]\n",
      "total loss :  0.0\n",
      "TEST :  [248]\n",
      "total loss :  0.0\n",
      "TEST :  [249]\n",
      "total loss :  0.0\n",
      "TEST :  [250]\n",
      "total loss :  0.0\n",
      "TEST :  [251]\n",
      "total loss :  0.0\n",
      "TEST :  [252]\n",
      "total loss :  0.0\n",
      "TEST :  [253]\n",
      "total loss :  0.0\n",
      "TEST :  [254]\n",
      "total loss :  0.0\n",
      "TEST :  [255]\n",
      "total loss :  0.0\n",
      "TEST :  [256]\n",
      "total loss :  0.0\n",
      "TEST :  [257]\n",
      "total loss :  0.0\n",
      "TEST :  [258]\n",
      "total loss :  0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST :  [259]\n",
      "total loss :  0.0\n",
      "TEST :  [260]\n",
      "total loss :  0.0\n",
      "TEST :  [261]\n",
      "total loss :  0.0\n",
      "TEST :  [262]\n",
      "total loss :  0.0\n",
      "TEST :  [263]\n",
      "total loss :  0.0\n",
      "TEST :  [264]\n",
      "total loss :  0.0\n",
      "TEST :  [265]\n",
      "total loss :  0.0\n",
      "TEST :  [266]\n",
      "total loss :  0.0\n",
      "TEST :  [267]\n",
      "total loss :  0.0\n",
      "TEST :  [268]\n",
      "total loss :  0.0\n",
      "TEST :  [269]\n",
      "total loss :  0.0\n",
      "TEST :  [270]\n",
      "total loss :  0.0\n",
      "TEST :  [271]\n",
      "total loss :  0.0\n",
      "TEST :  [272]\n",
      "total loss :  0.0\n",
      "TEST :  [273]\n",
      "total loss :  0.0\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "GENERATE_SHAP = True\n",
    "total_epochs = 500 #250(ideal)\n",
    "num_features_list = [usable_features.shape[1]]\n",
    "# random_integers = [2, 6, 108, 90, 5]\n",
    "random_integers = [90]#, 92, 0, 87, 73, 82, 54]\n",
    "\n",
    "folds_list = [10]#[37*2]\n",
    "\n",
    "avg_val_acc = []\n",
    "\n",
    "shap_values_list = []\n",
    "\n",
    "for num_features in num_features_list:\n",
    "    print(f'NF:{num_features}')\n",
    "    global_best_acc_val = 0.\n",
    "    precision_avg = 0\n",
    "    recall_avg = 0\n",
    "    global_loss = 0\n",
    "    \n",
    "    for total_folds in folds_list:\n",
    "        print(f'\\n#F{total_folds}')\n",
    "        for random_seed in random_integers:\n",
    "            N_splits = random_samples(total_folds=total_folds, random_seed=random_seed)\n",
    "            accuracies = []\n",
    "            accuracies_val = []\n",
    "            temp_shap_values = np.zeros(usable_features.shape)\n",
    "            loo = LeaveOneOut()\n",
    "            loo.get_n_splits(N_splits)\n",
    "\n",
    "            for train_index, test_index in loo.split(N_splits):\n",
    "#                 print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "                print(\"TEST : \", test_index)\n",
    "                train_set, _, test_set = generate_datasets_loocv(train_index, test_index, random_seed)                \n",
    "                \n",
    "    #             print(f'fold-{fold_num}:')\n",
    "#                 train_set, val_set, test_set = generate_datasets(N_splits=N_splits, fold_num=1, random_seed=random_seed)\n",
    "#                 train_set, _, test_set = generate_datasets(N_splits=N_splits, fold_num=fold_num, random_seed=random_seed)\n",
    "                val_set = test_set        \n",
    "                train_loader, val_loader, test_loader = generate_loader(train_set=train_set, val_set=val_set, \n",
    "                                                                        test_set=test_set, num_workers=0)\n",
    "                model = simple_model(num_features=usable_features.shape[1], hidden_dim=32)\n",
    "                model = model.to(DEVICE)\n",
    "                optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "                criterion = torch.nn.BCEWithLogitsLoss() \n",
    "                best_acc_val = 0.\n",
    "                model_best = None\n",
    "                for epoch_num in range(total_epochs):\n",
    "                    model.train()\n",
    "#                     model.drop_probab=.8\n",
    "                    precision, recall, fscore, support, auroc, auprc, acc_train, total_loss, pred, pred_binary, true = epoch(model=model, optimizer=optimizer, \n",
    "                                                                                             criterion=criterion, is_training=True, \n",
    "                                                                                             loader=train_loader)\n",
    "                    model.eval()\n",
    "#                     model.drop_probab=.0\n",
    "                    precision, recall, fscore, support, auroc, auprc, acc_val, total_loss, pred, pred_binary, true = epoch(model=model, \n",
    "                                                                                             optimizer=optimizer, \n",
    "                                                                                             criterion=criterion, is_training=False, \n",
    "                                                                                            loader=val_loader)\n",
    "#                     if acc_val > best_acc_val:\n",
    "#                         best_acc_val = acc_val\n",
    "#                         if acc_val > global_best_acc_val:\n",
    "#                             global_best_acc_val = acc_val\n",
    "#     #                         print('global updated!')\n",
    "#                         torch.save(model.state_dict(), 'PRS_model.pt')\n",
    "#     #                     print(f'#F:{total_folds}| seed:{random_seed}, fold:{fold_num}, epoch:{epoch_num} -> local:{best_acc_val}, global:{global_best_acc_val}')  \n",
    "# #                     if epoch_num + 1 == total_epochs:\n",
    "# #     #                     print(f'LAST_Epoch:{epoch_num}, train_acc:{acc_train}, val_acc:{acc_val}, local_best:{best_acc_val}, global_best:{global_best_acc_val}')\n",
    "# #                         pass\n",
    "                model_best = simple_model(num_features=usable_features.shape[1], hidden_dim=32, drop_probab=.0)\n",
    "#                 model_best.load_state_dict(torch.load('PRS_model.pt'))\n",
    "                model_best = model_best.to(DEVICE)\n",
    "                model_best.eval()\n",
    "                precision, recall, fscore, support, auroc, auprc, acc_test, total_loss, pred, pred_binary, true = epoch(model=model_best, \n",
    "                                                                                         optimizer=optimizer, \n",
    "                                                                                         criterion=criterion, is_training=False, \n",
    "                                                                                         loader=val_loader)\n",
    "#                 accuracies += [acc_test]\n",
    "#                 accuracies_val += [best_acc_val]\n",
    "# #                 print(\"precision : \", precision, \" ; recall : \", recall)\n",
    "#                 precision_avg += precision\n",
    "#                 recall_avg += recall\n",
    "                \n",
    "#                 print(precision, recall, fscore, support, auroc, auprc, acc_test, total_loss)\n",
    "            \n",
    "#                 print(\"pred\")\n",
    "#                 print(pred)\n",
    "#                 print(\"pred binary\")\n",
    "#                 print(pred_binary)\n",
    "                print(\"total loss : \", total_loss)\n",
    "                global_loss += total_loss\n",
    "                \n",
    "#                 print(fold_num, ':', accuracies)\n",
    "                if GENERATE_SHAP:\n",
    "                    explainer = shap.GradientExplainer(model_best.to(DEVICE), usable_features,\n",
    "                                                       batch_size=usable_features.shape[0]) #https://shap-lrjball.readthedocs.io/en/latest/generated/shap.KernelExplainer.html\n",
    "#                     print(\"usable features : \", usable_features.shape[0])\n",
    "#                     print(usable_features.shape)\n",
    "#                     print(usable_features)\n",
    "                    shap_values = explainer.shap_values(usable_features, nsamples=500)\n",
    "#                     print(\"shap values shape : \", shap_values.shape)\n",
    "#                     print(\"Shap values : \", shap_values)\n",
    "#                     print(\"shap values of 0 index\", shap_values[0, :])\n",
    "                    \n",
    "                    temp_shap_values += shap_values \n",
    "            if GENERATE_SHAP:\n",
    "                temp_shap_values /= total_folds\n",
    "                shap_values_list += [temp_shap_values] \n",
    "            print(f'random_seed:{random_seed}:', np.mean(accuracies), np.std(accuracies), \n",
    "                  np.mean(accuracies_val), np.std(accuracies_val), 'train acc:', acc_train)\n",
    "            avg_val_acc += [np.mean(accuracies_val)]\n",
    "    \n",
    "    print(f'global_best_acc_val:{global_best_acc_val}')\n",
    "    precision_avg = precision_avg * 1.0 / total_folds\n",
    "    recall_avg = recall_avg * 1.0 / total_folds\n",
    "    print( \"precision avg : \", precision_avg )\n",
    "    print( \"recall avg : \", recall_avg )\n",
    "# usable_features = usable_features.cpu().detach().numpy().astype(np.float64)\n",
    "avg_val_acc = np.array(avg_val_acc)\n",
    "print(avg_val_acc.max(), avg_val_acc.min(), avg_val_acc.mean(), avg_val_acc.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_in_file(\"Neural Network with \" + str(hidden)  + \" layers_4yrs_\" + str(len(feature_indices_to_consider)), global_best_acc_val)\n",
    "# save_in_file(\"Neural Network with \" + str(hidden) + \" layers\", global_best_acc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usable_features = usable_features.cpu().detach().numpy().astype(np.float64)\n",
    "print(np.array([.67699, 0.685, 0.694, 0.687, 0.695, 0.693, 0.6849999, 0.683]).mean())\n",
    "print(np.array([0.6809999999999999, 0.6889999999999998, 0.7060000000000001, 0.6910000000000001, 0.701, 0.6740000000000002, 0.6869999999999999, 0.6869999999999999]).mean())\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print( shap_values_list )\n",
    "\n",
    "import pickle\n",
    "pickle.dump(shap_values_list, open('shap_values_list.pkl', 'wb'))\n",
    "shap_values = np.mean(shap_values_list, axis=0)\n",
    "print( shap_values.shape )\n",
    "# print(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# print( shap_values_list )\n",
    "# print the JS visualization code to the notebook\n",
    "shap.initjs()\n",
    "# print(shap_values[0, :])\n",
    "# print(usable_features[0, :])\n",
    "# shap.summary_plot(shap_values[:, :], usable_features[:, :])\n",
    "\n",
    "shap.force_plot(.5, shap_values[0,:], usable_features[0, :], link = \"logit\", matplotlib = True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shap.force_plot(.5, shap_values[:,:], usable_features[:, :], link=\"logit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traits[20]\n",
    "# shap_values = np.sum(shap_values_list)\n",
    "# usable_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GWAS_IDS = ['ieu-b-109', 'ukb-b-12064', 'ukb-b-13806', 'ukb-d-20405_0', 'ieu-b-38', 'ukb-b-6134', 'ieu-b-110', 'ukb-b-17627', 'ukb-b-19953', 'ukb-b-8476', 'ukb-d-20405_1', 'ukb-d-20405_2', 'ukb-b-2209', 'ukb-b-4424', 'ukb-b-7663', \n",
    "#             'ukb-b-18275', 'ukb-b-770', 'met-d-Total_C', 'ieu-b-25', 'ieu-b-111', 'ukb-b-3957', 'ieu-b-39', 'ukb-b-6324',\n",
    "#            'ukb-a-257','ukb-b-14699','ukb-b-323']\n",
    "# # new added\n",
    "# # ukb-a-257 Hearing difficulty/problems: Yes\n",
    "# # ukb-b-14699 Illnesses of mother: Alzheimer's disease/dementia\n",
    "# # ukb-b-323 Illnesses of father: Alzheimer's disease/dementia\n",
    "GWAS_IDS=[\n",
    "'ukb-b-2209',\n",
    "'ieu-b-39',\n",
    "'ukb-b-4424',\n",
    "'ukb-b-7663',\n",
    "'ukb-d-20405_2',\n",
    "'ukb-b-6324',\n",
    "'ieu-b-111',\n",
    "'ukb-b-13806',\n",
    "'ieu-b-25',\n",
    "'ukb-d-20405_1',\n",
    "'ukb-b-14699',\n",
    "'ukb-b-770',\n",
    "'ieu-b-109',\n",
    "'ukb-d-20405_0',\n",
    "'ieu-b-110',\n",
    "'ukb-b-17627',\n",
    "'ukb-a-257',\n",
    "'ieu-b-38',\n",
    "'ukb-b-18275',\n",
    "'ukb-b-3957'   \n",
    "]\n",
    "\n",
    "# traits = ['HDL cholesterol', 'Non-cancer illness code, self-reported: depression', \n",
    "#           'Non-cancer illness code, self-reported: type 2 diabetes', 'Ever had known person concerned about, or recommend reduction of, alcohol consumption: No', \n",
    "#           'systolic blood pressure', 'Age completed full time education', 'LDL cholesterol', \n",
    "#           'Non-oily fish intake', 'Body mass index (BMI)', 'Loneliness, isolation', \n",
    "#           'Ever had known person concerned about, or recommend reduction of, alcohol consumption: Yes, but not in the last year', \n",
    "#           'Ever had known person concerned about, or recommend reduction of, alcohol consumption: Yes, during the last year',\n",
    "#           'Oily fish intake', 'Sleep duration', 'Types of physical activity in last 4 weeks: Strenuous sports', \n",
    "#           'Hearing difficulty/problems with background noise', 'Other meat intake', 'Total cholesterol', \n",
    "#           'Cigarettes per Day', 'triglycerides', 'Sleeplessness / insomnia', 'diastolic blood pressure', \n",
    "#           'Processed meat intake','Hearing difficulty/problems: Yes','Illnesses of mother: Alzheimer\\'s disease/dementia','Illnesses of father: Alzheimer\\'s di\n",
    "\n",
    "\n",
    "\n",
    "# for GWAS_ID in GWAS_IDS:\n",
    "#     print(GWAS_ID)\n",
    "# traits = ['HDL cholesterol', 'Non-cancer illness code, self-reported: depression', \n",
    "#           'Non-cancer illness code, self-reported: type 2 diabetes', 'Ever had known person concerned about, or recommend reduction of, alcohol consumption: No', \n",
    "#           'systolic blood pressure', 'Age completed full time education', 'LDL cholesterol', \n",
    "#           'Non-oily fish intake', 'Body mass index (BMI)', 'Loneliness, isolation', \n",
    "#           'Ever had known person concerned about, or recommend reduction of, alcohol consumption: Yes, but not in the last year', \n",
    "#           'Ever had known person concerned about, or recommend reduction of, alcohol consumption: Yes, during the last year',\n",
    "#           'Oily fish intake', 'Sleep duration', 'Types of physical activity in last 4 weeks: Strenuous sports', \n",
    "#           'Hearing difficulty/problems with background noise', 'Other meat intake', 'Total cholesterol', \n",
    "#           'Cigarettes per Day', 'triglycerides', 'Sleeplessness / insomnia', 'diastolic blood pressure', \n",
    "#           'Processed meat intake','Hearing difficulty/problems: Yes','Illnesses of mother: Alzheimer\\'s disease/dementia','Illnesses of father: Alzheimer\\'s disease/dementia']\n",
    "\n",
    "# # https://shap-lrjball.readthedocs.io/en/latest/generated/shap.summary_plot.html?highlight=beeswarm#shap.summary_plot\n",
    "# # usable_features_std = (usable_features - usable_features.mean(0))/usable_features.std(0)\n",
    "# shap.summary_plot(shap_values, features=usable_features, feature_names=traits, plot_type='dot', max_display=len(traits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# in place of json straight took it hardcoded\n",
    "\n",
    "all_traits = json.load(open('traits_map.json', 'r'))\n",
    "# print(all_traits)\n",
    "GWAS_IDS = list(all_traits)\n",
    "# print(GWAS_IDS)\n",
    "traits = [all_traits[x] for x in all_traits]\n",
    "# print(traits)\n",
    "# traits.append(\"gender\")\n",
    "# traits.append(\"age\")\n",
    "# print(PRS_orig_feature_matrix.shape[1])\n",
    "# print(feature_indices_to_consider)\n",
    "\n",
    "print(len(traits))\n",
    "print(feature_indices_to_consider)\n",
    "\n",
    "\n",
    "if any(y >PRS_orig_feature_matrix.shape[1] for y in feature_indices_to_consider):\n",
    "    features = feature_indices_to_consider.copy()\n",
    "    features.pop(-2)\n",
    "    features.pop(-1)\n",
    "    print(features)\n",
    "    traits = [ traits[i] for i in features]\n",
    "    print(\"age gender included\")\n",
    "#     traits.append(\"output prediction\")\n",
    "    traits.append(\"age\")\n",
    "    traits.append(\"gender\")\n",
    "else:\n",
    "    traits = [ traits[i] for i in feature_indices_to_consider]\n",
    "print(traits)\n",
    "# for trait in traits:\n",
    "#     print(trait)\n",
    "# https://shap-lrjball.readthedocs.io/en/latest/generated/shap.summary_plot.html?highlight=beeswarm#shap.summary_plot\n",
    "# usable_features_std = (usable_features - usable_features.mean(0))/usable_features.std(0)\n",
    "shap.summary_plot(shap_values, features=usable_features, feature_names=traits, plot_type='dot', max_display=len(traits), show = False)\n",
    "plt.savefig('shap/' + str(num_features) + '/summary_plot_hidden_'+ str(hidden) + '_dim_' + str(hidden_dimension) + '.pdf',  bbox_inches='tight')\n",
    "# shap.summary_plot(shap_values, features=usable_features, feature_names=list(range(23)), plot_type='dot', max_display=len(traits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://shap-lrjball.readthedocs.io/en/latest/generated/shap.summary_plot.html?highlight=beeswarm#shap.summary_plot\n",
    "# shap.summary_plot(shap_values, features=usable_features, feature_names=list(range(23)), plot_type='bar', max_display=len(traits), show=False)\n",
    "# plt.savefig('shap/summary_plot_hidden_'+ str(hidden) + '_bar.png', bbox_inches='tight')\n",
    "# naeem modified\n",
    "shap.summary_plot(shap_values, features=usable_features, feature_names=list(range(num_features)), plot_type='bar', max_display=len(traits), show=False)\n",
    "plt.savefig('shap/' + str(num_features) + 'summary_plot_hidden_'+ str(hidden) + '_bar.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(list(zip(list(range(23)), abs(shap_values).mean(0))), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(shap.force_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # print(Final_Samples)\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn import svm\n",
    "# from sklearn.neural_network import MLPClassifier, MLPRegressor, BernoulliRBM\n",
    "\n",
    "# feature_indices_to_consider = list(range(0, 23)) #[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 18, 20, 22]\n",
    "\n",
    "# usable_indices = [usable_samples_ADNI[Final_Samples[i][0]] for i in range(len(Final_Samples))]\n",
    "# usable_features = FEATURE_MATRIX[usable_indices][:, feature_indices_to_consider]\n",
    "# usable_labels = np.array([float(Final_Samples[i][1]) for i in range(len(Final_Samples))])\n",
    "\n",
    "# Final_Samples = positive_samples[:500] + negative_samples[:500]\n",
    "# random.seed(2);random.shuffle(Final_Samples)\n",
    "# # Final_Samples = np.array(Final_Samples)\n",
    "# print(len([x[1] for x in Final_Samples if x[1] == 1]), len([x[1] for x in Final_Samples if x[1] == 0]))\n",
    "# print(sum(usable_labels), len(usable_labels))\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     usable_features, usable_labels, test_size=0.1)\n",
    "\n",
    "# X_train.shape, y_train.shape\n",
    "\n",
    "# X_test.shape, y_test.shape\n",
    "\n",
    "# print(y_test.sum(), y_test.shape)\n",
    "# clf = svm.SVC(kernel='rbf', C=1).fit(X_train, y_train)\n",
    "# # clf = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam').fit(X_train, y_train)\n",
    "# clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.shuffle(Final_Samples)\n",
    "# usable_indices = [usable_samples_ADNI[Final_Samples[i][0]] for i in range(len(Final_Samples))]\n",
    "# usable_features = FEATURE_MATRIX[usable_indices][:, feature_indices_to_consider]\n",
    "# usable_labels = np.array([float(Final_Samples[i][1]) for i in range(len(Final_Samples))])\n",
    "\n",
    "\n",
    "# from sklearn.model_selection import KFold\n",
    "# X = usable_features[:, :23]\n",
    "# y = usable_labels\n",
    "# kf = KFold(n_splits=10)\n",
    "# kf.get_n_splits(X)\n",
    "\n",
    "# print(kf)\n",
    "# # print(y_test)\n",
    "# accuracies = []\n",
    "# for train_index, test_index in kf.split(X):\n",
    "# #     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#     X_train, X_test = X[train_index], X[test_index]\n",
    "#     y_train, y_test = y[train_index], y[test_index]\n",
    "#     clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "# #     clf = MLPClassifier(hidden_layer_sizes=(32,8), activation='relu', solver='adam', max_iter=100, learning_rate='invscaling').fit(X_train, y_train)\n",
    "# #     print(y_test.sum(), y_test.shape)\n",
    "#     print(clf.score(X_test, y_test))\n",
    "#     accuracies += [clf.score(X_test, y_test)]\n",
    "# print(np.mean(accuracies), np.std(accuracies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "# accuracies = []\n",
    "# X = usable_features[:, :23]\n",
    "# y = usable_labels\n",
    "# kf = KFold(n_splits=10)\n",
    "# kf.get_n_splits(X)\n",
    "\n",
    "# for train_index, test_index in kf.split(X):\n",
    "# #     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#     X_train, X_test = X[train_index], X[test_index]\n",
    "#     y_train, y_test = y[train_index], y[test_index]\n",
    "#     reg = RandomForestClassifier(random_state=0)\n",
    "#     reg.fit(X_train, y_train)\n",
    "#     print(\"Accuracy of model : \",reg.score(X_test, y_test)*100,\"%\")\n",
    "# #     clf = MLPClassifier(hidden_layer_sizes=(32,8), activation='relu', solver='adam', max_iter=100, learning_rate='invscaling').fit(X_train, y_train)\n",
    "# #     print(y_test.sum(), y_test.shape)\n",
    "#     accuracies += [reg.score(X_test, y_test)]\n",
    "# print(np.mean(accuracies), np.std(accuracies))\n",
    "# save_in_file(\"Random Forest\", np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBRegressor, XGBClassifier\n",
    "# model_name = \"XGB\"\n",
    "\n",
    "# accuracies = []\n",
    "# for train_index, test_index in kf.split(X):\n",
    "# #     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "#     X_train, X_test = X[train_index], X[test_index]\n",
    "#     y_train, y_test = y[train_index], y[test_index]\n",
    "#     reg = XGBClassifier()\n",
    "#     reg.fit(X_train, y_train)\n",
    "#     print(\"Accuracy of model : \",reg.score(X_test, y_test)*100,\"%\")\n",
    "# #     clf = MLPClassifier(hidden_layer_sizes=(32,8), activation='relu', solver='adam', max_iter=100, learning_rate='invscaling').fit(X_train, y_train)\n",
    "# #     print(y_test.sum(), y_test.shape)\n",
    "#     accuracies += [reg.score(X_test, y_test)]\n",
    "# print(np.mean(accuracies), np.std(accuracies))\n",
    "# save_in_file(\"XGBoost\", np.mean(accuracies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# open the file in the write mode\n",
    "f = open('model_global_best_accuracy.csv', 'a')\n",
    "\n",
    "# create the csv writer\n",
    "writer = csv.writer(f)\n",
    "\n",
    "# write a row to the csv file\n",
    "# writer.writerow(['num_features','num_nn_layers','global_best_accuracy'])\n",
    "writer.writerow([str(num_features),str(hidden),str(global_best_acc_val)])\n",
    "\n",
    "# close the file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ad_venv_2",
   "language": "python",
   "name": "ad_venv_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
