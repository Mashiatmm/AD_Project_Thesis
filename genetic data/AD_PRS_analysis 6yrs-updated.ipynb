{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1816\n",
      "974\n",
      "(1816,)\n",
      "974\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "\n",
    "PRS_orig_feature_matrix = np.load('./PRS_feature_matrix_only_ad.npy').astype(np.float32)\n",
    "usable_samples_ADNI = json.load(open('./usable_samples_ADNI.json'))\n",
    "final_samples_6yrs=json.load(open('./Final_Samples_6yrs.json'))\n",
    "# final_samples_2yrs=json.load(open('./Final_Samples_2yrs.json'))\n",
    "covar_df = pd.read_csv('./COVAR_FILE_bigger_dataset.txt', ' ') \n",
    "covar_df['AGE'] = covar_df['AGE'] / 100.0\n",
    "\n",
    "print(usable_samples_ADNI.__len__())\n",
    "print(final_samples_6yrs.__len__())\n",
    "# print(final_samples_2yrs.__len__())\n",
    "print(PRS_orig_feature_matrix.shape)\n",
    "print(len(final_samples_6yrs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before adding covar_df columns, shape :  (1816,)\n",
      "Before adding covar_df columns, shape :  (1816, 2)\n",
      "Count of missing samples for covar data :  234\n"
     ]
    }
   ],
   "source": [
    "# cnt = number of missing IDs for which covar data doesn't exist\n",
    "cnt = 0\n",
    "print(\"Before adding covar_df columns, shape : \",PRS_orig_feature_matrix.shape)\n",
    "# adding ( total columns - 2 ) of covar_df , excluding FID, IID\n",
    "FEATURE_MATRIX = np.concatenate([PRS_orig_feature_matrix.reshape(PRS_orig_feature_matrix.shape[0],1), np.zeros([PRS_orig_feature_matrix.shape[0], 1 ])],1).astype(np.float32)\n",
    "print(\"Before adding covar_df columns, shape : \",FEATURE_MATRIX.shape)\n",
    "for sample in usable_samples_ADNI:\n",
    "    # taking from the PCs, skipping the first two columns of IID, FID\n",
    "    age = covar_df[covar_df['IID'] == sample]['AGE']\n",
    "    # shape[0] = 1 means a row is found in covar for the following sample ID\n",
    "    # if not, that means no covar data exists for the sample in usable_samples_ADNI\n",
    "#     print(usable_samples_ADNI[sample],age)\n",
    "#     print(FEATURE_MATRIX[usable_samples_ADNI[sample]])\n",
    "    if age.shape[0] != 1:\n",
    "#         print(covar.shape)\n",
    "#         print(sample)\n",
    "        cnt += 1\n",
    "        continue\n",
    "    # Adding the covar values to the feature matrix\n",
    "    FEATURE_MATRIX[usable_samples_ADNI[sample], -1] = age\n",
    "#     print(FEATURE_MATRIX[usable_samples_ADNI[sample]])\n",
    "\n",
    "\n",
    "print(\"Count of missing samples for covar data : \", cnt)\n",
    "#     FEATURE_MATRIX[usable_samples_ADNI[sample], num_features:] = covar # naeem's modification\n",
    "# cnt/FEATURE_MATRIX.shape[0], FEATURE_MATRIX[:2], PRS_feature_matrix[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1816, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# removing age zero indices\n",
    "# FEATURE_MATRIX = np.delete(FEATURE_MATRIX, age_zero_idx, axis = 0)\n",
    "print(FEATURE_MATRIX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "974\n",
      "166\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26426/2161915526.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shape of feature matrix : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musable_samples_ADNI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "usable_indices = [( usable_samples_ADNI[final_samples_6yrs[i][0]] if ( final_samples_6yrs[i][0] in usable_samples_ADNI.keys() ) else None ) for i in range(len(final_samples_6yrs))]\n",
    "print(len(usable_indices))\n",
    "# print(usable_indices)\n",
    "FEATURE_MATRIX = FEATURE_MATRIX[usable_indices]\n",
    "age_zero = 0\n",
    "age_zero_idx = []\n",
    "for i in range( len(FEATURE_MATRIX) ):\n",
    "    if FEATURE_MATRIX[i, -1] == 0.00:\n",
    "        age_zero += 1\n",
    "        age_zero_idx.append(i)\n",
    "        \n",
    "print(age_zero)\n",
    "FEATURE_MATRIX = np.delete(FEATURE_MATRIX, age_zero_idx, axis = 0)\n",
    "# usable_features = np.delete(usable_features, age_zero_idx, axis = 0)\n",
    "final_samples_6yrs = np.delete(final_samples_6yrs, age_zero_idx, axis = 0)\n",
    "# usable_samples_ADNI\n",
    "# usable_samples_ADNI = np.delete(usable_samples_ADNI, age_zero_idx, axis = 0)\n",
    "\n",
    "\n",
    "print(\"Shape of feature matrix : \", usable_samples_ADNI.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(usable_samples_ADNI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print( df['output'].value_counts() )\n",
    "\n",
    "# ones = df[df['output'] == 1]\n",
    "# zeros = df[df['output'] == 0]\n",
    "# min_len = min( len(ones), len(zeros) ) \n",
    "\n",
    "# ones = ones.iloc[:min_len, :]\n",
    "# zeros = zeros.iloc[:min_len, :]\n",
    "\n",
    "# df = ones.append(zeros, ignore_index=True)\n",
    "# print(df.shape)\n",
    "print(final_samples_6yrs[1][1]==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(final_samples_6yrs)\n",
    "positive_samples = []\n",
    "negative_samples = []\n",
    "\n",
    "final_positive_samples = []\n",
    "final_negative_samples = []\n",
    "for i,s in enumerate(final_samples_6yrs):\n",
    "    if s[1] == '0':\n",
    "        negative_samples.append(FEATURE_MATRIX[i])\n",
    "        final_negative_samples.append(s)\n",
    "    else:\n",
    "        positive_samples.append(FEATURE_MATRIX[i])\n",
    "        final_positive_samples.append(s)\n",
    "\n",
    "min_len=min(len(positive_samples),len(negative_samples))\n",
    "\n",
    "# np.shuffle(final_positive_samples)\n",
    "# np.shuffle(final_negative_samples)\n",
    "final_samples_reduced=final_positive_samples[:min_len]+final_negative_samples[:min_len]\n",
    "total_prs_samples=negative_samples[:min_len]+positive_samples[:min_len]\n",
    "\n",
    "print(len(final_samples_reduced))\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # random.shuffle(final_samples_6yrs)\n",
    "\n",
    "# for i,sample in enumerate(usable_samples_ADNI):\n",
    "#     for s in final_samples_6yrs:\n",
    "#         # print(s)\n",
    "#         if sample == s[0]:\n",
    "            \n",
    "# # print(PRS_to_AD_mapping.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# print(\"Positive samples mean PRS :\",np.mean(positive_samples),\"standard deviation\",np.std(positive_samples))\n",
    "# plt.hist(positive_samples,10)\n",
    "# plt.show()\n",
    "# plt.hist(negative_samples,10)\n",
    "# print(\"Negative samples mean PRS :\",np.mean(negative_samples),\"standard deviation\",np.std(negative_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # making 0 as threshold\n",
    "# y_original=[]\n",
    "# y_predicted=[]\n",
    "\n",
    "# for i,sample in enumerate(usable_samples_ADNI):\n",
    "    \n",
    "#     for s in final_samples_6yrs:\n",
    "#         # print(s)\n",
    "#         if sample == s[0]: \n",
    "#             y_predicted.append(PRS_orig_feature_matrix[i] >= 0)\n",
    "#             y_original.append(s[1])\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import metrics\n",
    "# true=0\n",
    "# for i in range(y_original.__len__()):\n",
    "#     true+=(y_original[i]==y_predicted[i])\n",
    "# precision, recall, fscore,support = metrics.precision_recall_fscore_support(y_original, y_predicted,average=\"macro\")\n",
    "# AUROC=metrics.roc_auc_score(y_original,y_predicted)\n",
    "# p, r, thresholds = metrics.precision_recall_curve(y_original,y_predicted)\n",
    "# AUPRC = metrics.auc(r, p)\n",
    "# print(\"precision: \",precision,\"recall: \", recall,\"f1 score:\", fscore)\n",
    "# print(\"accuracy\",true/(y_original.__len__()))\n",
    "# print(\"AUROC:\",AUROC,\"AUPRC:\",AUPRC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # making 0.6 as threshold\n",
    "# y_original=[]\n",
    "# y_predicted=[]\n",
    "\n",
    "# for i,sample in enumerate(usable_samples_ADNI):\n",
    "    \n",
    "#     for s in final_samples_6yrs:\n",
    "#         # print(s)\n",
    "#         if sample == s[0]: \n",
    "#             y_predicted.append(PRS_orig_feature_matrix[i] >= 0.6)\n",
    "#             y_original.append(s[1])\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import metrics\n",
    "# true=0\n",
    "# # for i in range(y_original.__len__()):\n",
    "# #     true+=(y_original[i]==y_predicted[i])\n",
    "# precision, recall, fscore,support = metrics.precision_recall_fscore_support(y_original, y_predicted,average=\"macro\")\n",
    "# AUROC=metrics.roc_auc_score(y_original,y_predicted)\n",
    "# p, r, thresholds = metrics.precision_recall_curve(y_original,y_predicted)\n",
    "# AUPRC = metrics.auc(r, p)\n",
    "# print(\"precision: \",precision,\"recall: \", recall,\"f1 score:\", fscore)\n",
    "# print(\"accuracy\",true/(y_original.__len__()))\n",
    "# print(\"AUROC:\",AUROC,\"AUPRC:\",AUPRC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(positive_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# random.shuffle(positive_samples)\n",
    "# positive_samples_reduced=positive_samples[:len(negative_samples)]\n",
    "# total_samples=positive_samples+negative_samples\n",
    "# print(len(negative_samples),len(total_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_of_total=np.mean(total_prs_samples)\n",
    "median_of_total=np.median(total_prs_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mean\",mean_of_total)\n",
    "print(\"median\",median_of_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making mean as threshold\n",
    "y_original=[]\n",
    "y_predicted=[]\n",
    "\n",
    "for i,sample in enumerate(usable_samples_ADNI):\n",
    "    \n",
    "    for s in final_samples_reduced:\n",
    "        # print(s)\n",
    "        if sample == s[0]: \n",
    "            y_predicted.append(PRS_orig_feature_matrix[i] >= mean_of_total)\n",
    "            y_original.append(s[1])\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(len(y_original)):\n",
    "    y_original[i]=int(y_original[i])\n",
    "print(y_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.4503495505778285 recall:  0.4547413793103448 f1 score: 0.4424110005462274\n",
      "accuracy 0.4547413793103448\n",
      "AUROC: 0.4547413793103448 AUPRC: 0.5443000317325999\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "true=0\n",
    "for i in range(y_original.__len__()):\n",
    "    true+=(y_original[i]==y_predicted[i])\n",
    "precision, recall, fscore,support = metrics.precision_recall_fscore_support(y_original, y_predicted,average=\"macro\")\n",
    "AUROC=metrics.roc_auc_score(y_original,y_predicted)\n",
    "p, r, thresholds = metrics.precision_recall_curve(y_original,y_predicted)\n",
    "AUPRC = metrics.auc(r, p)\n",
    "print(\"precision: \",precision,\"recall: \", recall,\"f1 score:\", fscore)\n",
    "print(\"accuracy\",true/(y_original.__len__()))\n",
    "print(\"AUROC:\",AUROC,\"AUPRC:\",AUPRC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# making median as threshold\n",
    "y_original=[]\n",
    "y_predicted=[]\n",
    "\n",
    "for i,sample in enumerate(usable_samples_ADNI):\n",
    "    \n",
    "    for s in final_samples_reduced:\n",
    "        # print(s)\n",
    "        if sample == s[0]: \n",
    "            y_predicted.append(PRS_orig_feature_matrix[i] >= median_of_total)\n",
    "            y_original.append(s[1])\n",
    "\n",
    "for i in range(len(y_original)):\n",
    "    y_original[i]=int(y_original[i])\n",
    "print(y_original)\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.41158536585365857 recall:  0.4267241379310345 f1 score: 0.4010869565217391\n",
      "accuracy 0.4267241379310345\n",
      "AUROC: 0.4267241379310345 AUPRC: 0.49245689655172414\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "true=0\n",
    "for i in range(y_original.__len__()):\n",
    "    true+=(y_original[i]==y_predicted[i])\n",
    "precision, recall, fscore,support = metrics.precision_recall_fscore_support(y_original, y_predicted,average=\"macro\")\n",
    "AUROC=metrics.roc_auc_score(y_original,y_predicted)\n",
    "p, r, thresholds = metrics.precision_recall_curve(y_original,y_predicted)\n",
    "AUPRC = metrics.auc(r, p)\n",
    "print(\"precision: \",precision,\"recall: \", recall,\"f1 score:\", fscore)\n",
    "print(\"accuracy\",true/(y_original.__len__()))\n",
    "print(\"AUROC:\",AUROC,\"AUPRC:\",AUPRC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "3f7965b4c8ddf98cd8cc1f613dce0c0d054499dd4a6b649eeb59a69b51e3259a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
